
sniffing and spoofing are security threats that target the
lower layers of the networking infrastructure supporting
applications that use the Internet. Users do not interact
directly with these lower layers and are typically
completely unaware that they exist. Without a deliberate
consideration of these threats, it is impossible to
build effective security into the higher levels.
Sniffing is a passive security attack in which a machine
separate from the intended destination reads data on a
network. The term “sniffing” comes from the notion of
“sniffing the ether” in an Ethernet network and is a
bad pun on the two meanings of the word “ether.”
Passive security attacks are those that do not alter the
normal flow of data on a communication link or inject
data into the link.
258 Part II: Gaining Access and Securing the Gateway
Spoofing is an active security attack in which one machine on the network masquerades as a
different machine. As an active attack, it disrupts the normal flow of data and may involve
injecting data into the communications link between other machines. This masquerade aims to
fool other machines on the network into accepting the impostor as an original, either to lure
the other machines into sending it data or to allow it to alter data. The meaning of “spoof”
here is not “a lighthearted parody,” but rather “a deception intended to trick one into accepting
as genuine something that is actually false.” Such deception can have grave consequences
because notions of trust are central to many networking systems. Sniffing may seem innocuous
(depending on just how sensitive and confidential you consider the information on your
network), some network security attacks use sniffing as a prelude to spoofing. Sniffing gathers
sufficient information to make the deception believable.
Sniffing
Sniffing is the use of a network interface to receive data not intended for the machine in which
the interface resides. A variety of types of machines need to have this capability. A token-ring
bridge, for example, typically has two network interfaces that normally receive all packets
traveling on the media on one interface and retransmit some, but not all, of these packets on
the other interface. Another example of a device that incorporates sniffing is one typically
marketed as a “network analyzer.” A network analyzer helps network administrators diagnose a
variety of obscure problems that may not be visible on any one particular host. These problems
can involve unusual interactions between more than just one or two machines and sometimes
involve a variety of protocols interacting in strange ways.
Devices that incorporate sniffing are useful and necessary. However, their very existence
implies that a malicious person could use such a device or modify an existing machine to snoop
on network traffic. Sniffing programs could be used to gather passwords, read inter-machine
e-mail, and examine client-server database records in transit. Besides these high-level data, lowlevel
information might be used to mount an active attack on data in another computer
system.
Sniffing: How It Is Done
In a shared media network, such as Ethernet, all network interfaces on a network segment have
access to all of the data that travels on the media. Each network interface has a hardware-layer
address that should differ from all hardware-layer addresses of all other network interfaces on
the network. Each network also has at least one broadcast address that corresponds not to an
individual network interface, but to the set of all network interfaces. Normally, a network
interface will only respond to a data frame carrying either its own hardware-layer address in
the frame’s destination field or the “broadcast address” in the destination field. It responds to
these frames by generating a hardware interrupt to the CPU. This interrupt gets the attention
of the operating system, and passes the data in the frame to the operating system for further
processing.
IP Spoofing and Sniffing 259
Note The term “broadcast address” is somewhat misleading. When the sender wants to
get the attention of the operating systems of all hosts on the network, he or she uses
the “broadcast address.” Most network interfaces are capable of being put into a
“promiscuous mode.” In promiscuous mode, network interfaces generate a hardware
interrupt to the CPU for every frame they encounter, not just the ones with
their own address or the “broadcast address.” The term “shared media” indicates to
the reader that such networks broadcast all frames—the frames travel on all the
physical media that make up the network.
At times, you may hear network administrators talk about their networking trouble spots—
when they observe failures in a localized area. They will say a particular area of the Ethernet is
busier than other areas of the Ethernet where there are no problems. All of the packets travel
through all parts of the Ethernet segment. Interconnection devices that do not pass all the
frames from one side of the device to the other form the boundaries of a segment. Bridges,
switches, and routers divide segments from each other, but low-level devices that operate on
one bit at a time, such as repeaters and hubs, do not divide segments from each other. If only
low-level devices separate two parts of the network, both are part of a single segment. All
frames traveling in one part of the segment also travel in the other part.
The broadcast nature of shared media networks affects network performance and reliability so
greatly that networking professionals use a network analyzer, or sniffer, to troubleshoot
problems. A sniffer puts a network interface in promiscuous mode so that the sniffer can
monitor each data packet on the network segment. In the hands of an experienced system
administrator, a sniffer is an invaluable aid in determining why a network is behaving (or
misbehaving) the way it is. With an analyzer, you can determine how much of the traffic is due
to which network protocols, which hosts are the source of most of the traffic, and which hosts
are the destination of most of the traffic. You can also examine data traveling between a
particular pair of hosts and categorize it by protocol and store it for later analysis offline. With
a sufficiently powerful CPU, you can also do the analysis in real time.
Most commercial network sniffers are rather expensive, costing thousands of dollars. When
you examine these closely, you notice that they are nothing more than a portable computer
with an Ethernet card and some special software. The only item that differentiates a sniffer
from an ordinary computer is software. It is also easy to download shareware and freeware
sniffing software from the Internet or various bulletin board systems.
The ease of access to sniffing software is great for network administrators because this type of
software helps them become better network troubleshooters. However, the availability of this
software also means that malicious computer users with access to a network can capture all the
data flowing through the network. The sniffer can capture all the data for a short period of
time or selected portions of the data for a fairly long period of time. Eventually, the malicious
user will run out of space to store the data—the network I use often has 1000 packets per
second flowing on it. Just capturing the first 64 bytes of data from each packet fills up my
system’s local disk space within the hour.
260 Part II: Gaining Access and Securing the Gateway
Note Esniff.c is a simple 300-line C language program that works on SunOS 4.x. When
run by the root user on a Sun workstation, Esniff captures the first 300 bytes of each
TCP/IP connection on the local network. It is quite effective at capturing all
usernames and passwords entered by users for telnet, rlogin, and FTP.
TCPDump 3.0.2 is a common, more sophisticated, and more portable Unix sniffing
program written by Van Jacobson, a famous developer of high-quality TCP/IP
software. It uses the libpcap library for portably interfacing with promiscuous mode
network interfaces. The most recent version is available via anonymous FTP to
ftp.ee.lbl.gov.
NetMan contains a more sophisticated, portable Unix sniffer in several programs in
its network management suite. The latest version of NetMan is available via
anonymous FTP to ftp.cs.curtin.edu.au in the directory /pub/netman.
EthDump is a sniffer that runs under DOS and can be obtained via anonymous FTP
from ftp.eu.germany.net in the directory /pub/networking/inet/ethernet/.
On some Unix systems, TCPDump comes bundled with the vendor OS. When
run by an ordinary, unprivileged user, it does not put the network interface into
promiscuous mode. With this command available, a user can only see data being
sent to the Unix host, but is not limited to seeing data sent to processes owned by
the user. Systems administrators concerned about sniffing should remove user
execution privileges from this program.
Sniffing: How It Threatens Security
Sniffing data from the network leads to loss of privacy of several kinds of information that
should be private for a computer network to be secure. These kinds of information include the
following:
n Passwords
n Financial account numbers
n Private data
n Low-level protocol information
The following subsections are intended to provide examples of these kinds.
Warning
IP Spoofing and Sniffing 261
Sniffing Passwords
Perhaps the most common loss of computer privacy is the loss of passwords. Typical users type
a password at least once a day. Data is often thought of as secure because access to it requires a
password. Users usually are very careful about guarding their password by not sharing it with
anyone and not writing it down anywhere.
Passwords are used not only to authenticate users for access to the files they keep in their
private accounts but other passwords are often employed within multilevel secure database
systems. When the user types any of these passwords, the system does not echo them to the
computer screen to ensure that no one will see them. After jealously guarding these passwords
and having the computer system reinforce the notion that they are private, a setup that sends
each character in a password across the network is extremely easy for any Ethernet sniffer to
see. End users do not realize just how easily these passwords can be found by someone using a
simple and common piece of software.
Sniffing Financial Account Numbers
Most users are uneasy about sending financial account numbers, such as credit card numbers
and checking account numbers, over the Internet. This apprehension may be partly because of
the carelessness most retailers display when tearing up or returning carbons of credit card
receipts. The privacy of each user’s credit card numbers is important. Although the Internet is
by no means bulletproof, the most likely location for the loss of privacy to occur is at the
endpoints of the transmission. Presumably, businesses making electronic transactions are as
fastidious about security as those that make paper transactions, so the highest risk probably
comes from the same local network in which the users are typing passwords.
However, much larger potential losses exist for businesses that conduct electronic funds
transfer or electronic document interchange over a computer network. These transactions
involve the transmission of account numbers that a sniffer could pick up; the thief could then
transfer funds into his or her own account or order goods paid for by a corporate account.
Most credit card fraud of this kind involves only a few thousand dollars per incident.
Sniffing Private Data
Loss of privacy is also common in e-mail transactions. Many e-mail messages have been
publicized without the permission of the sender or receiver. Remember the Iran-Contra affair
in which President Reagan’s secretary of defense, Caspar Weinberger, was convicted. A crucial
piece of evidence was backup tapes of PROFS e-mail on a National Security Agency computer.
The e-mail was not intercepted in transit, but in a typical networked system, it could have
been. It is not at all uncommon for e-mail to contain confidential business information or
personal information. Even routine memos can be embarrassing when they fall into the wrong
hands.
262 Part II: Gaining Access and Securing the Gateway
Sniffing Low-Level Protocol Information
Information network protocols send between computers includes hardware addresses of local
network interfaces, the IP addresses of remote network interfaces, IP routing information, and
sequence numbers assigned to bytes on a TCP connection. Knowledge of any of this information
can be misused by someone interested in attacking the security of machines on the
network. See the second part of this chapter for more information on how these data can pose
risks for the security of a network. A sniffer can obtain any of these data. After an attacker has
this kind of information, he or she is in a position to turn a passive attack into an active attack
with even greater potential for damage.
Protocol Sniffing: A Case Study
At one point in time, all user access to computing facilities in the organization under study
(the university at which the author is employed) was done via terminals. It was not practical to
hardwire each terminal to the host, and users needed to use more than one host. To solve these
two problems, Central Computing used a switch (an AT&T ISN switch) between the terminals
and the hosts. The terminals connected to the switch so that the user had a choice of
hosts. When the user chose a host the switch connected the terminal to the chosen host via a
very real, physical connection. The switch had several thousand ports and was, in theory,
capable of setting up connections between any pair of ports. In practice, however, some ports
attached to terminals and other ports attached to hosts. Figure 6.1 illustrates this setup.
Figure 6.1
Case study system
before networking.
~2500 Input
~400 Output
[SN Switcher]
IBM Mainframe
DEC Vax
DEC Vax
Multiplexor
To make the system more flexible, the central computing facility was changed to a new system
that uses a set of (DEC 550) Ethernet terminal servers with ports connected to the switch,
rather than the old system, which used a fixed number of switch ports connected to each host.
The new terminal servers are on an Ethernet segment shared by the hosts in the central
machine room.
IP Spoofing and Sniffing 263
Offices have a cable running from a wallplate to a wiring closet punchdown block. The punchdown
block has cables running to multiplexers which in turn connect to the switch. The
multiplexers serve to decrease the number of cables that need to be long. With this arrangement
sniffing or other forms of security problems are not an issue. No two offices share any
media. The switch mediates all interaction between computers, isolating the flow of data away
from the physical location of the end users (see fig. 6.2).
Figure 6.2
Case study system after
networking of machine
room but before
networking of user areas.
~2500 Input
~400 Output
[SN Switcher]
IBM Mainframe
DEC Vax
DEC Vax
Multiplexor
Terminal
Server
Terminal
Server
Terminal
Server
Ethernet
Hub
Rather than using simple terminals, however, most computer users have a computer on their
desktop that they use in addition to the Central Computing computers. The switch services
these computers as well as simple terminals. The number of computer users, however, has
grown rapidly over the past decade and the switch is no longer adequate. Terminal ports are in
short supply, host ports are in even shorter supply, and the switch does not supply particularly
high-speed connections.
To phase out the switch, Central Computing installed an Ethernet hub in the basement of
each building next to the punchdown block used to support both the switch multiplexer and
the telephone lines. The hubs in the basements connect to the central facility using fiber-optic
cables to prevent signal degradation over long distances. Hubs also were placed in the wiring
closets on each floor of each building that connected to the basement hub. Now the cables
leading to the wallplates in the offices are being moved from the punchdown block that leads
to the multiplexer to a punchdown block that leads to one of these hubs. The new wiring
scheme neatly parallels the old and was changed relatively inexpensively. Figure 6.3 illustrates
the system after the networking of user areas. Figure 6.4 shows the user area networking detail.
264 Part II: Gaining Access and Securing the Gateway
Although the new wiring scheme neatly parallels the old, the data traveling on the new wiring
scheme does not neatly parallel its previous path. From a logical standpoint, it can get to the
same places, but the data can and does go to many other places as well. Under this scheme, any
office can sniff on all the data flowing to Central Computing from all of the other offices in
the building. Different departments are located in the same building. These departments
compete for resources allocated by upper management and are not above spying on one
another. Ordinary staff, the managers that supervise them, and middle management all are
located in the same building. A fair amount of potential exists for employees to want to know
what other people are sending in e-mail messages, storing in personnel files, and storing in
project planning files.
In addition to nosiness and competition, a variety of people sharing the same physical media in
the new wiring scheme, could easily misuse the network. Since all occupants of a building
IBM Mainframe
DEC Vax
DEC Vax
Ethernet
Hub
Ethernet Hub
Ethernet Hub
Ethernet Hub
Router
Figure 6.3
Case study system after
networking of user areas.
Mac OS
MS Windows
Unix
Punch Block
Hubs
Staff Offices
Hub
NetWare 
Server
NFS Server
Departmental
Machine Room
Figure 6.4
Case study user area
networking detail.
IP Spoofing and Sniffing 265
share a single set of Ethernet hubs, they broadcast all of their network traffic to every network
interface in the entire building. Any sensitive information that they transmit is no longer
limited to a direct path between the user’s machine and the final destination, anyone in the
building can intercept the information with a sniffer. However, some careful planning of
network installation or a redesign of an existing network should include security considerations
(as well as performance issues) to avoid the risks inherent in shared media networking.
The network in the case study fails miserably in the prevention of sniffing. Any computer in a
building is capable of sniffing the network traffic to or from any other computer in the
building. The following section describes how to design a network that limits the sharing of
media to prevent sniffing by untrustworthy machines.
Sniffing: How to Prevent It
To be able to prevent a sniffing attack, you first need to understand the network segments and
trust between computer systems.
Network Segmentation
A network segment consists of a set of machines that share low-level devices and wiring and see
the same set of data on their network interfaces. The wires on both sides of a repeater are
clearly in the same network segment because a repeater simply copies bits from one wire to the
other wire. An ordinary hub is essentially a multiport repeater; all the wires attached to it are
part of the same segment.
In higher-level devices, such as bridges, something different happens. The wires on opposite
sides of a bridge are not part of the same segment because the bridge filters out some of the
packets flowing through it. The same data is not flowing on both sides of the bridge. Some
packets flow through the bridge, but not all. The two segments are still part of the same
physical network. Any device on one side of the bridge can still send packets to any device on
the other side of the bridge. However, the exact same sets of data packets do not exist on both
sides of the bridge. Just as bridges can be used to set up boundaries between segments, so can
switches. Switches are essentially multiport bridges. Because they limit the flow of all data, a
careful introduction of bridges and switches can be used to limit the flow of sensitive information
and prevent sniffing on untrustworthy machines.
The introduction of switches and bridges into a network is traditionally motivated by factors
other than security. They enhance performance by reducing the collision rate of segments,
which is much higher without these components. Switches and bridges overcome the time
delay problems that occur when wires are too long or when simple repeaters or hubs introduce
additional time delay. As one is planning the network infrastructure one should keep these
other factors in mind as well. One can use these factors to sell the introduction of additional
hardware to parties less concerned with security.
266 Part II: Gaining Access and Securing the Gateway
A segment is a subset of machines on the same subnet. Routers are used to partition networks
into subnets. Hence, they also form borders between segments in a network. Unlike bridges
and switches, which do not interact with software on other devices, routers interact with
network layer software on the devices in the network. Machines on different subnets are always
part of different segments. Segments are divisions within subnets, although many subnets
consist of a single segment in many networks. Dividing a network into subnets with routers is
a more radical solution to the sniffing problem than dividing subnets into segments. However,
as you will see in a later section, it may help with some spoofing problems.
Segmentation of a network is the primary tool one has in fighting sniffing. Ideally, each
machine would be on its own segment and its interface would not have access to network data
for which it is not the destination. This ideal can be accomplished by using switches instead of
hubs to connect to individual machines in a 10BASE-T network. As a matter of practicality
and economics, however, one must often find a less ideal solution. Such solutions all involve
the notion of trust between machines. Machines that can trust each other can be on the same
segment without worry of one machine sniffing at the other’s data.
Understanding Trust
Typically, one thinks of trust at the application layer between file servers and clients. Clearly,
the file server trusts its clients to authenticate users. However, this notion of trust extends to
lower-level network devices as well. For example, at the network layer, routers are trusted to
deliver datagrams and correct routing tables to the hosts on their networks. Hosts are trusting
of routers and routers are trusted machines. If you extend the concept of trust down to the
data link layer one gets to sniffing. A machine sending data considered private on a particular
network segment must trust all machines on that network segment. To be worthy of that trust,
the machines on the segment and the wiring between them must have sufficient physical
security (locks on doors, armed guards, and such) to ensure that an attacker cannot install a
sniffer on that segment.
The threat of sniffing comes from someone installing sniffing software on a machine normally
on the network, someone taking a sniffer into a room and jacking it into the network connections
available there, or even installing an unauthorized network connection to sniff. To
counter these options, you must rely on the security of the operating system itself to prevent
the execution of unauthorized sniffing, the personal trustworthiness of the people who have
access to the rooms in which network components are located, and physical security to prevent
untrustworthy people from gaining access to these rooms.
Hardware Barriers
To create trustworthy segments, you must set up barriers between secure segments and
insecure segments. All of the machines on a segment must mutually trust each other with the
data traveling on the segment. An example of such a segment would be a segment that does
not extend outside the machine room of a computing facility. All machines are under the
IP Spoofing and Sniffing 267
control of a cooperating and mutually trusting systems staff. The personal trust between staff
members is mirrored by the mutual trust between the systems for which they are responsible.
The opposite of this is the belief and understanding that some segments simply must be
considered insecure. Insecure segments need not be trusted if those segments carry only public
or non-critical data. An example of such a segment is a university laboratory used only by
students. No guarantee of absolute security is made for the information stored. Possibly the
students realize that for this network drive only reasonable precautions will be taken to
maintain privacy by enforcement of password protections, file system access lists, and regular
backups.
It is less clear where to draw the line in a more professional business setting. The only basis for
trust between machines is for trust between the people who control the machines. Even if a
person can be trusted personally in an ethical sense, he or she may not be trustworthy technically
to administer a machine in such a way that an attacker could not abuse the machine
under his or her control.
Suppose a set of machines has a set of trust relationships as shown in figure 6.5 (an arrow
points from the trusting machine to the trusted machine). One needs to connect them to the
network in such a way that two machines that do not trust each other are on the same segment
and provide appropriate physical security to avoid tampering with a trusted machine. One
such partitioning is shown in figure 6.6 (the lines between segments indicate that the segments
are connected by a device that limits data flow, such as a bridge).
Figure 6.5
A simple set of trust
relationships between
machines An arrow points
from the trusting machine
to the trusted machines.
268 Part II: Gaining Access and Securing the Gateway
Secure User Segments
Security is a relative thing. How secure you make a segment is related to how much control
you take away from the technically untrustworthy end user who uses the network in a location
with limited physical security.
In some settings, you may consider it appropriate to remove control of a machine from the end
user because you cannot trust the end user from a technical standpoint. However, to actually
remove control from the end user and prevent the end user machine from being used for
sniffing, the machine on the end user’s desk essentially becomes a terminal. This may seem
disheartening, but keep in mind that terminals such as X Window System terminals provide
the user with all the functionality of a workstation for running most Unix application software—
they also have no moving parts and are virtually maintenance free.
If the end user cannot be trusted or if the software on a desktop machine could be altered by
the authorized end user because of the machine’s physical location, then the machine should
not be a personal computer. For the purposes of this discussion, a personal computer is one
that runs an operating system such as DOS, Windows 3.1, or Windows 95. These operating
systems lack the notion of a privileged user in the sense that any user can run any program
without interference from the operating system. Hence, any user can run a sniffer on such a
system. PCs have always been popular because they can be customized by the end user. No
system administrator can restrict what the end user can and cannot do with one of these
machines. In highly secure settings, machines that use these operating systems are set up
without local disks to prevent installation of unauthorized software such as a sniffer. Essentially,
they become terminals that offload some of the work from the central, physically secure
server.
Insecure
Segement
Secure
Segment
One-Way Trust
Segment
Mutually Trusting
Segment
Mutually Trusting
Segment
Figure 6.6
A partitioning into
network segments of the
machines in figure 6.5 that
satisfies the lack of trust
between machines.
IP Spoofing and Sniffing 269
A workstation running an operating system such as Windows NT, Unix, or VMS provides an
extra degree of protection because these systems include privileged users, also known as
superusers (“administrator” in NT, “root” in Unix, and “system” in VMS) who must know a
special password. These operating systems only allow access to certain hardware level operations
to superusers. If the end user has ordinary user access to the machine on his or her desk
but does not have superuser privileges, then the machine can be trusted to a larger degree than
the user. It is still possible to bring alternative boot media to most workstation-class operating
systems and obtain superuser privileges without knowing the superuser password. The more
secure systems, however, limit the user’s ability to install software. Usually the only software
that can be installed by the user is the operating system.
Note I once had to review the security arrangements on a set of (DECstation 3100)
workstations. The system administrator in charge of the local network had designated
the workstations secure enough to be trusted by the file server to NFS mount a
file system containing mission-critical data directories. I turned one of the workstations
off, waited a second and turned it back on. After a self-test, it came up with a
boot monitor prompt. I was familiar with similar machines and knew I had two
alternatives, but was unsure what the effective difference would be on this particular
model of workstation. As it turned out, one command (auto) would boot the
workstation directly into Unix multiuser mode, which is what the system administrator
had always done. The system administrator was unaware of the results of trying
the alternative command. When I tried the alternative command (boot), the workstation
booted directly into Unix single-user mode and gave the person at the keyboard
superuser privileges without being required to issue a password.
These workstations clearly were not sufficiently secure to be trusted to NFS mount
the mission-critical disks. The documentation supplied with the workstations did not
mention it. However, it turned out that the single-user mode can be password
protected with a password stored in non-volatile RAM under the control of the boot
monitor. Password protection made these workstations sufficiently secure to be
trusted to mount the mission-critical disks. Absolute security is out of the question,
since one can still reset the non-volatile RAM by opening the system box. On other
systems, the password may be circumvented with other methods.
Although this story has little to do with sniffing, it illustrates how trust can often lead
to unexpected risks on machines outside the server room. By obtaining superuser
privileges, a user could not only sniff data, but do much more serious damage.
Segments with Mutually Trusting Machines
Some research at academic and industrial departments requires that the end user have complete
access to the machine on the desktop. In these cases, a secure segment is probably out of the
question unless the end users are impeccably ethical and technically competent to maintain
system security on the machines they control (a machine administered by someone without
270 Part II: Gaining Access and Securing the Gateway
security training is likely to be broken into by an attacker and used as a base of operations to
attack other machines, including sniffing attacks). If you assume the end users are indeed
competent to ensure the security of their own desktop system, all machines on the segment can
be considered mutually trusting with respect to sniffing. That is, while any of the machines on
the segment could be used as a sniffer, the users trust that they will not be based on the following:
n The physical security of the machines
n The technical competence of the other users to prevent outsiders from gaining control of
one of the machines remotely
n The personal integrity of the other users
It is possible to build a secure subnet or local area network out of a set of segments that each
have mutually trusting machines. You must locate machines that are not mutually trusting on
separate segments. Machines that need to communicate across segment boundaries should only
do so with data that is not private. You can join mutually trusting segments by secure segments.
Such an arrangement presumes that the end users trust the staff operating these central
facilities. However, from a practical standpoint all but the most paranoid end users find this
acceptable.
Connecting Segments of One-Way Trust
Consider, for example, the simple situation of two segments of mutual trust. Mutual trust
exists between the machines on the first segment and mutual trust exists between the machines
on the second segment. However, the machines in the first segment are communicating less
sensitive information than those in the second segment. The machines in the first segment may
trust those in the second segment but not vice versa. In this case, it is allowable for the data
from the first segment to flow through the second segment. However, you must use a barrier
such as a bridge to prevent the flow of data in the opposite direction.
One-way trust is fairly common between secure segments and other types of segments. The less
secure machines must trust the more secure machines, but not vice versa. Similarly, one way
trust may exist between a segment of mutual trust and an insecure segment. Connecting
segments with one way trust via bridges and routers leads to a hierarchy of segments. Tree
diagrams represent hierarchies graphically. In this case, the parent-child relationship in the tree
associates the parent with a more secure segment and the child with a less secure segment.
Thus, the more secure segments are closer to the root of the tree and less secure segments are
closer to the leaves—insecure segments are leaves in the tree representing the one-way trust
hierarchy.
Insecure Segments
In many cases, it is not practical to construct the segment boundaries between machines that
are not mutually trusting. The reason for this is that such a setup isn’t safe from sniffing.
IP Spoofing and Sniffing 271
Insecure segments might be acceptable in areas where security requirements are also low.
However, most users expect a higher level of security than any such setup could provide.
If you must use an insecure segment and still expect a higher degree of security, your only
solution is software-based techniques rather than hardware-based techniques, such as encryption
technology.
Case Study: A Small Department Subnet
A good case study of a network system at risk is in building at the university where I work.
Computer Science shares two floors of the building with Mathematics and English. On the
lower floor are several rooms with computers that are accessible by clients of Computer
Science, offices for professional staff members in each of the three departments, and the
Computer Science machine room. On the upper floor are offices for professional staff members
of Computer Science and Mathematics and the office suites for the managers and secretarial
staff of each.
The rooms in which clients access the network are not secure. Professional staff members in
each department are mutually trusting of each other. They are not mutually trusting of all
members of other departments. The two management suites cannot trust each other. They
cannot trust the professional staff they supervise because they work with sensitive employee
records dealing with performance reviews, salary recommendations, and compete for resources
provided by higher levels of management.
In fact, the management suites are equipped with a higher level of physical security than the
professional staff offices. These suites may be considered secure relative to the offices of the
staff they supervise. The machines in each suite can be considered mutually trusting of other
machines, because the personnel share sensitive information with each other anyway (see fig.
6.7). Finally, the Computer Science machine room is secure.
Math
Staff
Math 
Management
Computer Science
Machine Room
Computer Science
Management
Computer Science
Staff
English
Staff
Computer Science
Clients
To satisfy the constraints of these trust relationships, the staff members of Computer Science,
Mathematics, and English must each be placed on a separate segment. The Mathematics
management suite must be placed on a separate segment. However, data to and from the
Mathematics staff may flow through the Mathematics management suite without violating the
trust constrains. In an exact parallel, the Computer Science management suite can have a
segment with data flowing through it to and from the Computer Science staff segment. The
machines used by Computer Science clients may transmit through staff and management
Figure 6.7
Trust relationships
between groups of
machines in case study.
272 Part II: Gaining Access and Securing the Gateway
segments. Notice the fact that we have a hierarchy of trust being in effect here. At the top end
of the hierarchy is the Computer Science machine room, which must be on its own segment as
well.
Now consider the wiring system available to service these two floors. The lower floor has a
single communication closet that contains the connection to the central computing facility.
The upper floor has a primary communication closet immediately above it connected by a
conduit through the flooring. This primary communication closet on the upper floor is close
to the Mathematics management suite. The primary closet connects, via a wiring conduit, to a
secondary communication closet on the opposite side of the upper floor close to the Computer
Science management suite.
If you do not consider security, you will design the network by looking purely at cost and
performance. The minimum cost solution is simply to locate a set of hubs in each communications
closet and connect all the hubs together to form a single segment. From a performance
standpoint the management personnel do not want to have their network activity slowed by
the activity of the staff they supervise or by people from a different department, so one can
argue to segment the network on the basis of performance in a way that is close to what is
needed for security purposes. If cost is not an issue, each of the proposed segments can simply
be connected by a switch.
A realistic solution needs to do the following:
n Balance the issues of cost and performance
n Take into consideration the physical layout of the building
n Maintain security by not violating the trust constraints
Figure 6.8 shows such a solution. Mathematics places all of its staff on a single segment by
connecting hubs in the upper and lower floor communication closets. The Mathematics
management suite has a segment that bears the burden of traffic from the staff segment. While
Mathematics has a lower cost solution, Computer Science has a higher performance solution.
Computer Science has five separate segments joined by a switch. Computer Science staff are
placed on two separate segments, one for the upper floor and one for the lower floor, not to
satisfy any security concern, but because separate hubs on each floor simplified the wiring and
provide a low-cost opportunity to enhance performance. Computer Science, Mathematics, and
English each have a separate subnet. These three subnets are joined into a single network by a
router located in the communication closet on the lower floor.
The solution shown in figure 6.8 provides for reasonable security against sniffing. Absolute
security is not provided since it is still possible for anyone to hook up a sniffer on any of the
segments. However, data from areas where more security is needed do not flow through areas
where less security is needed. The areas where more security is needed have higher levels of
physical security as well. Hence, it is increasingly difficult to physically get to a location where
sensitive data is flowing on the wires. Also, except on the insecure Computer Science client
IP Spoofing and Sniffing 273
segment, there is trust between the authorized users of the machines sharing a segment. Hence,
an authorized user of a machine cannot use it to sniff data going to or from someone who does
not trust the user.
You can learn several things from looking at the case study and its solution:
n A minimum cost solution is not likely to provide for security.
n A totally secure system is prohibitively expensive, but a reasonably secure system is not.
n Different approaches to cost and performance trade-offs may be combined in a secure
system. Mathematics and Computer Science have different budgets for equipment and
needs for network performance.
n A single solution may provide both security and enhance performance as in the solution
shown for Computer Science.
n A solution that provides for security adds significantly to cost. There is almost no cost
difference between having a single segment for Mathematics and the solution shown. An
extra wire run from the lower floor staff hub to the upper floor staff hub is one extra cost
item as is the bridge separating the two segments.
Computer Science
Management
Computer Science
Staff
Math
Management
Math
Staff
Computer Science
Staff
Computer Science
Machine Room
Computer Science
Clients
English
Staff
Math
Staff
Hub
Hub
Hub
Switch
Hub
Hub
Bridge
Hub
Hub Hub
Router
Figure 6.8
Wiring system to satisfy
trust constraints and fit the
building layout.
274 Part II: Gaining Access and Securing the Gateway
Tip A simple hardware barrier that is inexpensive and has the potential for increasing
network performance is the installation of a bridge between your machine room and
the rest of your facility. In many cases, a great deal of traffic occurs between the
computers in the machine room. A bridge placed between the machine room and
the rest of the facility prevents this traffic from escaping to less secure areas and
reduces the collision rate outside the machine room. Bridges are much less expensive
than a router or a switch. In fact, a low-cost personal computer may be
configured for this purpose with free software such as Drawbridge.
Drawbridge is a free software package that turns an ordinary PC with a pair of standard
Ethernet interfaces into a bridge. Drawbridge is also capable of filtering operations and can act
as a cheap alternative to a firewall in small networks. In some cases, you may be able to recycle
a used PC considered obsolete for this purpose as the memory and disk requirements of
Drawbridge are quite modest.
So far, this section has covered how to avoid sniffing of data from the local part of the Internet.
Such an action seems directed toward protection against internal personnel rather than external
threats. However, many security breaches are aided either knowingly or unknowingly by
internal personnel. In such cases, the hardware barriers described in this section will limit what
an intruder, physically present or remote, can do with a sniffer. Not only is physical security
greater for the more trusted segments, but so is the technical competence of those in charge of
the computer systems. The least technically competent to protect a system from remote
intruders must be given systems that cannot be given commands from a remote location (such
as a simple personal computer). Systems that can accept commands from remote locations
must be administered by those technically competent enough to prevent remote intruders by
not making mistakes that will allow remote intruders to gain access to the systems.
Avoiding Transmission of Passwords
In some sense, the prevention of sniffing by installing hardware barriers may be considered the
last line of defense in a security system. When building medieval fortresses, the last line of
defense was typically the most formidable but could only protect those who would be left
inside after the outer defenses had been breached. In dealing with sniffing, the first line of
defense is simply not to transmit anything sensitive on the network in the first place. The local
hardware defenses may limit intrusion into the local systems. However, if authorized users may
access those systems from remote locations, one must not transmit sensitive information over
remote parts of the Internet lest the information be sniffed somewhere along the way. One
extreme that preserves security is simply not to permit access from remote locations. Also, the
most formidable defenses against inward directed attack do nothing to provide for the security
of one leaving the area being protected. Legitimate Internet sessions initiated inside a network
with those outside must also be protected.
IP Spoofing and Sniffing 275
The most glaring security hole beyond simple loss of privacy is the opportunity for a sniffer to
gather passwords. The best way to deal with this problem is simply not to transmit cleartext
passwords across the network. Simply transmitting an encrypted password that could be
captured and replayed by a sniffer is also not acceptable. Several different methods are in use to
provide this kind of protection:
n The rlogin family of protocols
n Using encrypted passwords
n Zero knowledge authentication
The rlogin Family of Protocols
The rlogin protocol, originally used with Unix-to-Unix terminal sessions, uses end-to-end
mutual trust to avoid the transmission of any form of password. The protocol requires that the
server trust the client to authenticate the user. The user places a file on the server indicating
what combinations of username and hostname may connect to a particular account on
machines using the server. The user may connect from these without presenting any further
credentials such as a password.
This file is called the rhosts file. For the original Unix server, the filename had to be preceded
with a dot, “.rhosts,” but on non-Unix systems using this protocol, the file may have to have a
different name to satisfy the constraints imposed for filenames or different mechanisms used to
store the information about what users are accepted on what trusted systems. The user must
trust that the server is sufficiently secure, that no one else can alter the rhosts file and that
no one else can read the rhosts file. The requirement that the rhosts file not be altered is
obvious—if someone modified the rhosts file, he or she could connect to the account via the
rlogin protocol without the permission of the legitimate user. The requirement that no one
else can read the rhosts file is a bit more obscure, but learned from painful experience. If an
attacker gains access to another account on the machine hosting the rlogin server, the attacker
can read the rhosts file of a user and target the user for an indirect attack. In an indirect attack,
the attacker attempts to gain access to an account listed in the rhosts file on another machine
and use it to obtain access to the machine hosting the rlogin server.
Another file used by some servers for the rlogin protocol is called the host equivalence file,
which is named “/etc/hosts.equiv” in the original Unix implementation. Any user of any host
listed in the host equivalence file may access an account with the same username on the
machine on which the host equivalence file exists without presenting a password. The use of a
host equivalence file adds convenience for the user by relieving individual users from the need
to create their own rhosts file. However, it opens up users to the risks of ARP spoofing and
name server spoofing (both covered later in this chapter) without the implicit consent they give
to that risk when creating their own rhosts file. System administrators are strongly urged not to
use a host equivalence file because of those risks. Users without the network savvy to create an
rhosts file are being put at risk from a threat they have no possibility of understanding.
276 Part II: Gaining Access and Securing the Gateway
Note The rlogin protocol is used by a whole family of programs that use the same
authentication protocol. The family is collectively referred to as the r-commands.
The family includes rlogin for terminal sessions, rsh for remote shell execution of
command-line programs, and rcp for remote file copying. rcp is preferred over FTP
for its security and ease of use. It is secure because it does not require the transmission
of a password and it is easier to use because it can transfer multiple files
specified with the same syntax as the local file copying command.
The rlogin protocol remains vulnerable to ARP spoofing and DNS spoofing (discussed later in
this chapter). It also does not completely protect a user who uses machines that he or she does
not control. For example, when you start an rlogin terminal session from a client’s or
colleague’s office, the client’s or colleague’s machine is not listed in your rhosts. In these cases,
you must remember my password and have it transmitted across the network in plain sight of
any sniffers that may be out there.
Note The r-commands are not limited to Unix. DEC VMS has a variety of TCP/IP software
available for it including both clients and servers for many of the programs in this
family. Many TCP/IP software packages for the PC offer r-command clients. There is
a networking suite for Windows NT that provides an rlogin server, enabling you to
have access to the command line from a remote location without being logged into
it locally. There are many freeware packages that provide a similar server for any PC
with winsock.dll.
Problems with rlogin
As mentioned earlier, on a machine with any server for programs in the rlogin protocol family
it is critical that only the user can modify his or her rhosts file. If it is possible for someone else
to modify it then the ability to modify it can be leveraged into the ability to obtain full access
to the account. Note that if your home directory is on an NFS mounted file system exported
to someone else’s machine your rhosts file is vulnerable to simple attacks on NFS. A standard
attack for the superuser of another machine is to give you an account on the other machine
and then use the su command to gain access to your account on the other machine. The NFS
server is fooled into believing you are accessing your files because it trusts the other machine to
authenticate its users. So far, the attacker is limited to accessing your files, but when he alters
your rhosts file the attacker can begin to run programs that execute with your privileges and do
greater harm.
If an attacker is able to modify the superuser rlogin file or gain access to any account listed in
it, such access can be leveraged into a very serious attack. In particular, an attacker can use rsh
to subvert the requirement that Unix superuser logins occur from secure terminals. Unlike
rlogin or telnet, rsh does not require a pseudo-tty. If protection of your superuser login
account involves restricting insecure terminals, you may want to disable or alter the rsh
program.
IP Spoofing and Sniffing 277
Do not confuse the rexec commands (rexec and rcmd) with the r-commands. The rexec
daemon waits for a username and cleartext password to authenticate a client. It will then
execute a single shell command. Although this is similar to rsh, rexec requires the transmission
of a cleartext password to be sniffed. Also, it provides two distinct error conditions, one for an
invalid username and one for an invalid password. Hence, a brute-force attack can be mounted
by attempting all possible usernames to both determine what usernames are valid and which
users have no password. A standard login program will not provide this distinction and provide
a mechanism to prevent rapid-fire attempts to log in. Security conscious system administrators
often disable the rexec daemon and rexec commands are so seldom known about by users as
not to be missed.
Using Encrypted Passwords
Another solution is to use encrypted passwords over the network. You must use caution,
however, when simplifying this technique. Even with encryption, a sniffer can still record the
encrypted password and decipher the encrypted password at his or her leisure. One way around
this is to use an encryption key that involves the current time. If the sender and receiver are
closely synchronized, the sniffer must replay the encrypted password within one tick of the two
machines’ shared clock. If the sender and receiver are widely separated, however, this technique
becomes less practical and effective because shared clocks will lack sufficient time resolution to
prevent an attacker from using a quick replay. One way around this lack of close synchronization
is to set a limited number of attempts at typing the password correctly.
It also does not suffice to simply encrypt the password with an algorithm using a key that
allows an attacker to determine the encryption key. The attacker would decrypt it for repeated
use at a later time. Some protocols use an encryption technique equivalent to the one used by
the Unix password program when it stores passwords in the password file. This encryption
technique is no longer considered particularly secure against brute force cryptographic attacks
where all likely passwords are encrypted with the same algorithm used by the password file.
Any two words that encrypt the same must be the same. Hence, poorly chosen (for example,
dictionary words) or short passwords are particularly easy to crack by brute force.
What is required is the use of public key cryptography such as PGP (see Chapter 11). In public
key cryptography (also called asymmetric cryptography), you use separate keys for encryption
and decryption—the decryption key is not computable from the encryption key. The server
can send the client its public key and the client can use that key to encrypt the user password.
The server then decrypts the password to verify the authenticity of the user. This is a variation
on the classic public key system in which a trustworthy third party holds the public keys, but it
simplifies the case when no mutually trusted third party is available. It also allows the server to
use a time-dependent public key to prevent password replay or brute force decryption of a
relatively short password.
278 Part II: Gaining Access and Securing the Gateway
Note SRA from Texas A&M provides telnet and FTP without cleartext password exchange.
It uses Secure RPC (Remote Procedure Call) authentication. Secure RPC is part of the
Sun RPC package distributed along with Secure NFS by many vendors and is quite
common on Unix systems. Secure RPC uses public key cryptography using the
patented Diffy-Hellman algorithm. SRA uses a new random secret key/public key
pair for each connection eliminating the need for a separate keyserver.
SRA can be obtained by anonymous ftp to coast.cs.purdue.edu in the directory
/pub/tools/unix/TAMU.
The use of Kerberos also prevents cleartext passwords from being sent across the network.
Kerberos is a comprehensive authentication system using a sophisticated time varying encryption
algorithm and requires that both systems at the ends of a communication connection trust
a separate security server to negotiate the authentication. This avoids having servers trust
clients to do the authentication, as the rlogin protocol must do. See Chapter 9 for more
information on Kerberos.
Zero-Knowledge Authentication
Another mechanism for secure authentication without passwords is zero-knowledge proofs.
Networks that use this system have a client and a server that share what is in essence a very
long sequence of digits. When the client connects to the server, the server queries the client
about a set of digits in a small set of positions in the sequence. Because the number of digits in
the sequence is very long, knowledge of a few digits by a sniffer is not sufficient. The server
will query for a different set of positions each time the client connects.
This type of authentication is growing in popularity. You store the digit sequence held by the
client on a credit card sized device or even in a ring worn by the user. No computer needs to
be carried by a mobile user of this technique; only a few kilobytes of data storage.
RFC 1704 and RFC 1750 provide a good background in the principles of authentication and
the current state of encryption technology for the Internet.
DESlogin 1.3 uses a challenge / response technique in conjunction with DES encryption for
authentication. The latest version is available via anonymous FTP from ftp.uu.net/pub/
security/des.
S/KEY from Bellcore uses the response / challenge technique as well. S/Key is available via
anonymous FTP to thumper.bellcore.com in the /pub/nmh directory. S/Key has support for
a variety of platforms, including Unix, Macintosh, and Windows, to generate the onetime
password used as a response to a challenge. It also includes a replacement for /bin/login and
the FTP daemon on the Unix host.
RFC 1760 describes the system in technical detail.
IP Spoofing and Sniffing 279
Employing Encryption for Entire Connection/Session
Public key cryptography can manage the authentication process to prevent password sniffing
but is not practical for entire terminal sessions or TCP/IP connections. Public key cryptography
is sometimes called asymmetric because different keys are used for encryption and
decryption with no practical way to compute one key from the other key. Classical, symmetric
techniques are much more computationally simple and practical for entire sessions. Just as
public key cryptography can be used to authenticate a user, it can also be used to solve the key
distribution problem of a symmetric encryption technique. Each sender receives the key
electronically with the key encrypted by a public key technique. Thus, the key cannot be
sniffed and used to decrypt the rest of the session.
One such mechanism employing the RSA public key encryption algorithm is the secure socket
layer (SSL) that is being promoted for use with the Web. Because the entire contents of a TCP
connection are encrypted, you can send credit card numbers over the Internet without
worrying that someone will intercept them at one of the many routers between the user’s Web
browser and the merchant’s Web site. You can use SSL as a layer on top of TCP for any server
that might otherwise use raw TCP.
To take advantage of session encryption on the Web, you must have compatible encryption
techniques being used on both the browser and the Web server. Typically, encryption is only
used for transmission of sensitive information such as passwords and credit card information,
not routine HTML and image files. Any vendor doing business on the Web should be quite
clear about what encryption techniques the server supports and give a list of some of the
browsers that support it so that a user will know in advance if the information being sent is
protected by encryption. Conversely, a good browser should indicate if a response to a form on
the Web is not going to be encrypted so that vendors who do not provide a compatible
encryption technique do not endanger their customers.
Spoofing
Spoofing can occur at all layers of the IP system. The hardware layer, the data link layer, the IP
layer, the transport layer, and the application layer are susceptible. All application layer
protocols are at risk if the lower layers have been compromised. In this chapter, only the
application layer protocols intimately linked to the IP protocol are discussed. This includes
routing protocols and the DNS naming protocol. Other application layer protocols depend on
these two protocols to provide basic services to almost all applications using the Internet.
Hardware Address Spoofing
At the hardware layer, any network interface for a shared-media network will have a hardware
interface address. As you read earlier in the discussion on sniffing, most network interfaces can
be put into promiscuous mode and receive frames with any destination address. A much more
280 Part II: Gaining Access and Securing the Gateway
serious problem occurs if the network interface can alter the source address and send data that
appears to come from various source addresses. In the IEEE 802 standards for networking (of
which Ethernet is a variant), each network interface has a 48-bit hardware address. It uses this
hardware address to match the variety of destination addresses of the frames it sees. The
interface copies frames with matching destination addresses into its internal buffer and notifies
the operating system that they are available for further processing. Packets coming from the
operating system to the interface do not typically specify a source address; the interface always
puts its hardware address in the source field.
Most software does not typically control the source field of frames leaving an Ethernet
interface. When another host examines a packet containing a hardware source address associated
with an interface of a particular machine, it assumes that the packet originated on that
machine and accepts it as authentic. An IEEE standards committee assigns each network
interface manufacturer a unique 24-bit prefix for the 48-bit hardware address; the manufacturer
assigns a unique 24-bit suffix to each interface it makes. Regardless, many interface cards
are configurable and allow host software to specify a source address other than the one assigned
by the manufacturer. This configurability makes it possible to use them to spoof the source
address.
DECNet, for example, uses 16-bit identifiers and requires that the leading 32 bits of the
hardware address be set to a fixed value to indicate that the packet is a DECNet packet. Any
network interface that is compatible with DECNet can have its hardware source address
altered in some way, either by software or switches on the interface board.
To see how common it is for a network interface to be able to spoof the source address,
however, recall how a bridge works. A bridge not only puts its interfaces into promiscuous
mode, but it also sets the hardware source address of packets sent out on its interfaces to match
the hardware source address of the originating interface. A PC with two software configurable
interfaces can be configured to be used as a bridge. Clearly, such software configurability has a
variety of malicious uses. The drawbridge software mentioned in the previous section on
hardware barriers to prevent sniffing is compatible with most Ethernet boards which means
most Ethernet boards will permit source address spoofing.
As you can see, it is not entirely safe to base the authenticity of a packet on the hardware
source address. Unfortunately, there is very little you can do to protect yourself against such
deviousness. One solution is to use digital signatures at the application layer. Unfortunately,
currently there are no protections in the IP network layer that will prevent a hardware address
spoofer from disguising one machine as another. If the victim machine is trusted (for example,
is allowed to NFS mount filesystems from another machine), the spoofer will be able to take
advantage of that trust and violate security without being detected. Fortunately, hardware
address spoofing is difficult (relative to many other spoofing methods) and requires penetration
of physical security.
Countering hardware level spoofing is difficult because it is virtually undetectable without
tracing the physical wiring. You need to trace the wiring to be certain no one has connected an
IP Spoofing and Sniffing 281
unauthorized machine and you also need to check to see if the authorized machines are using
the hardware address they should. The latter can be checked using sufficiently “intelligent”
hubs in secure locations.
All machines not in physically secure locations can be connected to hubs in secure locations.
Some “intelligent” hubs can be configured to accept or send packets or both to or from specific
hardware addresses on each port they service. Thus, you can configure the hub to accept only
packets with hardware addresses matching the manufacturer-assigned hardware address of the
interface on the authorized machine. This interface should be connected to the wall plate on
the far side of the wires connected to that port. Clearly, you are still relying on physical
security to be sure that the hub, wires, and authorized machine remain as they should.
Note Devices that perform hardware address verifications cannot be categorized as
“hubs” in the traditional sense and are probably actually specialized switches or
bridges. However, they are marketed as “active hubs” or “filtering hubs.” Such hubs
are available from 3Com, HP, and IBM.
ARP Spoofing
A more common form of spoofing that is accidental is ARP spoofing. ARP (Address Resolution
Protocol) is part of Ethernet and some other similar protocols (such as token-ring) that
associate hardware addresses with IP addresses. ARP is not part of IP but part of these
Ethernet-like protocols; ARP supports IP and arbitrary network-layer protocols. When an IP
datagram is ready to go out on such a network, the host needs to know the hardware destination
address to associate with the given IP destination address. For local IP destinations, the
hardware address to use will be the hardware address of the destination interface. For non-local
destinations, the hardware address to use will be the hardware address of one of the routers on
the local network.
How ARP and ARP Spoofing Work
To find the hardware address, the host sends out an ARP request using the hardware broadcast
address. A frame with the hardware broadcast address reaches every network interface on the
local network, and each host on the local network has its operating system interrupted by the
network interface. The ARP request is essentially asking the question, “What is the hardware
address corresponding to the IP address I have here?” Typically, only the host with the
matching IP address sends an ARP reply and the remaining hosts ignore the ARP request. The
ARP request contains the IP address of the sender of the request and reaches all hosts via a
broadcast.
Other hosts could potentially store the association between hardware address and IP address of
the sender of the request for future reference. The target of the request certainly would store
the association. It will almost certainly send an IP datagram in reply to the IP datagram it is
about to receive. The reply will require knowing the association between the IP address and
the hardware address of the sender of the ARP broadcast.
282 Part II: Gaining Access and Securing the Gateway
The association between the hardware address and the IP address of other machines on a
network is stored in an ARP cache on each host. When an IP datagram is about to leave a host,
the host consults the ARP cache to find the destination hardware address. If the host finds an
entry for the IP destination address, it need not make an ARP request. The entries in an ARP
cache expire after a few minutes.
Thus, when the ARP cache entry for a machine expires, an ARP request goes out to refresh the
entry. No reply comes back if the target machine goes down. The entries for its interface’s
hardware will disappear from the ARP caches in the other machines on the network. The other
machines will be unable to send out IP datagrams to the downed system after the ARP cache
entries expire. Before that point in time, IP datagrams are sent out but are not received. When
the machine comes back up, it will again be able to reply to ARP requests. If someone replaces
its interface, the now up and running machine will have a new hardware address and will use
that new hardware address in ARP replies. ARP caches throughout the network will reflect the
change, and IP datagrams go out using the new hardware address.
Because you expect the IP address to hardware address association will change over time, the
potential exists that the change may be legitimate. Sometimes it is purely accidental. Someone
may inadvertently assign a machine the same IP address held by another machine. On personal
computers or special purpose devices such as network printers or X Window System terminals,
the end user typically has access to a dialog box, command, or text file that sets the IP address.
On multiuser systems, the system administrator is typically the only one who can set the IP
addresses of the network interface(s). This arrangement is changing, however, as more inexperienced
IP-based end users with PCs set addresses. In addition, bureaucracies often separate
system administrators and network administrators that use the same network. Under such
circumstances it is common for two machines to end up with the same IP address. Duplication
can occur either by copying the network configuration from one personal computer to another
without the end user knowing the need for IP addresses to be unique. Duplication can also
occur if system administrators on a network do not work together when configuring system
addressing.
When two machines end up with the same IP address, both of them will naturally reply to an
ARP request for that address. Two replies to the request come back to the host that originated
the request. These replies will arrive in rapid succession, typically separated by at most a few
milliseconds. Some operating systems will not realize anything is wrong and simply file each
reply in the ARP cache with the slowest response remaining in the ARP cache until the entry
for that IP address expires. Other operating systems will discard ARP replies that correspond to
IP addresses already in the cache. These may or may not bother to check if the second reply
was a harmless duplicate or an indication an ARP spoof may be underway.
Thus, depending on the mechanism used to process duplicate ARP replies, if a spoofer wants
to be the target of the IP datagrams being sent to a particular IP address from a particular host,
it needs to make sure it is either the first or the last to reply to ARP requests made by that
particular host. An easy way to be first or last is to have the only machine that replies to the
IP Spoofing and Sniffing 283
ARP requests. An attacker can simply use a machine assigned, via the normal operating system
configuration mechanisms, the same IP address as a machine that is currently not working. An
attacker attempting to masquerade his or her machine can simply turn the legitimate machine
off. The attacker does not need to have direct access to the power switch on the machine. The
machine can be turned off either by unplugging it or flipping the appropriate circuit breaker.
An alternative to disconnecting its power is to disconnect it from the network at some point in
the network wiring scheme. Third, the attacker can change the legitimate machine’s IP address
and leave it turned on if he or she can reconfigure the machine. Doing so is less likely to draw
attention or result in confusion from the machine’s user or administrator.
A Case Study: Inadvertent ARP Spoofing
At a Department of Computer Services in a midwestern university, a room is set aside for
making presentations to groups of clients. The room is equipped with a Unix workstation and
a $15,000 ceiling-mounted video projector projecting onto a $2,000 eight-foot diameter
screen. One day, the workstation needed to be replaced with a newer model. The new workstation
came in and was being configured to match to the configuration of the workstation in the
presentation room. One of the first questions asked during the operating system installation
process was the IP address. The technician in charge of configuring the new workstation
looked up the IP address of the workstation in the presentation room and entered it into the
dialog box.
After a short time, the new workstation was up and running. The systems staff wanted to be
sure it was working correctly because it was difficult to fix after it was installed in the presentation
room. The new workstation was turned off that night after testing the shutdown procedure
to be used by the presenters.
The next morning a presentation started in the presentation room with the old workstation.
All was going well until the systems staff decided to resume testing of the new workstation.
Shortly after the new workstation booted, the presentation came to a complete halt. The
person in charge of the presentation was using the X Window System to demonstrate a
program running on a better computer. The workstation in the presentation room had
established a TCP/IP connection with the better machine and the presenter was creating the
illusion that the program was running on the old workstation.
What had happened was the better computer had created an ARP cache entry for the old
workstation when the presenter started the TCP/IP connection. As the presentation progressed,
the ongoing IP datagrams from the better computer to the old workstation used the
cache entry created at the beginning of the presentation. Several minutes into the presentation
the ARP cache entry expired and a new ARP request went out from the better computer. The
first time the ARP cache entry expired, the old workstation replied appropriately. The next
time the ARP cache expired, however, the new workstation had been started. Both the old and
new workstations replied to the computer running the demonstration software. The new
workstation’s hardware address ended up in its ARP cache and the new workstation began
284 Part II: Gaining Access and Securing the Gateway
receiving the IP datagrams sent to the IP address the old and new workstations shared. The
new workstation did not know what to do with these datagrams and promptly sent a TCP/IP
reset message in reply, resulting in the shutdown of the demonstration program. From initial
appearances, the demonstration program just stopped and the old workstation appeared to
have been cut off from the network.
Needless to say, the presenter was upset. When the system administrator figured out what had
gone wrong, the technician who used the IP address of an existing machine learned a valuable
lesson: two machines with the same IP address cannot be connected to the network at the same
time.
A Case Study: Malicious ARP Spoofing
As mentioned earlier, I work at a university where Computer Science allows its clients (students)
temporary access to its computers. These include some Unix workstations using NFS to
mount a mission-critical filesystem. One of these clients has a laptop running Unix. He already
knows the IP address of the workstations that NFS mount the mission-critical filesystems. This
particular user has created a copy of the workstation password file on his laptop and has
superuser privileges on his own laptop, which runs Unix with NFS.
One day he is left alone in the room with one of our workstations. He shuts down the workstation
and jacks his laptop into our network. After a few minutes the file server’s ARP cache
entry for the workstation expires. Then, he launches an attack by telling his workstation to
NFS mount our mission-critical filesystem. The mount daemon on the file server checks the IP
address of the machine making this request against the list of authorized IP addresses and finds
a match. It then proceeds to send information needed to access the NFS daemon back to the
IP address that just made the mount request.
When the mount daemon sends the reply back, the low-level software connecting IP to
Ethernet discovers that it does not have an ARP cache entry for this IP address. It puts the
reply on hold and makes an ARP broadcast to determine the hardware address to which to
send the reply. The attacker’s laptop is the only machine to respond. The low-level software
takes the response, caches it, and uses it to take the reply out of the holding bin and send it out
the Ethernet interface. The attacker succeeds in accessing the mission-critical filesystem as if he
were a legitimate user of the workstation that he just turned off.
Preventing an ARP Spoof
It is not particularly satisfying to simply detect ARP spoofing, which only identifies a problem
after it has already occurred. Although it may not be possible to prevent ARP spoofing entirely,
one simple precaution can be taken where it may count the most. The devious thing about an
ARP spoof is that the attack is really directed at the machine being deceived, not the machine
whose IP address is being taken over. Presumably, the machine or machines being deceived
contain data that the ARP spoofer wants to get or modify.
IP Spoofing and Sniffing 285
The deception is useful to the ARP spoofer because the legitimate holder of the IP address is
trusted in some way by the machine being deceived. Perhaps the trusted machine is allowed to
NFS mount filesystems, use rlogin, or start a remote shell without being prompted for a
password (particularly troublesome for privileged user accounts). Ideally, machines extending
such trust should simply not use ARP to identify the hardware addresses of the machines they
trust.
Stop Using ARP
Machines extending trust to other machines on the local network based on an IP address
should not use ARP to obtain the hardware address of the trusted machines. Instead, the
hardware address of the trusted machines should be loaded as permanent entries into the ARP
cache of the trusting machine. Unlike normal ARP cache entries, permanent entries do not
expire after a few minutes. Sending a datagram to an IP address associated with a permanent
ARP cache entry will never result in an ARP request. With no ARP request being sent, an
attacker does not have the opportunity to send an ARP reply. It seems unlikely that any
operating system would overwrite a permanent ARP cache entry with an unsolicited ARP
reply.
With permanent ARP cache entries for trusted machines, the trusting host will not use ARP to
determine the correct hardware address and will not be fooled into sending IP data to an ARP
spoofer. Of course, it will also send IP data to the machine even if the machine has been down
for some time. Another downside to permanent ARP entries is that the cache entries will need
revising if the hardware address changes for a legitimate reason. Finally, ARP caches may be of
limited size, limiting the number of permanent entries or further limiting the time a dynamic
entry spends in the cache.
Displaying ARP Cache Entries
On Unix and Windows 95/NT machines, you use the arp command to manipulate and
inspect the ARP cache. This command has several options.
arp -a
The -a option displays all ARP cache entries for all interfaces of the host. The following output
is an example of what you would see on a Windows 95 machine:
Interface: 147.226.112.167
Internet Address Physical Address Type
147.226.112.1 aa-00-04-00-bc-06 static
147.226.112.88 08-00-20-0b-f0-8d dynamic
147.226.112.101 08-00-2b-18-93-68 static
147.226.112.102 08-00-2b-1b-d7-fd static
147.226.112.103 00-00-c0-63-33-2d dynamic
147.226.112.104 00-00-c0-d5-da-47 dynamic
147.226.112.105 08-00-20-0b-7b-df dynamic
147.226.112.106 08-00-20-0e-86-ef dynamic
147.226.112.124 08-00-2b-1c-08-68 dynamic
147.226.112.169 08-00-09-2a-3c-08 dynamic
286 Part II: Gaining Access and Securing the Gateway
Deleting an ARP Cache Entry
At some point you may want to delete a permanent ARP cache entry that is no longer valid or
delete a dynamic entry that you suspect of being spoofed. The -d option deletes the entry with
the given IP address from the ARP cache.
arp -d 147.226.112.101
Inserting a Permanent ARP Cache Entry
The -s option inserts a permanent (static) ARP cache entry for the given IP address. Typically,
the Ethernet address would be obtained by displaying the entire ARP cache as shown previously.
arp -s 147.226.112.101 08-00-2b-18-93-68
To ensure that the address is in the ARP cache you can first use the ping command to send an
ICMP/IP echo request to the IP address in question. A somewhat more secure, but tedious,
method is to use an operating system dependent method for querying the machine in question
for its own hardware address from its console. You can place a series of such commands into
the startup script for the machine that will be extending trust to others.
Inserting Many Permanent ARP Cache Entries
The -f option loads permanent entries into the ARP cache from a file containing an IP address
to hardware address database.
arp -f arptab
In this example, the file is named “arptab,” but the name of the file is up to the system
administrator using the command. The -f option to the arp command is not available on all
systems. In particular, it is missing from the current versions of Windows 95 and Windows
NT. However, it is really just a substitute for a series of arp commands with the -s option.
Use an ARP Server
The arp command outlined in the previous section also allows one machine to be an ARP
server. An ARP server responds to ARP requests on behalf of another machine by consulting
(permanent) entries in its own ARP cache. You can manually configure this ARP cache and
configure machines that extend trust based on this IP address to use ARP replies coming from
the ARP server rather than ARP replies from other sources. However, configuring a machine to
believe only in the ARP server is a difficult task for most operating systems.
Even if you do not configure other machines to trust only the ARP server for ARP replies, the
type of server may still be beneficial. The ARP server will send out a reply to the same requests
as a potential ARP spoofer. When machines process the ARP replies, there is at least a fair
chance that the ARP spoofer’s replies will be ignored. You cannot be sure because as you have
seen, much depends on the exact timing of the replies and the algorithms used to manage the
ARP cache.
IP Spoofing and Sniffing 287
Introduce Hardware Barriers
The use of bridges or switches removes the threat of sniffing between network segments;
likewise, the use of routers removes the threat of ARP spoofing between IP subnets. You can
separate the trusted hosts (those with IP addresses that might benefit an attacker using ARP
spoofing) from subnets on which an attacker might obtain access. Subnetting for security is
helpful if physical security prevents attachment to the subnet of the trusted machine. Such
subnetting prevents a spoofer from powering down one of the trusted machines and attaching
to the subnet on which ARP requests from the trusting machine are broadcast.
A temptation when considering using subnetting to protect from ARP spoofing is to place the
machine extending trust on a separate subnet from the machines to which it is extending trust.
However, this setup simply places the router in the position of being deceived by an ARP
spoof. If trust is extended on the basis of IP addresses, the machine extending the trust is in
turn trusting the routers to deliver the IP datagrams to the correct machine. If the trusted
machines are on a separate subnet that is susceptible to ARP spoofing, the router for that
subnet must bear the burden of ensuring that IP datagrams get to their legitimate destination.
With this setup, you might need to place permanent ARP cache entries for the trusted
machines in the router itself.
Finally, it is also important that trusted machines be protected from an ARP spoofer that is
attempting to masquerade as the router. Fortunately, routers are typically physically secure and
crash rarely or for very little time, which makes them difficult to impersonate.
Sniffing Case Study Revisited
To illustrate ARP spoofing in a familiar context, recall the solution to the sniffing problem
adopted by Computer Science in the case study earlier in the chapter (see fig. 6.7). The
solution to the sniffing problem was to divide the portion of the network servicing Computer
Science into five segments. These segments connect to a switch in the Computer Science
machine room. The only router being used is the router that joins Computer Science with the
two segment subnet for Mathematics and the one segment subnet for English. All five segments
in Computer Science are part of a single subnet.
Within a single subnet an ARP request goes out to all machines on the subnet and a reply may
come back from any of them. Thus, an ARP spoof attack may be launched from any of the
segments. To prevent this, the segments may be divided into a group of subnets rather than a
single larger subnet.
The analysis of the situation for the ARP spoofing problem is analogous to that for the sniffing
problem. The trust that a machine will not sniff is replaced by the trust that a machine will not
ARP spoof. The hardware barrier used to control ARP spoofing is a router to induce
subnetting rather than a bridge or a switch to induce segmenting.
288 Part II: Gaining Access and Securing the Gateway
The simple solution to the ARP spoofing problem for Computer Science is to simply place
each segment on its own single-segment subnet by replacing the switch with a router. However,
the two staff segments that were kept separate for reasons other than satisfying the trust
constraints may share a subnet.
One major benefit to this solution is the ease in which routers can perform media conversion.
The subnet for the machine room can use high-speed network media such as Fast Ethernet,
FDDI, or HyperChannel. The client and staff subnets can use lower speed network media
such as 10 Mbps Ethernet or 4 Mbps token ring.
Problems arise, however, with respect to routing protocols. If the Central Computing router
controls the router in the communication closet and does not trust the Computer Science
router, they cannot exchange routing information. The Central Computing router will refuse
to accept the routes advertised by the Computer Science router, cutting off a way for remote
machines to send datagrams to machines on subnets not directly attached to the Central
Computing router. Machines on the Computer Science subnets not directly connected to the
Central Computing router will be forced to interact with the central computing facility by
using the hosts in the Computer Science as intermediaries. Such a use of intermediaries is
known as a “proxy” arrangement.
A proxy arrangement is actually an attractive setup from a security standpoint, but can be quite
awkward for end users. A simple proxy Web server in the Computer Science machine room
will reduce this awkwardness. Another, more sophisticated proxy arrangement would be to give
IP addresses to Computer Science machines that make them appear to be on the same subnet
from the perspective of the Central Computing router. The Central Computing router will
make ARP requests to determine where to send the datagrams it is forwarding to a Computer
Science segment it is not connected to. The Computer Science router can perform a “proxy
ARP” and reply with its own hardware address. The datagrams will be delivered to the
Computer Science router for forwarding, while the Central Computing router is led to believe
it delivered the datagram to its destination. In essence, the Computer Science router is
performing a beneficial ARP spoof: it benefits the machines on the Computer Science subnets,
and it spoofs the Central Computing router.
Detecting an ARP Spoof
Unless you have the capability to introduce the kind of hardware barriers described previously,
preventing an ARP spoof is probably not practical. The best you can usually hope for is rapid
detection followed by some form of intervention. When an anomaly is detected in the ARP
protocol it may be legitimate, accidental, or a security breach. Policies and procedures should
be in place to handle each type of incident. This chapter limits its discussion to mechanisms; it
is up to the reader to decide what policies and procedures to implement after detection of a
potentially serious problem takes place.
Several mechanisms exist for detecting an ARP spoof. At the host level, an ordinary host may
attempt to detect another machine using its own IP address either by passively examining
IP Spoofing and Sniffing 289
network broadcasts or by actively probing for such a machine. At the server level, a machine
providing a supposedly secure service to the network—perhaps a file server or a router—may
also attempt to detect an ARP spoof by one of its clients. Finally, at the network level, a
machine under control of the network administrator may examine all ARP requests and replies
to check for anomalies indicating an ARP spoof is underway.
Host-Level Passive Detection
As a basic precaution, when an operating system responds to an ARP broadcast, it should
inspect both the sender IP address and the target IP address. It only needs to check the target
address to see if the target IP address matches its own IP address. If so, it needs to send an ARP
reply. However, once the operating system has been interrupted, it takes little extra work to
check to see if the sender IP address matches its own. If so, another machine on the network is
claiming to have the same IP address. Such an anomaly certainly indicates a serious configuration
problem and may be the result of a simplistic ARP spoof in which the attacker simply
reset the IP address of the machine being used in the attack. Many Unix systems perform such
a check.
Host-Level Active Detection
Another precaution to detect ARP spoofs is to arrange for hosts to send out an ARP request for
their own IP address, both on system startup and periodically thereafter. If the host receives an
ARP reply for its own IP address, the IP software should report the detection of an ARP spoof
to the host user or administrator. Actively querying ARP with one’s own IP address will catch
inadvertent IP address misconfigurations as well as an attacker who is simply using an ordinary
operating system with a deliberately misassigned IP address. However, it is possible to mount a
more sophisticated attack that will thwart the active query detection method.
In particular, a technically adept attacker might modify the operating system of the machine
being used to mount the attack. A simple modification that thwarts the active query detection
method is to not reply to ARP requests originating from the legitimate interface associated
with the IP address being used. The availability of such sophisticated software may seem
unlikely even to an advanced computer user.
However, freely distributed Unix-like operating systems with freely distributed source code are
now very common. It is not particularly difficult for a determined attacker to obtain such an
operating system. He or she could then modify its kernel at the source code level, and compile
a modified kernel specifically for the purpose of mounting such an attack.
Server-Level Detection
Alternatively, a more elaborate precaution would be to verify an ARP reply by making an
RARP request for the hardware address contained in the reply. RARP, the reverse address
resolution protocol, uses the same format as ARP and also broadcasts requests. RARP requests
ask the question “What is the IP address associated with the hardware address I have here?”
290 Part II: Gaining Access and Securing the Gateway
Traditionally, the primary use of RARP is by diskless machines with no permanent modifiable
memory. Such machines need to discover their own IP address at boot time. RARP relies on
one or more RARP servers that maintain a database of hardware addresses and the corresponding
IP addresses. Use of an RARP server is probably overly elaborate when an ARP server
would do the same job.
Note The basic idea of checking the validity of the results to a query by making an
inverse query is generically useful. That is, in many situations you are querying a
system equivalent to a database. Suppose you use one value, X, as a key for a query
with the database indexed on one field and get a second value, Y, from a second
field as a result. Then, you can use Y as they key for a query with the database
indexed on the second field and you should get X as a result. If you do not, then
something is wrong with the database or its searching mechanism.
Network-Level Detection: The Motivation
The motivation for network-level detection is that host-level detection may be unable to
effectively inform the network staff that a problem exists and that server-level detection
probably requires modification of IP software of the operating system source code. When a
host detects that it is being impersonated by another machine, it may be able to report the fact
to its user, but once an attack is underway it may be unable to inform the network administrator
who is presumably using another machine.
Some popular IP system software may very well take the precaution of occasionally making
ARP requests for the hardware address associated with the IP address it believes is its own. The
active querying precaution is well-known and is a common textbook exercise. Most corporate
system staffs are unable to modify the IP software of most of the machines on their network. If
that is your situation, you probably want a software detection system that can be deployed on a
single machine on your network. Building the system using software already written by
someone else is preferable.
Network-Level Detection via Periodic Polling
By periodically inspecting the ARP caches on machines, you should be able to detect changes
in the IP address to hardware address association on those machines. It should be routine for
the network staff to keep a database of hardware addresses, IP addresses, DNS names, machine
types, locations, and responsible persons. At the very least, such an inspection can probably be
done manually on most hosts. It could be done more often if hosts could be configured to
periodically report the contents of their ARP caches to a centralized machine. A program on
that machine could look for inconsistencies between hosts, changes from previous reports, and
conflicts between reported ARP cache information and the information in the manually
maintained database—any of these may indicate a problem.
IP Spoofing and Sniffing 291
Standard mechanisms for periodic reporting of network configuration information from
machines on an IP-based network to the network administration staff already exist. One such
mechanism is SNMP—the Simple Network Management Protocol.
In SNMP, each machine using IP runs an SNMP agent which both responds to information
and configuration requests as well as reports certain conditions to the network management
staff. Virtually all current systems provide bundled SNMP agents. To take advantage of
SNMP, the network management staff must have SNMP management software to query the
agents and react to the agent reports. Finding good SNMP management software may be
difficult and expensive to purchase and deploy.
If your network is already employing SNMP for other purposes, including a check on ARP
caches may be simple and inexpensive depending on the sophistication of your SNMP
management software. The standard SNMP MIB-I contains the address translation group that
contains a single table named “at.atTable,” which contains the IP address and hardware
address of each interface being monitored by the SNMP agent. The address translation group
has to be deprecated in SNMP MIB-II to allow for greater flexibility because IP is now no
longer the only protocol being controlled with SNMP. For SNMP agents that use MIB-II, you
should look in the IP address translation table in the IP group named ip.ipNetToMediaTable.
SNMPv1 requests use a “community name” to access a particular view of the
MIB. Many SNMPv1 agents are configured with a community name of “public” to
give a read-only view of all of the objects in the MIB. Writable views should not be
used on an SNMPv1 agent if sniffing is a concern. A sniffer could determine the
community name for the writable view and use it to alter the state of the device
being controlled by the agent.
Network-Level Detection via Continuous Monitoring
A more robust and rapid mechanism for detecting ARP spoofing is to keep an interface on the
network in promiscuous mode. A program on the promiscuous interface’s host can inspect
every packet sent on the network and monitor the network on a continuous basis, not just
when troubleshooting. Such a program can monitor network load, the protocol mix—how
much of the traffic is IP, how much is IPX, how much is other network-layer protocols—as
well as look for anomalies including ARP spoofing. A network monitor can detect a change in
the association between a hardware address and an IP address and report such changes immediately
when they occur.
Brouters, transparent bridges, and switches are all logical places to locate the type of network
monitor described in the previous paragraph. (Brouters are devices that are combination
bridges and routers—a hybrid device such as the Cisco AGS that is often found in
multiprotocol networks where non-routable protocols must be bridged.) All these devices have
their interfaces in promiscuous mode all the time, so the monitor would not dramatically
increase the load on one of these machines because they are all routinely examining each
Warning
292 Part II: Gaining Access and Securing the Gateway
packet. Also, they all typically come with SNMP agents that can send a trap message to the
network operations center to report the detection of a potential ARP spoof.
These kinds of systems have a reasonable chance of actually getting such a trap message all the
way to the network operations center. However, none of these devices may be successful in
doing so if the spoofer is masquerading as the network operations center itself. The trap also
may be lost if the spoofer is masquerading as a router between the monitor that detects the
spoof and the network operations center.
SNMP agents supporting the RMON protocol (as described in RFC 1271) are designed to do
low-level monitoring involving sniffing. On a multisegment network, an RMON/SNMP agent
needs to be placed on each segment to get full coverage of the network. Locating the RMON
agent on devices that connect to more than one segment will reduce the number of agents that
need to be fielded.
Note I am unaware of any good, comprehensive, or affordable commercial packages to
implement SNMP-based ARP spoofing monitors. However, building your own
system using freeware packages such as BTNG and Tricklet provides an alternative
to expensive commercial packages.
RFC 1271 describes the RMON protocol.
BTNG (Beholder, The Next Generation) is an RMON agent available from the Delft
University of Technology in the Netherlands via anonymous FTP.
Tricklet, an SNMPv1 management system written in the PERL scripting language,
was developed by the same group that developed BTNG. The two systems are
integrated and are a good place to start to put together an ARP spoofing detection
system in a network large enough to require SNMP management.
In smaller networks, simply placing monitoring software on a small number of secure hosts
with interfaces in promiscuous mode all the time might be the only ARP spoofing detection
you need. Such monitoring software includes “arpmon” and “netlog” from Ohio State
University. These two programs are part of a larger set of programs to assist system and
network administrators. Another program to do this kind of monitoring is ARPWatch, which
is more narrowly focused on the issue of looking for anomalous behavior in the ARP protocol.
n arpmon is available from ftp.net.ohio-state.edu:/pub/networking. It requires
tcpdump and PERL.
n netlog is available from ftp.net.ohio-state.edu:/pub/security.
n ARPWatch 1.7 is a Unix program for monitoring ARP requests and replies. The most
recent version can be obtained via anonymous FTP to ftp.ee.lbl.gov.
IP Spoofing and Sniffing 293
Spoofing the IP Routing System
On the Internet, every machine that is active at the network layer takes part in routing
decisions (bridges and repeaters are only active at lower layers). The decentralization of routing
is unlike simpler systems that limit end user machines to delivering data to a single point of
entry on the network, isolating the end user machine from the internal complexities of the
network. The essential routing decision is “Where should a datagram with a particular IP
destination address be sent?” If the destination address matches the (sub)network address of
(one of ) the machine’s interface(s), then the machine routes the datagram directly to the
destination hardware address. Otherwise, the machine selects a router to forward the datagram.
Each machine keeps a routing table containing a list of destination (sub)networks and the IP
address of the router used to forward to that (sub)network. A default router handles destinations
not specifically listed.
How Routers and Route Spoofing Work
Route spoofing can take various forms, all of which involve getting Internet machines to send
routed IP datagrams somewhere other than where they should. Route spoofing misdirects nonlocally
delivered IP datagrams and is thus somewhat similar to ARP spoofing, which misdirects
directly delivered IP datagrams. Like ARP spoofing, route spoofing can result in a denial of
service attack—datagrams do not go to the machine for which they are intended with the
result that a machine appears to be unable to communicate with the network. With a little
more sophistication, both ARP spoofing and route spoofing can simply intercept all traffic
between two pieces of the network. In the process, they can filter through the network traffic,
possibly making modifications to it, creating the illusion of a properly working network.
If you start with a single default router and other routers are available on the network, you
would expect that for some destination networks the default router would not be the best
choice. If the default router is not the best choice, it sends the datagram back over the same
network from which the datagram originated to a different router. When a router does so, it
uses the Internet Control Message Protocol (ICMP) to send a message to the machine originating
the datagram. ICMP includes a variety of types of messages. The type of ICMP message
here is a redirect message.
A redirect message essentially says “it would be best to send datagrams to a router with IP
address W.X.Y.Z when the destination network is A.B.C.D rather than using me as your
router for that destination.” A machine receiving an ICMP redirect message typically updates
its routing table to avoid making the mistake in the future. Note that the datagram did not
become lost and does not need to be re-sent because the router sending the ICMP redirect has
already forwarded the datagram to the appropriate router.
ICMP-Based Route Spoofing
If a machine ignores ICMP redirects, its datagrams are still delivered, just not as efficiently.
Turning off ICMP redirect processing is one way of avoiding the simplest of route spoofing
294 Part II: Gaining Access and Securing the Gateway
techniques—sending illegitimate ICMP redirect messages. Many systems simply process ICMP
redirect messages without checking for their validity. At the very least, a check hopefully is
made to see that the message coming from an IP address corresponds to a known router.
Note Microsoft Windows 95 and Windows NT keep a list of known routers. The first
router on the list is the default router; the next router on the list becomes the default
router in case the first one appears to be down.
Another minimal safeguard is to ensure the ARP caches on the hosts have permanent entries
for the hardware address of all legitimate routers. This prevents an ARP spoof in which a
machine masquerades as one of the routers. Such a masquerade would allow such a machine to
intercept virtually all traffic leaving the local network just like the attack described in the next
paragraph.
If a machine sends ICMP redirect messages to another machine in the network it could cause
the other machine to have an invalid routing table. At the very least, an invalid routing table
would constitute a denial of service attack—some or all non-local datagrams would not be able
to reach their destination. A much more serious situation would arise if a machine poses as a
router to intercept IP datagrams to some or all destination networks. In that case, the machine
being used to launch the attack could be multihomed and deliver the IP datagrams via its other
network interface. Otherwise, it could simply forward the datagrams to the legitimate router
over the same network interface on which they arrived (without the usual ICMP redirect to
point back to the legitimate router).
The simplest way to avoid ICMP redirect spoofing is to configure hosts not to process ICMP
redirect messages. Doing so may be difficult unless your TCP/IP software is configurable.
Some systems require source code modifications to prevent these redirect messages. Many Unix
System V machines accept a packet filter with no recompilation or relinking of the kernel.
Note ICMPinfo provides specialized monitoring of ICMP packets received by a host.
TAP is an example of a packet filter used for monitoring. It provides an example that
helps you put together your own ICMP packet filter to discard suspicious ICMP
redirects.
An alternative is to validate ICMP redirect messages, such as checking that the ICMP redirect
is from a router you are currently using. This involves checking the IP address of the source of
the redirect and verifying that the IP address matches with the hardware address in the ARP
cache. The ICMP redirect should contain the header of the IP datagram that was forwarded.
The header can be checked for validity but could be forged with the aid of a sniffer. However,
such a check may add to your confidence in the validity of the redirect message and may be
easier to do than the other checks because neither the routing table nor the ARP cache needs to
be consulted.
IP Spoofing and Sniffing 295
Understanding Routing Protocols
An alternative to relying on ICMP redirect messages is to use a routing protocol to give
machines a better idea of which routers to use for which destination networks. A routing
protocol used on an ordinary host is probably not worth the effort because it will probably take
more work than processing ICMP redirects unless multiple routers are available on the
network. Relying on ICMP messages from a default router will not be effective when the
default router fails (which is why Windows 95 and Windows NT have a list of routers as
auxiliaries). Of course, routers need routing protocols to exchange routing information with
peer routers unless you use manually configured routing tables. Routing protocols may also be
vulnerable to an attack leading to corrupted routing tables on both routers and ordinary hosts.
Two categorizations of protocols used to describe routing protocols: one categorization
separates protocols by intended use; the other categorization separates protocols by the kind of
algorithm used to determine which router to use for a given destination network.
The first categorization separates internal routing protocols and external routing protocols.
Internal routing protocols are used between routers that are within the same corporate network
and external routing protocols are used between routers that belong to different companies.
The second categorization separates protocols that require only local information—no
information except information about directly connected routers—from protocols that require
global information, or information about the status of every inter-router link in the entire
network.
The external protocols are much more limited in the information they share. The technical
name for a set of networks of a single company is an “autonomous system.” An autonomous
system consists of one or more networks that may share detailed and complete routing
information with each other, but do not share complete routing information with other
autonomous systems. External routing protocols are used to communicate routing information
between autonomous systems. Within an autonomous system, the routers have information
about how the networks are divided into subnets and about all routes to other autonomous
systems.
The internal subnet structure of one company’s network almost always should be separate from
another company’s network. One company may also want to keep its network(s) from carrying
datagrams from another company to third parties. For these reasons, external routing protocols
are designed specifically to limit the knowledge they convey and to limit the degree of trust put
in the information they provide. External protocols are typically only used on “border” routers
that connect autonomous systems to each other. At the very least, each site with a network
connected to the Internet has a single border router that connects the site with an Internet
Service Provider (ISP).
At times, companies with strategic alliances will have border routers connecting their networks
to bypass the ISP for IP datagrams that have their source in one company’s network and their
296 Part II: Gaining Access and Securing the Gateway
destination in the other company’s network. Clearly, you must limit your trust in routing
information provided from other autonomous regions. Today’s strategic partner may be
tomorrow’s primary competitor and you have no control over the level of security provided
within another autonomous region. A security breach in another autonomous network could
turn into a security breach in your own autonomous region by spoofing the internal routing
protocol and then propagating that information using an external routing protocol.
Another category of routing protocols tries to find the best route through the Internet. One
type of protocol uses the vector-distance approach in which each router advertises some
measure of “distance” or “cost” of delivering datagrams to each destination network for which
it advertises a route. Vector-distance routing protocols (also called Bellman-Ford protocols)
only require that each router be aware of the routers it can deliver to directly.
Another type of routing protocol is the link-state, also called the Shortest Path First (SPF), in
which each router has a complete picture of the corporate network. In link-state routing
protocols, each router actively tests the status of its direct links to other routers, propagates
change information about the status of such routers to all such routers, and uses an algorithm
to compute the best path to all destinations from itself. Such an algorithm is Dijkstra’s shortest
path algorithm from graph theory.
The most commonly used routing protocol is a vector-distance protocol called simply the
Routing Information Protocol (RIP). RIP predates IP: it is part of the Xerox Networking
System (XNS), which was a networking protocol in use even before IP. According to some,
RIP was introduced to IP by a graduate student at Berkeley who produced the first implementation
overnight when he realized the IP would need some form of routing protocol.
RIP works by combining information sent by active participants in the protocol with information
on hand in passive participants. Ordinary hosts participate in the protocol passively by
listening to UDP broadcasts on port 520 to get information from the routing tables for each
router on their network. The hosts then merge these tables to determine which router to use
for which destination networks.
Routers participate in protocol actively by broadcasting their entire routing table every 30
seconds. Instead of the destination network being associated with a router IP address as in the
actual routing table, these broadcasts contain destination networks and their associated hop
count. The hop count is the number of routers between the router making the broadcast and
the destination network. A router that can directly deliver to a given network would advertise a
hop count of zero to that network.
A router using exactly one intermediary router to reach a network would advertise a hop count
of one to that network. RIP treats a hop count of 16 as an infinite distance indicating an
inability to deliver to the given network. Using such a low value eliminates routing loops
quickly, but limits RIP to networks with at most 16 routers between any two hosts.
IP Spoofing and Sniffing 297
Misdirecting IP Datagrams from Hosts
If a machine is a passive participant in the RIP protocol—it listens to RIP broadcasts and uses
them to update its routing table—one simple way to route spoof is to broadcast illegitimate
route information via UDP on port 520. On a typical Unix system, port 520 is numbered so
low that special privileges are required to access it. However, it is possible for almost any
personal computer user and anyone with special privileges to use RIP to mount a route
spoofing attack on all the passive participants in RIP on a network. A particularly serious
situation arises if routers are passive participants in RIP, using it as an internal routing
protocol. If so, RIP propagates the illegitimate information throughout a company’s portion
of the Internet and the damage can be widespread.
A Case Study of a RIP-Based Route Spoof
To illustrate such an attack, assume everyone at the university is well-intentioned and the
network seems to be normal. The network as well as the major multiuser systems and many
network servers are managed by Central Computing. The university has so many individual
systems, however, that some departments, such as Computer Science, have a separate system
administration staff. Each departmental system administration staff is responsible for a set of
networked hosts and is capable of installing network wiring without the knowledge of Central
Computing. Presumably, the Computer Science staff has enough common sense not to modify
the wiring installed by Central Computing. Occasionally, however, Computer Science chafes
at what seem to be unreasonable policies imposed by Central Computing.
As you can imagine, Computer Science came up with the brilliant idea of installing a network
that does not use the wiring installed and maintained by Centralized Computing. After all,
Computer Science will have to pay Central Computing to install a network, so why not
control the network after it is installed? Of course, the network installation crew is months
behind as it is. Network administration does not seem that hard and does not seem particularly
distinct from system administration, so the Computer Science staff takes the plunge and tries
to do it themselves. They are successful and the new network works wonderfully—they are
proud of their work.
The problem comes when the Computer Science head points out that it would really be nice if
the new Computer Science network would communicate with the Central Computing
network. The solution is obvious to the Computer Science staff: install a router between the
Computer Science network and the Central Computing network. The Computer Science staff
can control the new router and use RIP to advertise connectivity between the Central Computing
network and the Computer Science network. They spend a few dollars on a new
network card for one of their workstations and it becomes a router.
At first, the system works fine. The Central Computing routers recognize the availability of
the new Computer Science network and forward datagrams in both directions via the newly
installed departmental workstation/router. Then, one day, a departmental staff member
decides to reconfigure the workstation and makes a small mistake. He inadvertently changes the
298 Part II: Gaining Access and Securing the Gateway
IP address of the interface connecting the workstation to the Computer Science network. His error
prevents machines on the Computer Science network from being able to send IP datagrams to
the workstation/router because it no longer responds to their ARP requests. Computer Science
use of the Central Computing network is light and network failures on the Central Computing
network are common, so no one in Computer Science immediately becomes worried when
they can no longer communicate.
This mistake, however, causes much more severe problems than anyone could have predicted.
The IP address installed on the Computer Science router makes it appear to belong to a subnet
of the Central Computing network. This subnet is really in a building on the far side of
campus with several Central Computing routers in between Computer Science and the router
in building with this Central Computing subnet. The Computer Science workstation/router
begins advertising, via RIP, its direct connection to this subnet with a zero hop count. The
nearest Central Computing router decides that it can get to this subnet with a hop count of
one via the Computer Science workstation/router instead of using the next Central Computing
router that says it has a hop count of three to the subnet in question. The next centrally
controlled router gets a RIP broadcast from the first and decides to begin routing datagrams
for this subnet through the first.
Within minutes, a large portion of the network can’t communicate with the Computer Science
network or the Central Computing subnet associated with the misconfigured IP address. These
subnets, however, are used by the main multiuser computers and the off-campus Internet link.
Complaints are registered with Central Computing from both directions: Computer Science
complains its connection to Central Computing is down and the users in the building across
campus complain that their link to the multiuser computers and the Internet is down. Initially,
the two problems are seen as separate failures because they involve networks in widely separated
buildings. The problem was eventually discovered when the routing tables of the routers
were examined. To solve the problem, Central Computing made a manual entry in the routing
table of the router closest to Computer Science and solved half of the problem. Computer
Science fixed the address on its router and solved the other half.
The poor Computer Science system administrator who mistyped a single digit when working
on the workstation/router is then chastised. Afterward, Central Computing figures out that
someone might do such a thing on purpose, compromising the stability and security of the
network.
Preventing Route Spoofing
To prevent spoofing in situations like the case study, you have the following two primary
options:
n Stop using RIP passively on routers.
n Use passive RIP carefully on routers.
IP Spoofing and Sniffing 299
One way to prevent RIP spoofing is to remove Central Computing routers from passive
participation in RIP and use some other routing protocol between them. The Central Computing
routers are still active participants in RIP, broadcasting routing information to hosts
every 30 seconds. Thus, misinformation from rogue RIP broadcasts is not propagated throughout
the entire organization’s network. However, individual hosts are still susceptible to attack
via RIP if they are passive participants in RIP.
Actually, the problem is not in RIP itself, but in trusting the source of RIP information. To be
secure, the passive participant in RIP must only use RIP information from trustworthy sources.
The RIP daemon usually distributed with Unix is routed, which is overly trusting. A replacement
for the standard RIP daemon is GateD, developed at Carnegie-Mellon University
(CMU), This program consults a configuration file when it starts. The configuration file,
among other things, specifies the IP address(es) of trustworthy RIP information.
The GateD software is no longer available directly from CMU. GateD updates are now
available from the GateD Consortium at Merit Networking, Inc. The most recent version may
be obtained from the World Wide Web at http://www.gated.merit.edu/~gated or through
anonymous FTP to ftp.gated.merit.edu in the directory /net-research/gated.
Rather than abandoning passive participation in RIP, you can use GateD or the equivalent on
the routers and hosts. Each router is configured to restrict its sources of trusted RIP information
to trusted routers. Similarly, GateD is used on hosts that passively participate in RIP to
protect them from rogue RIP broadcasts.
Central Computing in the preceding example still needs to decide if it will configure the router
closest to Computer Science to accept the RIP information sent to it from non-Central
Computing routers. If it does not, the workstation/router can send IP datagrams from the new
departmental subnet to the router. The router, unless specially configured not to do so, will
proceed to forward these datagrams to their destinations. When the destination host is ready to
send a reply, it will not find the Computer Science network in its routing table. The routing
table for the destination host will probably have a default router to use in such a case and send
the IP datagram containing the reply to it.
The default router will also not have an entry in its routing table for the destination of the
reply. If it does not have a default router to use for such a case, it will send an ICMP message
back to the host that was attempting to send back the reply and discard the IP datagram
containing the reply. If the routers do have default routers to use, the reply may be sent
through a long sequence of routers until it hits one that does not have a default or the time-tolive
field on the IP datagram hits zero and the datagram is discarded. In any case, the reply is
dropped by a router, an ICMP message goes to the machine that sent the reply, and no reply
reaches the Computer Science network.
If the Computer Science workstation/router is ignored by the central routers, it can still be
used. In particular it can exchange data between the Computer Science network and the hosts
on the Central Computing subnet directly connected to the Computer Science router. The
300 Part II: Gaining Access and Securing the Gateway
only problem is in getting data from subnets beyond the Central Computing controlled
routers.
To give Computer Science access to the rest of the network, Central Computing has several
options. First, manual entries for the Computer Science network can be added to the routers
closest to the Computer Science router and continue to ignore RIP broadcasts originating from
it. This is simple, neat, and clean. However, if the central routers are using a link-state routing
protocol rather than RIP to communicate among themselves, a manual entry for the Computer
Science router may make it appear that the route to the Computer Science network is
always up when, if fact, the route will occasionally be down.
A second option is to have the Central Computing router pay attention to RIP broadcasts
from the Computer Science router but limit the information extracted from the broadcast.
Specifically, the only thing that the central router really needs to know is if the workstation/
router has a working route to the Computer Science network. Even if the Central Computing
routers use a link-state protocol among themselves, the router nearest to Computer Science can
use a hybrid approach to manage the oddball workstation/router that is not participating in the
link-state protocol.
A Case Study Involving External Routing
Suppose two companies—Apple and IBM, for example—have a direct network link between
their respective research networks. Each of them has a “border” router with a direct connection
to the other border router. Each of them also has border routers connected to several different
Internet Service Providers. An external routing protocol, such as EGP, is used to exchange
routing information between the two border routers. Apple’s border router tells IBM’s border
router what internal networks should be reached from which border routers in Apple’s
autonomous system. IBM’s border router inserts these routes in its routing table. It then uses
an internal routing protocol to distribute this information within IBM’s research network.
Suppose Apple were to use EGP (the External Gateway Protocol—a name that makes it sound
like there is no other alternative), a classic external routing protocol, to advertise a route to
another company’s research network, Intel’s, for example, and IBM normally routed IP traffic
through an ISP. The IBM routing tables would not have any specific routing information for
Intel and would just use the default route to the ISP and let the ISP worry about the delivery
route. If all goes as it would normally, the IBM router sees a route to Intel through one of
Apple’s border routers. It makes a specific entry for Intel’s network in its routing table and
spreads the reachability information to other IBM routers via its internal routing protocol.
Now, Apple is getting all of the IP traffic sent from IBM to Intel. If no malice is intended in
this error, the traffic is routed out to one of Apple’s ISPs and on to Intel with only a short
added delay and extra traffic on the edge of Apple’s internal network. On the other hand, the
Apple border router could be configured to discard such datagrams and Apple would have
IP Spoofing and Sniffing 301
succeeded in a denial of service attack. The attack would be discovered quickly and would be
fairly pointless. Alternatively, a sniffer on Apple’s internal network would now be able to
intercept traffic from IBM to Intel for industrial espionage purposes.
Clearly, a good implementation of an external routing protocol needs to be a bit suspicious of
the routing information provided by routers from another organization. A database of network
addresses and their associated autonomous system numbers such as the one provided by
InterNIC would reveal to IBM’s border router that the Intel network has an autonomous
system number different from the one Apple was claiming it had when making the EGP
advertisement. With millions of networks and thousands of autonomous networks, you merely
need to store the part of the InterNIC database that specifies which network numbers are valid
for the autonomous systems that are valid peers of the border router.
Note EGP is no longer considered state-of-the-art in external routing protocols, but the
principle remains the same for all external routing protocols.
Spoofing Domain Name System Names
Some systems base trust on IP addresses; other systems base trust on Domain Name System
(DNS) names. DNS names are easier to remember and easier for most people to work with
than dotted decimal IP addresses. Just as the IP address to hardware address correspondence
may change over time, the name to address correspondence may change too as different
machines are used for a different set of tasks. Unfortunately, the use of names involves yet
another layer of software, introducing another point of vulnerability for the security of the
systems.
Understanding Name Resolution for Hosts
When software on a host needs to convert a name to an address it sends an address lookup
query to a DNS name server. When a client connects to a named host, the client needs to
convert the name to an address. The client trusts the DNS system to return the correct address
and trusts the routing system to deliver the data to the correct destination. Because virtually all
systems place trust in name server, all of the special precautions described previously in this
chapter to protect trust should be used to protect that trust. For example, if you go back and
see which hosts had permanent ARP cache entries on my Windows 95 machine, one of them
was 147.226.112.102—the DNS name server used by my machine. The name server is on the
same subnet as my machine, so it would be possible for an ARP spoofer to masquerade as the
name server and cause all sorts of mischief by misdirecting datagrams.
Similarly, when a host needs to convert an address to a name it sends a reverse lookup query to
a DNS name server. When a server accepts a connection from a prospective client, it can
determine the IP address of the prospective client from the IP datagram header. However, the
server must rely on the DNS system to perform a reverse lookup query to determine the name
of the prospective client. If trust is extended to the client on the basis of the client hostname,
302 Part II: Gaining Access and Securing the Gateway
the server is trusting the DNS system to perform this reverse lookup properly. If a DNS name
server is coerced into providing false data, the security of the system can become compromised.
Understanding DNS Name Servers
The DNS system is complex. To help you understand its structure, think of the DNS system
as a distributed database consisting of records with three fields: name, address, and record type.
The database is distributed; not all of the records are kept in a centralized location, and no
record is kept in only one location. The database is not centralized because it would be
impractical to do so—from a technical standpoint and from an administrative standpoint.
Technically, such a centralized setup would place an incredible load on one machine, which
would have to handle all the name-to-address queries for the entire Internet and create huge
amounts of long-distance network traffic. Administratively, this centralized database setup
would be horribly awkward to change because thousands of network administrators would
need to be checked for authenticity and privileges each time one of them makes a change.
Note The four record types of interest in DNS names are as follows:
n Canonical hostname to address mapping
n Alias hostname to canonical hostname mapping
n Domain name to name server name mapping
n Address to hostname mapping other record types that also exist
The primary purpose of DNS is to break down the authority for a set of names into domains.
Each domain is administered independently of each other domain. Each domain can create
subdomains that are only loosely related to the domain and administered independently of
each other. Each subdomain is responsible for a subset of the names of the whole domain. In
turn, subdomains can create subsubdomains and so on. The term “subdomain” is a relative
term between a domain and a domain that has control over a piece of the domain.
When a name server receives a query to resolve a name, it may make an authoritative reply
based on data it keeps in its own portion of the database, or it may make a non-authoritative
reply. Two types of non-local replies are possible: iterative or recursive. If the client asks for
recursive resolution (the more common choice), the name server forwards the request to a
name server it thinks is more likely to be authoritative than it is and then relays the reply back
to the client along with information indicating where the authoritative answer was found. If
the client asks for iterative resolution, the name server simply returns the address of the name
server it would have forwarded the request to and lets the client query that name server
directly.
IP Spoofing and Sniffing 303
Efficiency: Caching and Additional Information
Because name resolution is so frequent, efficiency is important. When a name server makes an
authoritative response, either to an ordinary client host or another name server, the authoritative
response includes a “time to live,” which amounts to a claim that the response will
continue to be valid for a certain amount of time. When a name server receives a reply from
another name server, it caches the reply for the amount of time specified by the “time to live.”
Some kinds of DNS replies will clearly lead to a follow-up query. For example, if a reply
includes a record specifying the name of a name server for a domain, the client probably will
soon make a query to find the address of that name server. Hence, a DNS reply not only has
sections for specifying the question, answer, and authority of the answer, but also has a section
for additional information. The name server caches additional information records along with
the answer records so that it can handle the follow-up queries efficiently without further name
server to name server queries.
How DNS Spoofing Can Happen
Suppose a name server somewhere on the Internet has been compromised by a security attack
or is being controlled by an intruder. This name server will provide authoritative responses for
some domain and all hosts on the Internet will trust those responses. The authoritative
responses can direct clients looking up the names of servers to connect to servers under the
control of the attacker rather than the legitimate servers. A falsified reverse address lookup can
fool servers attempting to determine if the IP address of a prospective client corresponds to the
name of an authorized client. Within the DNS system, absolutely nothing can be done about
such a direct attack.
A standard attempt at a defense to a DNS spoofing attack is to cross-check all responses to
reverse lookup queries by making a forward lookup query. That is, a server queries the DNS
system with the IP address of a prospective client via a reverse lookup and receives the DNS
name(s) of the prospective client. Then it takes the names and queries the DNS system for the
address(es) that corresponds to the name. Cross-checking has become a standard technique
with TCP wrapper systems.
Cross-checking may help if the attacker is clumsy and alters the name server files corresponding
to reverse lookups, but not those corresponding to forward lookups. Because these tables
are kept in separate files, they may also be kept on separate name servers. If the attacker has
compromised only one of the two name servers, the cross-checking may discover the inconsistency.
Because of potential abuses of the efficiency mechanisms in DNS, the name server may
not discover the inconsistency.
Another attempt to stifle DNS spoofing is to make iterative rather than recursive resolution
requests so that checks on consistency and authoritativeness can be made more carefully than
the name servers themselves do. In particular, when a name server makes a non-authoritative
response to an iterative query, it responds with the name of a name server more likely to be
304 Part II: Gaining Access and Securing the Gateway
authoritative than itself. If the name server has been compromised, it may direct the iterative
query to another compromised name server or it may claim authoritativeness when it does not
have authoritativeness for the domain being queried. In such cases, a check on authoritativeness
should, in principle, detect the attack.
A check on authoritativeness requires querying a root-level name server for the address of the
name servers that are authoritative for the base domain of the DNS name. One must then ask
the name server at that address for the address of the name server that is authoritative for the
next component of the DNS name and so on. Such a procedure is clearly quite time consuming
and places considerable load on root-level name servers. Also, it does not help if an
authoritative name server has become compromised; it only detects invalid claims to authority.
Note, however, that the plural was used when referring to authoritative name servers. The
DNS standards require that data for each domain be replicated on separate computers with no
common point of failure, meaning that the name servers with the duplicated data must not be
attached to the same network or obtain electrical power from a common source. It seems
unlikely that an attacker would be able to compromise all of the authoritative name servers for
a given domain.
For this reason, it might seem that you could poll all authoritative name servers when making a
query to look for a discrepancy. Unfortunately, one name server is typically designated as the
primary authority and the others as secondary authority. The secondary name servers simply
make a copy of the data in the primary on a periodic basis after the serial number on the data
for a domain has changed. If the primary authoritative name server is compromised, all the
secondary authoritative name servers will also contain invalid data after enough time has
elapsed. Meanwhile, inconsistencies may simply indicate that the secondary has not copied
legitimate changes to the data on the primary.
Efficiency Mechanisms: Downfall of DNS Security
The truly troubling part of the DNS security problem is that when a name server caches
invalid data, the invalid data can remain in the cache for a very long time and can misdirect
queries that are unrelated to the query that placed the data in the cache in the first place.
For example, suppose one query places the name of a domain and the name of its name server
in the cache as well as the name of the name server and its address. All later queries for names
in that domain will be referred to the earlier named name server at the earlier specified address.
If either of these cached records is invalid, all subsequent queries for this domain will be
directed to the wrong place. The responses to these misdirected queries will also be cached. A
compromised name server may cause errors in the caches of uncompromised name servers that
cause the uncompromised name server to provide invalid data to its clients.
Furthermore, a DNS name server can supply arbitrary information in the additional information
section of a response to any query. Thus, it may provide a perfectly valid response to the
IP Spoofing and Sniffing 305
original query, but arbitrary misinformation provided in the additional information section of
the response will be cached by a name server that queries it.
Suppose, for example, that a server (not a name server) attempts to check on the name of a
prospective client by making a query that forces the DNS system to do a reverse lookup on the
address to find the DNS name of the prospective client. A compromised name server might
provide an invalid response, which would seem to make the prospective client legitimate.
When the server attempts to cross-check this information, the name server may respond with
misinformation provided as additional information to the reverse query. If the server makes an
iterative query instead, it will not cause immediate corruption of its name server’s cache when
the compromised name server is not directly interacting with the local name server, but any
client of the local name server may trigger a request that corrupts the cache of the local name
server.
Case Study: A Passive Attack
Consider the case of Frank and Mary, who work at Widgets, Inc. Their company runs a name
server to support their DNS domain, widget.com. Their workstations consult this name server
when looking up the IP addresses of outside networks. One day, Mary is surfing the Web and
finds a reference to something that looks interesting at a site in the podunk.edu domain. Her
Web browser does a DNS query of the widget.com name server that forwards the query to the
podunk.edu name server. The widget.com name server caches the reply from podunk.edu and
supplies the requested IP address information to Mary’s Web browser.
Unfortunately, the podunk.edu name server has been taken over by a malicious college
student. When the reply goes back to the widget.com name server, additional information
fields are attached. One of these contains the name “well.sf.ca.us,” the DNS name for the
Well—an online service provider located in San Francisco. The additional information field
says that this name is associated with yet another machine controlled by the malicious college
student.
A little while later, Frank decides to telnet to his account on well.sf.ca.us and is greeted with
the usual login information and prompt. When he types in his username and password, there
is a brief pause, he is presented with his usual menus, and continues his work.
What has happened is that when Frank used telnet, it made a DNS query of the widget.com
name server. The widget.com name server found the entry for well.sf.ca.us in its cache and
returned the IP address of the college student’s machine. Frank’s machine established a
connection with the college student’s machine and it began the classic Trojan horse routine.
The student’s machine provided the login prompt and stored up the username and password.
It then turned around and used a modified version of telnet to connect to well.sf.ca.us and
passed packets back and forth between it and Frank’s machine at Widgets, Inc. The Trojan
horse created the illusion that Frank was directly connected to the Well and gave the college
student the password for Frank’s account on the Well.
306 Part II: Gaining Access and Securing the Gateway
Warning
Case Study: An Active Attack
The previous case study is a passive attack exploiting DNS weaknesses—the attacker had to
wait for someone to stumble into his trap and could not be sure who he would catch. Now
examine an active attack exploiting this same weakness, and with an attacker who targets a
specific individual. Assume that Frank, Mary, and the malicious college student at Podunk
University are involved.
Suppose Frank has set up his account at Widgets, Inc. so that he can use rlogin to connect to
it from his account on the Well (well.sf.ca.us) without being required to supply a password.
Frank trusts that the folks who run the Well are keeping his account secure (he’s probably right).
The malicious college student sends a mail message to a mail server at Widgets, Inc. addressed
to someone at Podunk University. The mail server performs a DNS lookup for podunk.edu.
The compromised name server supplies additional information in its reply that indicates not
only that well.sf.ca.us has the college student’s IP address but also that the reverse is true: the
student’s IP address corresponds to the name well.sf.ca.us.
The student then uses rlogin from his machine to connect to Frank’s account at Widgets, Inc.
His machine starts up the rlogin daemon. The rlogin daemon gets the IP address of the
incoming connection and performs a reverse query of the widget.com name server, looking for
the name that corresponds to the IP address of the college student’s machine. The widget.com
name server finds this information in its cache and replies that the IP address corresponds to
the name “well.sf.ca.us.” The college student gains access to Frank’s account at Widgets, Inc.
The only thing the logging information indicates is that Frank connected from his account on
the Well. The logs on the Well show that Frank was not logged in, however, which would tip
Frank off if he ever cross-checked them with his own logs.
rlogin is handy when you want to keep passwords out of sight of sniffers, but it
suffers from the problem outlined here. Do not use rlogin to allow access from
machines that do not have authoritative entries in the local name server database.
Otherwise, the DNS name of the accessing machine is checked to determine whether
it can be trusted to authenticate its users. A DNS spoof will subvert this check.
Defenses against DNS Spoofing
The ultimate defense against DNS spoofing is not to use the DNS. However, DNS style
naming is such a part of the way users and system administrators work that it is unthinkable to
do without it. On the other hand, many name-to-IP address mappings will not change and, in
some cases, it may make as much sense for a system administrator to configure clients to use an
IP address as it would to use a DNS name. Every place an IP address is used in place of a DNS
name is one less place the system is vulnerable to DNS spoofing.
Many operating systems simplify the process of reducing use of the DNS by having an API for
name-to-address and address-to-name mappings. The API is the same whether DNS is being
IP Spoofing and Sniffing 307
used to implement these mappings or some other standard. Some implementations of the API
will consult local data that is believed to be faster or more secure than DNS. The DNS is
consulted by these implementations of the API only if the local sources fail to give conclusive
results.
Even if the API on your system only implements the naming system via one mechanism (in
which case choosing to use DNS may be unavoidable), it may be possible to change the
implementation and reap widespread benefit immediately. In particular, many modern
operating systems use dynamic linking or shared libraries to reduce the size of executable files.
With these systems, replacing the library containing the implementation of the API with an
implementation that behaves differently will affect all programs started after the replacement.
Note When using SunOS 4.1 as shipped from Sun, for example, you can choose to have
the gethostbyname() and gethostbyaddr() functions use either the /etc/hosts file or
the NIS system. When I wanted my programs to use the DNS system instead, I had
to get source code to implement those functions using the DNS, compile it, and
include it in the shared C system library.
One way to limit the spread of invalid cached entries is to use name server software running on
many hosts in your network. If a client on one machine triggers the corruption of the cache on
one name server, the use of multiple name servers reduces the likelihood of widespread
damage. Placing a name server on every timeshared Unix host, for example, will not only
provide quick responses to local clients from the cached entries on the name server, but will
also reduce the set of hosts affected by a compromised name server consulted by a set of users
on a single timeshared host.
Other hosts can use a different name server that will not have its cache corrupted as long as the
name server on the timeshared host does not forward recursive requests to the other name
server. An active attacker targeting a particular system may make direct queries of any name
server to trigger the corruption of its cache. The technique outlined here limits damage from a
passive attacker waiting for victims to come along. You can also add checks to some name
servers so that they will respond only to select clients rather than an arbitrary client. Placing
such a limitation on a name server does not make it useful for serving requests to the outside
world but makes it more secure for internal use.
In the case study of Frank’s and Mary’s Widget company you read about earlier, the college
student would not have been so successful in his attack if Frank and Mary had been running
name servers on their own workstations. In the first case study, Mary’s cache would have been
corrupted but it would not have caused problems for Frank. In the second case, the cache for
the name server used by the mail server would have been corrupted, but, again, Frank would
not have used the corrupted cache unless his name server consulted with the same one as the
mail server.
308 Part II: Gaining Access and Securing the Gateway
The use of local name servers on workstations also may reduce total network traffic and aids in
fault tolerance. If a network-wide name server goes down, it will not create any delays for
information stored in the local name servers.
You are still at risk of a DNS spoof if local name servers on workstations are
configured to process queries recursively when they consult the network wide name
server. You are also at risk if the local name server refers its local clients to query
the network wide name server for names for which the network wide name server is
also non-authoritative. In either case, a corrupted network-wide name server cache
will affect the workstations.
The use of local name servers will limit, not eliminate, risks. Local name servers are
also subject to cache corruption. The reduced risk comes from fewer interactions
with any single cache. You should be sure local name servers only process queries
from the local machine to prevent an active attacker from directly contaminating
their cache. Hiding the workstations behind a firewall will also help.
You might also modify local name server software to be more selective about the information it
caches. Again, doing so will be of limited value if the erroneous data is coming from the cache
of an unmodified name server being consulted by the local name server. Selective caching by
doing such things as ignoring information in the additional information section of DNS
replies will certainly have an adverse impact on efficiency. Response times will also be lengthened
by any cross-checking or authority checking done by the modified name server, but
cached authority checks may ease the problem somewhat.
RFC 1788 proposes an alternative to DNS reverse lookups: all machines would respond to a
new ICMP message requesting the set of names that correspond to the IP address on which the
ICMP message was received. These responses can then be cross-checked through forward DNS
lookups. Although this proposal aims to increase the security of DNS, it is not clear how it
would have helped in the case study involving Frank and Mary described earlier. Name-based
authentication is fundamentally insecure when the name is not coming directly from a
trustworthy source.
The simplest thing a name server administrator can do to prevent a DNS spoof from corrupting
the name server cache is to have the most recent version of the operating system’s DNS
name server software. The most common implementation of a DNS name server is BIND
(Berkeley Internet Name Daemon) on Unix. Newer versions of BIND incorporate modifications
made with a more security conscious attitude than older versions. For the most current
version, consult the Web at http://www.dns.net.dnsrd/servers.html.
Warning
IP Spoofing and Sniffing 309
Tip For a more detailed treatment of the security weaknesses of the DNS system, see the
paper “Countering Abuses of Name-based Authentication” by Christoph Schuba and
Eugene Spafford of the COAST security lab at Purdue University. The COAST
department supplies useful security-related information and many useful tools.
COAST has a site on the World Wide Web at http://www.cs.purdue.edu/coast/
coast.html.
Spoofing TCP Connections
TCP builds a connection-oriented, reliable byte stream on top of IP that can send
connectionless, unreliable datagrams. It is possible for an attacker’s machine to spoof by
sending IP datagrams that have an IP source address belonging to another machine. Such
spoofing provides a mechanism for an attack on the security of any machine using IP to receive
commands.
The attacker’s machine can send IP datagrams with a forged source address to other machines
while the machine legitimately possessing that IP address is active. It can do so with no
intention of getting replies to those datagrams. The other machines will accept these datagrams
as coming from the legitimate holder of the IP source address of these forged datagrams. They
will carry out actions not actually requested by the user of the legitimate machine.
Typically, IP-based application protocols have some notion of a session with some information
exchanged at startup, which is used to identify the two parties to each another during the
active part of the session. One effect of the information exchange is that a third party cannot
pose as one of the initial two parties. If a sniffer is being used by the attacker, it becomes easy
for the attacker to pose as either party. For example, in the NFS protocol, a client will first
exchange information with the server’s mount daemon. After this exchange, the client will be
able to open and read or write files on the server by making requests of the NFS daemon. An
attacker can wait for the client to mount a file system and open a file. If the attacker sends out
an appropriately formatted UDP datagram, the server will process an NFS request and send
the results back to the client. Regardless of the client’s reaction to the unexpected reply, if the
request was a write request, the attacker will have succeeded in writing some information to
the server’s disk. If the request was a read request and the attacker has a sniffer between the
client and server, the attacker will succeed in finding out some of the contents of the disk via
the sniffer.
Through the use of datagrams with forged IP addresses, an attacker can get datagrams holding
requests accepted as valid but cannot get replies to those requests without a sniffer. In the NFS
scenario described earlier, you were using UDP and assumed the attacker had a sniffer to
obtain the credentials that allowed acceptance of the request as valid. You might assume that if
you use a connection-oriented protocol, such as TCP, you might be more secure. If you can
rule out an attacker having a sniffer between the client and the server, the attacker would be
unable to obtain the needed credentials. Unfortunately, these assumptions are valid.
310 Part II: Gaining Access and Securing the Gateway
Introduction to TCP/IP End-to-End Handshaking
To understand how an attacker might be able to send datagrams accepted as valid, you need to
understand the information exchanged between the parties of a TCP connection. A TCP
connection proceeds through three stages:
n Connection setup
n Data exchange
n Connection tear-down
TCP Connection Setup
TCP connection setup requires a three-way handshake between the two parties. Initially, one
party is passively waiting for the establishment of a connection. This passive party is said to be
“listening.” The passive party is typically a server. The other party actively opens the TCP
connection by sending the first IP datagram. The active party is typically a client. The definition
of client and server is separate from active and passive parties during the setup phase. This
discussion refers to the parties as client and server merely to be more suggestive of the typical
roles they will play later.
The client starts things off by sending a TCP header with the SYN flag set. SYN stands for
“synchronize” and refers to the synchronization of initial sequence numbers. The TCP
protocol assigns each data byte sent on a connection its own sequence number. Every TCP
header contains a sequence number field corresponding to the sequence number in the first
data byte of the field. Initial sequence numbers should be random rather than merely arbitrary.
Randomness of initial sequence number is important for handling the situation when a
connection is established, the machine on one side crashes, and then attempts to reestablish a
connection. The other machine needs to be able to detect wild out-of-range sequence and
acknowledgment numbers to close its side of the connection to the program that is no longer
running. TCP only sets the SYN flag when the connection is started.
The server replies to the SYN header with a header containing both a SYN and an ACK flag
set. ACK stands for “acknowledgment.” The SYN lets the client know its initial sequence
number—TCP connections are bi-directional. The ACK flag lets the client know that it
received the initial sequence number. Whenever the acknowledgment number field is valid,
corresponding to the sequence number of the next data byte expected, the TCP sets ACK flag.
To complete the connection, the client responds back to the server with a TCP header that
has the ACK flag set. The acknowledgment lets the server know that it is now ready to begin
receiving data. Understanding the sequence of events with SYN and ACK flags during the
establishment of a connection is also important when configuring firewalls (see Chapter 7,
“How to Build a Firewall,” for more information).
IP Spoofing and Sniffing 311
TCP Data Exchange
During normal TCP data exchange, one party will send one or more TCP/IP datagrams. The
other party will occasionally send back a TCP/IP datagram with the TCP header having the
ACK flag set to let the sender know that the data arrived. During establishment of the connection
both parties also inform the other how much room they have in their receive buffers. TCP
transmits the amount of available room in the window field of the TCP header in each
datagram sent to inform the sender how much more data may be sent before the receive buffer
fills. As the program on the receiving side empties the receive buffer, the number in the
window field increases. The acknowledgment number specifies the lowest sequence number of
a data byte that it expects to receive. The acknowledgment number plus the number in the
window field specifies the highest sequence number of a data byte that will be placed in the
input buffer when received.
Occasionally, IP datagrams will arrive out of order. When a datagram arrives earlier than
expected, the early datagram goes into the receiver’s input buffer but the receiver does not
immediately acknowledge it. When the expected datagram arrives, the receiver may acknowledge
both sets of TCP data at once. However, at this point, the receiving program will be able
to read both sets of data without waiting for any more action from the sender.
Forged TCP/IP Datagrams
To successfully forge a TCP/IP datagram that will be accepted as part on an existing connection,
an attacker only needs to estimate the sequence number to be assigned to the next data
byte to be sent by the legitimate sender. Consider the three cases of being exact, being a bit too
low with the estimate, and being a bit too high with the estimate.
If the attacker knows or successfully guesses the exact value of the next sequence number of the
next byte being sent, the attacker can forge a TCP/IP datagram containing data that will be
placed in the receiver’s input buffer in the next available position. If the forged datagram
arrives after the legitimate datagram, the receiver may completely discard the forged datagram
if it contains less data than the legitimate one. However, if the forged datagram contains more
data, the receiver will discard only the first part. The receiver will place into its input buffer the
part of the forged datagram with data bytes having larger sequence numbers than those
received in the earlier legitimate datagram.
On the other hand, if the forged datagram arrives before the legitimate datagram, the legitimate
datagram will be discarded by the receiver (at least partially).
If the attacker’s guess of the sequence number is a bit too low, it will definitely not get the first
part of the data in the forged TCP/IP datagram placed in the receiver’s input buffer. However,
if the forged datagram contains enough data, the receiver may place the last part of the forged
data in its input buffer.
312 Part II: Gaining Access and Securing the Gateway
If the attacker’s guess of the sequence number is a bit too high, the receiver will consider it to
be data that simply arrived out of order and put it into its input buffer. Some of the data bytes
at the end of the forged datagram may have sequence numbers that do not fit in the current
window, so the receiver will discard these. Later, the legitimate datagram arrives to fill in the
gap between the next expected sequence number and the sequence number of the first forged
data byte. Then, the whole forged datagram is available to the receiving program.
Sniffing + Forging = Trouble
Clearly, one way to obtain an estimate of the sequence numbers in a TCP/IP connection is to
sniff the network somewhere between the client and the server. An attacker could possibly be
controlling more than one machine along this path so the machine doing the sniffing need not
be the machine doing the forging.
If a machine on the same physical network as the legitimate sender does the forging, then
routers will not have much of a chance of stopping the forged datagram. The only possible
place to stop the forged datagram would be at the router on the forger’s network, where a
discrepancy might be detected between the hardware address of the legitimate sender and the
forger.
If a machine on the same physical network as the receiver does the forging, the receiver would
also have the opportunity to note such a discrepancy. If the forging occurs on neither of the
two endpoint networks, then the opportunity to stop the forged datagram decreases. However,
in many cases attackers would only have access to physical networks attached to routers with a
single legitimate source network. You can protect your network from being the source of a
forging attack by configuring these routers not to forward datagrams with impossible IP
network addresses.
One particular case deserves special note. If both endpoints are on the same physical network,
an attacker might be bold enough to forge a datagram from another physical network. Because
only the destination address needs examination to deliver a datagram, the datagram could get
to the receiver via the normal routing mechanisms. However, the router would have the
opportunity to detect the forged datagram by noting that the IP source network address
matches the IP destination network address. Datagrams with matching source and destination
network addresses should not be allowed into the router if the network address matches that of
an internal network.
Note See the files for CERT Advisory CA:95-01 to find out more about actual attacks
based on this special case.
TCP/IP Forging without Sniffing
With four billion possible initial sequence numbers, it should be extremely difficult to guess a
valid current sequence number for a TCP/IP connection. However, this assumes assignment of
IP Spoofing and Sniffing 313
the initial sequence numbers in a completely random manner. If an attacker establishes a TCP/
IP connection with the receiving end of another TCP/IP connection, the attacker also obtains
an initial sequence number from the receiving end. If the initial sequence numbers of the two
connections are related in some way, the attacker will be able to compute the initial sequence
number of the other connection.
When the attacker has the initial sequence number of the connection, the next and final step is
to estimate how much TCP/IP data has been sent to the receiver. This estimate added to the
initial sequence number estimates the current sequence number. An estimate of the current
sequence number goes into a forged TCP/IP header.
Some TCP/IP implementations use initial sequence numbers generated by a simple random
number generator that generates numbers in a fixed order. If the attacker knows this ordering,
the attacker can establish a connection at about the same time as the connection to be spoofed.
Knowing that connection’s initial sequence number will provide enough information to
narrow the plausible initial sequence numbers for the connection to a very few instead of four
billion. The way to prevent this attack is to use a TCP/IP implementation that does a good job
of generating random initial sequence numbers.
Terminal Hijacking: An Example of TCP/IP Forging
Imagine the following everyday scenario at my workplace. Many workers use windowing
systems such as the X Window system or Microsoft Windows to start terminal sessions to one
or more of the timesharing systems. The most convenient way to use these systems is to have
them start automatically. With this setup, many of the windows will have idle terminal sessions
using a TCP/IP-based protocol such as telnet, tn3270, or rlogin.
In fact, some of these sessions never are used after they start. Some of these remain idle for days
or weeks at a time. An attacker with ordinary access to one of the timesharing systems can
easily detect the time any particular worker starts a terminal session by monitoring the set of
users on the timeshared system.
Immediately after the targeted worker logs in to the timesharing system, the attacker determines
the initial sequence number of the TCP/IP connection used for the terminal session.
The attacker may have received this number using a sniffer running on another host on the
network or by taking advantage of the deterministic pattern of initial sequence numbers.
Next, the attacker estimates the number of data bytes the worker’s terminal session has sent to
the timesharing system. Typically, the worker types in at most a username, password, and a
command or two by this time. By simply estimating the number of data bytes to be between
zero and one hundred, the attacker will be close enough to hit the window of acceptable
sequence numbers.
To do some real damage, the attacker simply has to insert a sequence of characters in the data
stream that correspond to a command being typed in at the command prompt. Just to be sure
314 Part II: Gaining Access and Securing the Gateway
that the command is accepted as an entire command, the attacker could place characters in
the data stream that would exit a typical application and get to new command line. Putting
“rm -rf *” on the command line in Unix deletes all files in the current directory along with all
files in all subdirectories of the current directory.
If the attacker really wants to spook the worker, he or she could wait to see if the terminal
session will remain idle overnight while the worker is gone, the office locked, and all the
physical security mechanisms in place to ensure no one enters the office.
If the attacker determines the exact initial sequence number for the terminal session, the
command is executed by the timesharing system in the worker’s absence. The echo of the
presumed keystrokes will appear in the worker’s terminal window along with a new command
prompt indicating that the command has completed. Imagine the surprise the worker gets
when he or she shows up in the morning and sees this terminal window. Imagine the horror of
realizing that backups were done shortly after the command executed and that a whole backup
period of work has been lost.
Reducing the Risks of TCP/IP Spoofing
One way to reduce the threat of this sort of attack is to simply log out of all terminal sessions
before they become inactive and only start up terminal sessions when you need them. Inactive
terminal sessions are the easiest to hijack.
A second way to reduce the threat is to use an implementation of the terminal session protocol
(telnet or rlogin) that inserts extra terminal protocol data transmitted to the timesharing
machine. Doing so will not fool a sniffer, but it will make it harder for the attacker who is
guessing that the terminal protocol sends only a small, relatively fixed amount of data before
the user begins typing commands.
A third way to reduce the threat is to avoid the use of terminal session protocols between the
user’s desktop and the timesharing machine. For example, with the X Window system, you
have the option of running the windowing program (for example, xterm) on the desktop and
then starting a remote terminal session with the windowing program.
You can also run the windowing program on the timesharing machine and use the X protocol
to have the window displayed on your desktop. Using X may introduce its own set of security
problems, but convincing the timesharing system to accept forged data as keystrokes requires a
somewhat messier process and it is much harder to make a good guess at a current sequence
number without a sniffer.
A fourth way to reduce the threat of TCP/IP spoofing is to use an encryption-based terminal
protocol. The use of encryption does not help prevent an attacker from making a good guess at
the current sequence number. If the attacker is using a sniffer, the sniffer knows the exact
IP Spoofing and Sniffing 315
current sequence number. Encrypted protocols, however, can limit the consequences of
introducing forged data on the connection. Unless the encryption is broken, the receiver will
accept the data as valid but the command interpreter will not be able to make sense of it.
When the legitimate sender gets acknowledgments for the forged data it will become confused
and may reset the TCP/IP connection, causing the terminal session to be shut down.
The only way to deal with this threat completely with current standardized technology is to use
a combination approach. Initial sequence numbers must be unpredictable and fall throughout
the full range of four billion. TCP/IP data must be encrypted so that unencrypted or
misencrypted data will not be confused with valid commands. You also must simply live with
the possibility that an attacker may cause a TCP/IP connection to reset because of garbage
injected into a connection by an attacker with a sniffer.
Using Next-Generation Standard IP Encryption Technology
To stop IP address spoofing, you must use encryption on the entire data portion of an IP
datagram, including the TCP header. By doing so, you prevent a sniffer from determining the
sequence numbers of the TCP connection. See RFCs 1825-1830.
One IP encryption technique currently in use is SwIPe. It encrypts the TCP header and the
TCP data, preventing sniffers from finding sequence numbers. This program is considerably
more sophisticated than that, and goes well beyond the scope of the kind of coverage provided
in this chapter. Because it requires kernel modification the source code is not of general
interest; if you are interested, however, use anonymous FTP to access ftp.csua.berkeley.edu
/pub/cypherpunks/swIPe/.
An emerging standardized IP encryption technique is specified in “RFC 1825: Security
Architecture for the Internet Protocol.” It is a standards-track specification for an option to the
current version of IP (IPv4) and a required part of the next generation of IP (Ipv6). RFC 1825
specifies two parts: an authentication header (AH) and an encapsulating security payload.
These two parts may be used separately or in combination. The use of the authentication
header prevents the forging of IP datagrams. The encapsulated security payload encrypts the
content of the IP datagram, including the TCP header.
The following RFCs detail a proposed standard authored by R. Atkinson of the Naval Research
Laboratory and published in August 1995:
n RFC 1825: Security Architecture of the Internet Protocol
n RFC 1826: IP Authentication Header
n RFC 1827: IP Encapsulating Security Payload
316 Part II: Gaining Access and Securing the Gateway
The following RFCs detail the mechanisms behind RFC 1826 and RFC 1827, respectively,
and are part of the proposed standard. They were authored by Metzger, Karn, and Simpson
and published in August 1995. RFC 1851 and RFC 1852, published in September 1995, are
follow-ups to these papers. The newer RFCs are, as of this writing, still “experimental” rather
than part of a “proposed standard.”
n RFC 1828: IP Authentication using Keyed MD5
n RFC 1829: The ESP DES-CBC Transform
How to Build a Firewall 317
How to Build a Firewall
C H AP T E R C H AP T E R C H A P T E R C H A PT ER C H A PTE R CHA P TER CHAPT E R C H A P T E R
E
7
very day, people use insurance to protect their valuables
from fire or theft. Businesses protect themselves from
intellectual theft through patents and trademarks.
Because the use of global networking has increased the
information flow and dependence upon our computing
technology, Information System Managers have realized
the need to protect their computing systems, networks,
and information from damage and theft. Although
there are several ways this can be achieved, the most
prevalent is the use of a firewall.
318 Part II: Gaining Access and Securing the Gateway
When considering construction and building architecture, the “fire wall” is used to protect the
building structure from damage should a fire erupt within the structure. The concept applies
in a similar fashion to computer technology, except that often we are attempting to protect
ourselves from the fire that exists outside our “wall.” A firewall, per se, consists of a machine or
machines, that are separated from both the external network, such as the Internet, and the
internal network by a collection of software that forms the “bricks” within the firewall.
Strictly speaking, a firewall can be defined as a collection of components that is placed between
two networks. Collectively, the following properties exist:
n All traffic in either direction must pass through the firewall.
n Only traffic authorized by the local security policy will be allowed to pass.
n The firewall itself is immune to penetration.
This chapter examines the Trusted Information Systems (TIS) Firewall Toolkit, that is
provided as a consturction set for building a firewall. The chapter discusses how to get it,
compile it, and the major building blocks in the package.
The TIS Firewall Toolkit
The Firewall Toolkit produced by Trusted Information Systems, also known as TIS, is not a
single integrated package, but a set of tools that are used to build a firewall. For this reason, it
is not for everyone who intends to construct and operate a firewall. Consequently, it is difficult
to produce documentation that can be used in all situations.
Remember that a firewall is intended to be the security policy your organization has chosen to
develop and support. In this chapter, you will examine how to compile the TIS Toolkit, and
configure the various components that make up the kit. By the end of the chapter, you will
know the techniques and issues concerned with the construction of a firewall using this
Toolkit.
Understanding TIS
The TIS Firewall Toolkit is a collection of applications that, when properly assembled with a
security policy, forms the basis of a firewall. This Toolkit is available as freeware to the Internet
user community. As such, the Toolkit has gained a wide following, and is in use worldwide.
The Toolkit is not a single integrated package like most commercial packages. Rather, it is a set
of tools for building a number of different types of firewalls. Because of its inherent flexibility,
a wide variety of combinations are possible regarding the installation and configuration of the
TIS Toolkit. As such, this chapter explains what the Toolkit is and how the underlying
How to Build a Firewall 319
technology works. With this knowledge in hand, and a copy of the Toolkit in another, you
will be able to configure the Toolkit for your protection.
Where to Get TIS Toolkit
The TIS Toolkit is available from the site ftp.tis.com, in the directory /pub/firewalls/toolkit.
The filename is fwtk.tar.Z.
After you retrieve the file, it must be uncompressed and extracted from the tar archive. While
you’re at the TIS anonymous FTP site, you may want to examine its collection of firewall
documentation and information. After uncompressing and extracting the archive, the directory
structure illustrated in figure 7.1 is created.
When the files are extracted from the tar archive, the next task is to compile them. Before
compiling, any site specific changes should be made to firewall.h and the Makefile.config files.
Major issues that you need to consider are the installation location of the Toolkit—defaults to
/usr/lcoal/etc—and how the library and compiler are to be configured.
Note Most users may experience difficulties compiling the X-gw proxy. The reason for this
is this program’s dependencies on the X Window System Athena Widget set. If you
do not have this widget set, you will experience problems in getting this application
to compile.
auth
config
ftp-gw
http-gw
lib
netacl
plug-gw
rlogin-gw
smap
smapd
tn-gw
x-gw
flog
netscan
portscan
progmail
reporting
gate-ftp
misc
aix-auth
ftpd
login-sh
login-ts
syslog
reg
admin
client
server
tools
fwtk Figure 7.1
The TIS Toolkit directory
structure.
320 Part II: Gaining Access and Securing the Gateway
Compiling under SunOS 4.1.3 and 4.1.4
There should be little difficulty in compiling the TIS Toolkit under the SunOS 4.1.3 and
4.1.4 operating systems. There are no changes required from the base configuration to achieve
a successful compile. After the archive is extracted, a successful compile can be achieved even
without modifying the Toolkit configuration.
Compiling under BSDI
No significant surprises occur when you compile the Toolkit under BSD/OS Version 2.0 from
BSD, Inc. A few changes do need to be made to ensure the compile is successful, however.
First, the Makefiles are not in the correct format for the make command. In TIS, the Makefiles
use the syntax:
include Makefile.config
This syntax is not understood by the make command that is shipped with BSD/OS. To resolve
the problem you can edit each of the Makefiles by hand, or use the program fixmake. The
include statement also requires a small change. The required format looks like this:
.include <Makefile.config>
If you edit the Makefiles by hand, this is what the change looks like. However, you can also
use the fixmake command to correct the syntax of the Makefile by removing the include
statement and including all of the required instructions in one Makefile.
While you are tweaking, it is a good idea to make the following additional changes. No other
changes are necessary.
CC= gcc
COPT= -g -traditional -DBSDI
Code Changes
Several issues need to be considered when you compile the Toolkit components. These issues
revolve primarily around the definition of sys_errlist. To resolve the problem, you must change
the declaration of sys_errlist in all places where it is declared. For example, sys_errlist is defined
in the code as:
extern char *sys_errlist[];
Commenting out the line using the C comment symbols (/* */) results in a successful compile
of the source code:
/* extern char *sys_errlist[]; */
How to Build a Firewall 321
Installing the Toolkit
After the compile process completes successfully, you must install the files in the appropriate
place. The easiest way to install these files is to use the command:
make install
This command uses information in the Makefile to place the objects in the correct place. The
process is shown in the following command sequence:
pc# make install
if [ ! -d /usr/local/etc ]; then mkdir /usr/local/etc; fi
for a in config lib auth smap smapd netacl plug-gw ftp-gw tn-gw rlogin-gw http-g
w; do ( cd $a; echo install: ‘pwd‘; make install ); done
install: /usr/tis/fwtk/config
if [ ! -f /usr/local/etc/netperm-table ]; then cp netperm-table /usr/local
/etc; chmod 644 /usr/local/etc/netperm-table; fi
install: /usr/tis/fwtk/lib
install: /usr/tis/fwtk/auth
if [ -f /usr/local/etc/authsrv ]; then mv /usr/local/etc/authsrv /u
sr/local/etc/authsrv.old; fi
cp authsrv /usr/local/etc
chmod 755 /usr/local/etc/authsrv
if [ -f /usr/local/etc/authmgr ]; then mv /usr/local/etc/authmgr /u
sr/local/etc/authmgr.old; fi
cp authmgr /usr/local/etc
chmod 755 /usr/local/etc/authmgr
if [ -f /usr/local/etc/authload ]; then mv /usr/local/etc/authload
/usr/local/etc/authload.old; fi
cp authload /usr/local/etc
chmod 755 /usr/local/etc/authload
if [ -f /usr/local/etc/authdump ]; then mv /usr/local/etc/authdump
/usr/local/etc/authdump.old; fi
cp authdump /usr/local/etc
chmod 755 /usr/local/etc/authdump
install: /usr/tis/fwtk/smap
if [ -f /usr/local/etc/smap ]; then mv /usr/local/etc/smap /usr/local/etc/
åsmap.old; fi
cp smap /usr/local/etc
chmod 755 /usr/local/etc/smap
install: /usr/tis/fwtk/smapd
if [ -f /usr/local/etc/smapd ]; then mv /usr/local/etc/smapd /usr/local/etc/
åsmapd.old; fi
cp smapd /usr/local/etc
chmod 755 /usr/local/etc/smapd
install: /usr/tis/fwtk/netacl
if [ -f /usr/local/etc/netacl ]; then mv /usr/local/etc/netacl /usr
/local/etc/netacl.old; fi
cp netacl /usr/local/etc
chmod 755 /usr/local/etc/netacl
install: /usr/tis/fwtk/plug-gw
if [ -f /usr/local/etc/plug-gw ]; then mv /usr/local/etc/plug-gw /u
322 Part II: Gaining Access and Securing the Gateway
sr/local/etc/plug-gw.old; fi
cp plug-gw /usr/local/etc
chmod 755 /usr/local/etc/plug-gw
install: /usr/tis/fwtk/ftp-gw
if [ -f /usr/local/etc/ftp-gw ]; then mv /usr/local/etc/ftp-gw /usr
/local/etc/ftp-gw.old; fi
cp ftp-gw /usr/local/etc
chmod 755 /usr/local/etc/ftp-gw
install: /usr/tis/fwtk/tn-gw
if [ -f /usr/local/etc/tn-gw ]; then mv /usr/local/etc/tn-gw /usr/local/etc/tn-
ågw.old; fi
cp tn-gw /usr/local/etc
chmod 755 /usr/local/etc/tn-gw
install: /usr/tis/fwtk/rlogin-gw
if [ -f /usr/local/etc/rlogin-gw ]; then mv /usr/local/etc/rlogin-g
w /usr/local/etc/rlogin-gw.old; fi
cp rlogin-gw /usr/local/etc
chmod 755 /usr/local/etc/rlogin-gw
install: /usr/tis/fwtk/http-gw
if [ -f /usr/local/etc/http-gw ]; then mv /usr/local/etc/http-gw /usr/local/etc
/http-gw.old; fi
cp http-gw /usr/local/etc
chmod 755 /usr/local/etc/http-gw
With the Toolkit successfully installed and compiled, the next step is the security policy and
the configuration of the Toolkit.
Preparing for Configuration
When configuring the Toolkit, the first step is to turn off all unnecessary services that are
running on the system that will affect your firewall. This requires that you have some level of
Unix knowledge regarding the system startup procedure and services for your system. For
example, you may have to:
n Edit the /etc/inetd.conf file
n Edit the system startup scripts such as /etc/rc /etc/rc2.d/* and others
n Edit the operating system configuration to disable unnecessary kernel-based services
You can use the ps command to see that a number of services are in operation. The following
output shows such services on a sample system:
pc# ps -aux
USER PID %CPU %MEM VSZ RSS TT STAT STARTED TIME COMMAND
root 442 0.0 1.7 144 240 p0 R+ 3:34AM 0:00.04 ps -aux
root 1 0.0 1.7 124 244 ?? Is 3:02AM 0:00.08 /sbin/init --
root 2 0.0 0.1 0 12 ?? DL 3:02AM 0:00.01 (pagedaemon)
root 15 0.0 6.0 816 888 ?? Is 3:03AM 0:00.47 mfs -o rw -s 1
How to Build a Firewall 323
root 36 0.0 1.5 124 220 ?? Ss 3:03AM 0:00.21 syslogd
root 40 0.0 1.2 116 176 ?? Ss 3:03AM 0:00.06 routed -q
root 77 0.0 0.5 72 72 ?? Ss 3:03AM 0:00.34 update
root 79 0.0 1.6 284 232 ?? Is 3:03AM 0:00.08 cron
root 85 0.0 0.3 72 36 ?? I 3:03AM 0:00.01 nfsiod 4
root 86 0.0 0.3 72 36 ?? I 3:03AM 0:00.01 nfsiod 4
root 87 0.0 0.3 72 36 ?? I 3:03AM 0:00.01 nfsiod 4
root 88 0.0 0.3 72 36 ?? I 3:03AM 0:00.01 nfsiod 4
root 91 0.0 1.0 96 144 ?? Is 3:03AM 0:00.07 rwhod
root 93 0.0 1.3 112 180 co- I 3:03AM 0:00.05 rstatd
root 95 0.0 1.3 128 192 ?? Is 3:03AM 0:00.07 lpd
root 97 0.0 1.3 104 184 ?? Ss 3:03AM 0:00.13 portmap
root 102 0.0 1.6 332 224 ?? Is 3:03AM 0:00.05 (sendmail)
root 108 0.0 1.4 144 200 ?? Is 3:03AM 0:00.11 inetd
root 117 0.0 2.1 228 300 co Is+ 3:03AM 0:00.90 -csh (csh)
root 425 0.0 2.0 156 292 ?? S 3:33AM 0:00.15 telnetd
chrish 426 0.0 2.1 280 304 p0 Ss 3:33AM 0:00.26 -ksh (ksh)
root 440 0.4 1.9 220 280 p0 S 3:34AM 0:00.17 -su (csh)
root 0 0.0 0.1 0 0 ?? DLs 3:02AM 0:00.01 (swapper)
pc#
By editing the /etc/inetd.conf file so that it resembles the following output, you can reduce the
number of active processes. This reduces the load on the system and, more importantly, does
not accept TCP connections on unnecessary ports.
#
# Internet server configuration database
#
# BSDI $Id: inetd.conf,v 2.1 1995/02/03 05:54:01 polk Exp $
# @(#)inetd.conf 8.2 (Berkeley) 3/18/94
#
# ftp stream tcp nowait root /usr/libexec/tcpd ftpd -l -A
# telnet stream tcp nowait root /usr/libexec/tcpd telnetd
# shell stream tcp nowait root /usr/libexec/tcpd rshd
# login stream tcp nowait root /usr/libexec/tcpd rlogind -a
# exec stream tcp nowait root /usr/libexec/tcpd rexecd
# uucpd stream tcp nowait root /usr/libexec/tcpd uucpd
# finger stream tcp nowait nobody /usr/libexec/tcpd fingerd
# tftp dgram udp wait nobody /usr/libexec/tcpd tftpd
# comsat dgram udp wait root /usr/libexec/tcpd comsat
# ntalk dgram udp wait root /usr/libexec/tcpd ntalkd
# pop stream tcp nowait root /usr/libexec/tcpd popper
# ident stream tcp nowait sys /usr/libexec/identd identd -l
# #bootp dgram udp wait root /usr/libexec/tcpd bootpd -t 1
# echo stream tcp nowait root internal
# discard stream tcp nowait root internal
# chargen stream tcp nowait root internal
# daytime stream tcp nowait root internal
# tcpmux stream tcp nowait root internal
# time stream tcp nowait root internal
# echo dgram udp wait root internal
# discard dgram udp wait root internal
324 Part II: Gaining Access and Securing the Gateway
# chargen dgram udp wait root internal
# daytime dgram udp wait root internal
# time dgram udp wait root internal
# Kerberos authenticated services
#klogin stream tcp nowait root /usr/libexec/rlogind rlogind -k
#eklogin stream tcp nowait root /usr/libexec/rlogind rlogind -k -x
#kshell stream tcp nowait root /usr/libexec/rshd rshd -k
# Services run ONLY on the Kerberos server
#krbupdate stream tcp nowait root /usr/libexec/registerd registerd
#kpasswd stream tcp nowait root /usr/libexec/kpasswdd kpasswdd
The reason for turning off all these services is to reduce the likelihood that your system will be
compromised while the firewall is being installed and configured. You should also use the
console to perform the initial setup and configuration of the firewall. With the /.etc/inetd.conf
file updated, inetd must be signaled to know that some changes have been made. This signal is
generated using the command:
kill -1 inetd.pid
The process identifier (PID) can be procured, and inetd restarted by using this command
sequence:
pc# ps -aux | grep inetd
root 108 0.0 1.4 144 200 ?? Is 3:03AM 0:00.11 inetd
pc# kill -1 108
To ensure that the services are turned off, you can attempt to connect to a service offered by
inetd:
pc# telnet pc ftp
Trying 204.191.3.150...
telnet: Unable to connect to remote host: Connection refused
pc#
Now that the inetd services are disabled, disable other services that are part of the system start
up files and the kernel. Some of these services are system specific, which might require some
exploration. Nevertheless, try to find the following services and processes and turn them off.
gated, cgd pcnfsd rwhod
mountd portmap sendmail
named printer timed
nfsd rstatd xntpd
nfsiod
How to Build a Firewall 325
Tip While timed, which is when the NTP time server process is turned off, you should
configure your firewall to get time updates via an NTP server. This allows your
firewall clock to have accurate time, which may prove invaluable should you take
legal action.
After turning off these daemons, the process table on the sample system now looks like this:
pc.unilabs.org$ ps -aux
USER PID %CPU %MEM VSZ RSS TT STAT STARTED TIME COMMAND
chrish 89 2.3 2.1 280 304 p0 Ss 4:24AM 0:00.25 -ksh (ksh)
root 1 0.0 1.7 124 244 ?? Is 4:18AM 0:00.07 /sbin/init --
root 2 0.0 0.1 0 12 ?? DL 4:18AM 0:00.01 (pagedaemon)
root 15 0.0 3.2 816 464 ?? Is 4:19AM 0:00.08 mfs -o rw -s 1
root 36 0.0 1.5 124 220 ?? Ss 4:19AM 0:00.17 syslogd
root 71 0.0 0.5 72 72 ?? Ss 4:19AM 0:00.05 update
root 73 0.0 1.8 284 256 ?? Is 4:19AM 0:00.05 cron
root 75 0.0 1.3 140 192 ?? Ss 4:19AM 0:00.04 inetd
root 84 0.0 2.0 220 292 co Is+ 4:19AM 0:00.26 -csh (csh)
root 88 0.1 2.0 156 292 ?? S 4:24AM 0:00.13 telnetd
root 0 0.0 0.1 0 0 ?? DLs 4:18AM 0:00.00 (swapper)
chrish 95 0.0 1.6 136 232 p0 R+ 4:24AM 0:00.02 ps -aux
pc.unilabs.org$
The ps command output shown now represents a quiet system. For clarification, the mfs
command in the ps output is for a memory-based temporary file system on the BSDI Version
2.0 Operating System. However, this does not really list the actual services that are provided
on this system. In the sample inetd.cof file presented earlier, virtually all the available network
services were disabled. This is illustrated in the output of the netstat command:
pc# netstat -a
Active Internet connections (including servers)
Proto Recv-Q Send-Q Local Address Foreign Address (state)
tcp 0 0 pc.telnet stargazer.1037 ESTABLISHED
tcp 0 0 *.telnet *.* LISTEN
udp 0 0 *.syslog *.*
Active Unix domain sockets
Address Type Recv-Q Send-Q Inode Conn Refs Nextref Addr
f0764400 dgram 0 0 0 f0665c94 0 f0665214
f074e480 dgram 0 0 0 f0665c94 0 0
f0665c00 dgram 0 0 f0665780 0 f06d6194 0 /dev/log
pc#
The tools directory in the Toolkit distribution includes a utility called portscan, which probes
a system to determine what TCP services are currently being offered. This program probes the
ports on a system and prints a list of available port numbers, or service names. The output of
the command is shown here:
326 Part II: Gaining Access and Securing the Gateway
pc# ./portscan pc
7
9
13
19
21
23
25
...
512
513
shell
1053
1054
1055
1056
1057
pc#
This command shows what ports were available prior to reducing the available services. After
reducing those services by shutting off the entries in inetd.conf and the startup files, the system
now offers the following ports:
pc# ./portscan pc
21
23
pc#
With the host almost completely shut down from the network, the next step is to configure
TIS Toolkit components.
Configuring TCP/IP
For TIS to be effective as a firewall, the system on which it is running must not perform
routing. A system that has two or more network interfaces must be configured so that it does
not automatically route packets from one interface to another. If this occurs, services that are
being constructed with the TIS Toolkit will not be used.
IP Forwarding
To receive any real benefits from a firewall installation, you need to make sure IP forwarding
has been disabled. IP forwarding causes the packets received on one interface to be retransmitted
on all other applicable interfaces. To help illustrate IP forwarding, suppose you are
considering setting up a firewall on the system in figure 7.2.
How to Build a Firewall 327
This machine has two interfaces: one is for the local area network, which has an IP address of
204.191.3.150. The other interface is for the wide area network, and is a PPP link using an IP
address of 198.53.166.62. When IP forwarding is enabled, any packets received on the LAN
interface of this machine that are destined for a different network are automatically forwarded
to the PPP link. The same is true for packets on the PPP link. If the packets received on the
PPP link are for the rnet, they will be transmitted on the ethernet interface in the machine.
This type of arrangement is unsuitable for a firewall. The reason is that the firewall will still
pass unlogged and unauthenticated traffic from either direction. Consequently, there is little or
no point to going through this exercise if you leave IP forwarding enabled.
Disabling IP forwarding usually requires that a new kernel be configured. The reason for this is
that the process of IP disabling involves changing some kernel parameters. Table 7.1 lists
parameters that must be changed for the identified operating systems.
Table 7.1
Disabling IP Forwarding
Operating System Parameter
BSDI Version 2.0 Make sure GATEWAY is commented out in the kernel configuration
files.
SunOS 4.1.x Run adb on the kernel to set IP_forwarding to -1, and save the
modified kernel image. Alternatively, modify /usr/kvm/sys/netinet/
in_proto.c ) to set the variable to -1 by default and rebuild the
kernel.
After making the required changes to the kernel parameters, you need to build a new kernel,
install it, and reboot. This removes any configured IP forwarding, and enables you to maximize
the capabilities of the Toolkit. After IP forwarding is removed, all traffic requests either
into or out from the private network need to be made through the proxy servers on the
firewall.
Modem
Server
204.191.3.150
198.53.166.62
Figure 7.2
Multihomed machines.
328 Part II: Gaining Access and Securing the Gateway
The netperm Table
The netperm table, found in /usr/local/etc/netperm-table, is the master configuration file for
all the components in the Trusted Firewall Toolkit (netacl, smap, smapd, ftp-gw, tn-gw, and
plug-gw). When an application in the Toolkit starts, it reads its configuration and permissions
information from netperm-table and stores it in an in-memory database. Saving the information
in an in-memory database allows the information to be preserved, even after a chroot
system call is used to reset the directory structure.
The permissions/configuration file is organized into rules. Each rule is the name of the
application that rule applies to, followed by a colon. Multiple applications can be targeted by a
single rule by separating the names with commas, or wildcarding them with an asterisk. When
an application extracts its configuration information, it only extracts the rules that apply to it,
preserving the order in which they appeared in the file. The following sequence lists a sample
set of rules for the smap and smapd application.
# sample rules for smap
smap, smapd: userid 4
smap, smapd: directory /mail/inspool
smap: timeout 3600
Note Comments regarding the rules can be inserted in the configuration file by starting
the line with “#” as the first character. As with any configuration file or program, the
more comments that are used, the easier it is later to maintain the rules.
When an application has matched a rule, the rule is translated into whitespace delimited
strings for later use. Typically, the application retrieves matching rules based on the first word
in the rule; the remaining words serve as parameters for that particular clause. For the smap
client and smapd server in the preceding example, the rules specify the userid to use when the
application executes, the directory clause identifies the location of files, and the timeout clause
indicates how long the server or client will wait before assuming that the remote end is “hung.”
Special modifiers are available for each clause. For example, if the clause begins with a permitor
deny- modifier, the rule is internally flagged as granting or revoking permission for that
clause. This means that if an application retrieves all of its configuration clauses for “hosts,” the
following will be returned:
netacl-in.ftpd: permit-hosts 192.33.112.117 -exec /usr/etc/in.ftpd
netacl-in.ftpd: permit-hosts 198.137.240.101 -exec /usr/etc/in.ftpd
netacl-in.ftpd: deny-hosts unknown
netacl-in.ftpd: deny-hosts *
Although this example may not seem clear, keep in mind that each application within the
Toolkit has its own unique set of clauses. The default configuration for each of the
application’s clauses and examples are presented with the applications description.
How to Build a Firewall 329
When assembling your netperm-table file, you might want to consider a few conventions.
These conventions promote consistency in the file, and help produce a more readable and
maintainable rules list. When a hostname or host IP address is specified in the rule, matching
is performed based on whether the pattern to which the address will be matched is all digits
and decimal points, or other characters.
To better explain this process, consider this configuration rule:
netacl-in.ftpd: permit-hosts 192.33.112.117 -exec /usr/etc/in.ftpd
When a connection is received and this rule is applied, the IP address of the remote machine
will be used to match this rule. If the pattern to match consists entirely of digits and decimals,
matching is performed against the IP address; otherwise, it is performed against the hostname.
If the rule specifies a host- or domain name, as in the following rule
netacl-in.ftpd: permit-hosts *.istar.net -exec /usr/etc/in.ftpd
then the remote system’s name is used to validate against the rule, not the IP address. To
prevent any vulnerability from DNS spoofing, it is highly recommended that the configuration
rules be bound to IP addresses. When matching, asterisk wildcards are supported, with syntax
similar to the shell’s, matching as many characters as possible.
When the application attempts to resolve an IP address to domain name and the reverse
lookup fails, the hostname is set to “unknown.” Otherwise the real hostname of the remote
system is returned. When the Domain Name resolution is performed by the firewall, a check is
made to ensure that the IP address for the DNS name returned by the reverse lookup is the
same.
This setup prevents DNS spoofing. If a hostname for this IP address cannot be located in the
DNS system, the hostname is set to “unknown” and a warning is logged. This permits rules to
operate on hosts that didn’t have valid DNS mappings. This means that it is possible to allow
any host in the Internet to pass through your firewall, or access certain services (or both) as
long as reverse DNS, or IN-ADDR.ARPA addressing is properly configured.
Configuring netacl
netacl is a network access control program; it provides a degree of access control for various
TCP-based services available on the server. For example, you may want to have telnet access to
the firewall for authorized users. The netacl program and the appropriate rules enable you to
create this setup. The same capabilities are possible for any of the available services, including
ftp and rlogin.
The netacl program is started through inetd; after inetd performs some checks, netacl allows or
denies the request for service from the remote user/system. When configuring the inetd.conf
file for netacl, it is important to know that netacl accepts only one argument: the name of the
330 Part II: Gaining Access and Securing the Gateway
service to be started. Any other arguments that are intended for the service do not go in the
inetd.conf file. Consider this example:
ftp stream tcp nowait root /usr/local/etc/netacl ftpd
In this situation, when a connection request is accepted by inetd for an ftp service, the netacl
program is started with an argument of ftpd. Before the ftpd daemon is started, the request is
validated using the rules found in the netperm-table. The rule name for netacl consists of the
keyword netacl- followed by the name of the service. For example, if the named service is ftpd,
the rule name consists of netacl-ftpd, as in the following:
netacl-ftpd: permit-hosts 204.191.3.147 -exec /usr/libexec/ftpd -A -l
When you examine these two lines—the first from inetd.conf and the second from netpermtable—
you can see that the command-line arguments and other information required for the
daemon is found in netperm-table.
As with all the TIS Toolkit components, arguments and descriptive keywords are permitted
in the authentication clause. As seen in the preceding command output, only the host
204.191.3.147 is permitted access on the firewall to run the ftpd command. It does, however,
mean that FTP requests can be sent through the firewall. Table 7.2 lists various keywords that
are understood by the netacl program.
Table 7.2
The netacl Rules and Clauses
Service Keyword Description
netacl permit-hosts IP Address Specifies a permission rule to allow the named
or hostname hosts. This is a list of IP addresses or hostnames.
deny-hosts IP Address Specifies a permission rule to deny the named
or hostname hosts. This is a list of IP addresses or hostnames.
The denial of service is logged via syslogd.
-exec executable [args] Specifies a program to invoke to handle the
service. This option must be the final option in
the rule. An -exec option must be present in
every rule.
-user userid userid is the numeric UID or the name from a
login in /etc/passwd that the program should use
when it is started.
-chroot rootdir Specifies a directory to which netacl should
chroot(2) prior to invoking the service program.
This requires that the service program be present,
and the pathname for the executable be relative to
the new root.
How to Build a Firewall 331
Acceptance or rejection of the service is logged by the syslog facility. The messages printed in
the syslog files resemble those shown here:
Oct 4 00:56:12 pc netacl[339]: deny host=stargazer.unilabs.org/204.191.3.147
service=ftpd
Oct 4 01:00:20 pc netacl[354]: permit host=stargazer.unilabs.org/204.191.3.147
service=ftpd execute=/usr/libexec/ftpd
The first line in the log report indicates that the host stargazer.unilabs.org was denied access to
the ftp service through the netacl program. The second line of output indicates that the ftp
request was accepted and allowed. Notice that the logging information only specifies the
service that was originated, and from where it originated. It does not show who the user
connected to. The sample netacl rules that follow illustrate the use of some of the parameters
and clauses for netacl.
netacl-in.telnetd: permit-hosts 198.53.64.*-exec /usr/etc/in.telnetd
netacl-in.ftpd: permit-hosts unknown -exec /bin/cat /usr/local/etc/noftp.txt
netacl-in.ftpd: permit-hosts 204.191.3.* -exec /usr/etc/in.ftpd
netacl-in.ftpd: permit-hosts * -chroot /home/ftp -exec /bin/ftpd -f
In this example, netacl is configured to permit telnet only for hosts in a particular subnet.
Netacl is configured to accept all FTP connections from systems that do not have a valid DNS
name (“unknown”) and to invoke cat to display a file when a connection is made. This
provides an easy and flexible means of politely informing someone that they are not permitted
to use a service. Hosts in the specified subnet are connected to the real FTP server in /usr/etc/
in.ftpd but all connections from other networks are connected to a version of the FTP server
that is already chrooted to the FTP area, effectively making all FTP activity “captive.”
Connecting with netacl
When netacl is configured for the service that you want to provide, you should test it to ensure
that it is working. Testing requires verifying rules configured for that service to ensure that
they are in fact operating as they should. Consider the following rules:
netacl-ftpd: permit-hosts 204.191.3.147 -exec /usr/libexec/ftpd -A -l
This rule says that FTP connections will be accepted only from the host 204.191.3.147. When
this connection is received, the ftpd server with the appropriate arguments will be started. This
can be evaluated by connecting to the FTP server from the authorized host, as illustrated here:
C:\ >ftp pc
Connected to pc.unilabs.org.
220 pc.unilabs.org FTP server (Version wu-2.4(1) Fri Feb 3 11:30:22 MST 1995)
ready.
User (pc.unilabs.org:(none)): chrish
331 Password required for chrish.
Password:
230 User chrish logged in.
ftp>
332 Part II: Gaining Access and Securing the Gateway
As you can see from this output, the connection from the authorized machine to the target
system did in fact work. This could further be validated by examining the syslog records for
the target system where any transfers may in fact be logged. The availability of this feature
depends on the implementation of the ftpd that is in use at your site.
Another security breach you want to avoid is granting a non-authorized system a connection.
To illustrate, consider the exchange:
pc# ftp pc
Connected to pc.unilabs.org.
421 Service not available, remote server has closed connection
ftp>
The connection is initially established, but after netacl has performed verification of the rules,
it finds that the host is not permitted access, and the connection is closed. On the target
system, a deny informational message is written to the syslog and to the console:
Oct 4 02:53:12 pc netacl[1775]: deny host=pc.unilabs.org/204.191.3.150
åservice=ftpd
In this case, the remote system received no information other than the connection has been
closed. Meanwhile, the system administrator knows that the remote has been attempting to
gain access. If this occurs enough, some other action may be required against the remote user.
Such a blunt response to an unauthorized attempt to gain access might not be the most
appreciated. For this reason, you might be wise to consider a rule like the one shown here:
netacl-ftpd: permit-hosts 204.191.3.147 -exec /bin/cat /usr/local/etc/noftp.txt
In this case, a user who attempts to connect from the site 204.191.3.147 will not be refused a
connection; he or she will just not get what they want. With this configuration, you can log
the connection, and tell the user that he or she is not permitted access to the requested service.
For example, when you attempt to connect to your server, the /usr/local/etc/noftp.txt file
displays this response:
C:\ >ftp pc
Connected to pc.unilabs.org.
**** ATTENTION ****
Your attempt to use this server’s FTP facility is not permitted due to
organizational security policies. Your connection attempt has been logged
and recorded.
Use of the FTP Services on this machine is restricted to specific sites.
If you believe that you are an authorized site, please contact Jon Smith
at 555-1212 ext 502, or e-mail to ftpadmin@org.com.
How to Build a Firewall 333
Connection closed by remote host.
C:\ >
Any type of message can be displayed here instead of allowing access to the requested service.
This “denial” can be for system administration purposes, for example, or because of maintenance.
Restarting inetd
Remember that after each reconfiguration of the inetd.conf file, inetd must be restarted. To do
this, you must find the Process ID or PID number for inetd and send a SIGHUP to it. The
following commands are used in this process:
Signalling inetd
pc# ps -aux | grep inetd
root 1898 0.0 0.2 120 28 p3 R+ 10:46AM 0:00.02 grep inetd
root 75 0.0 1.5 140 220 ?? Is 11:19AM 0:00.25 inetd
pc# kill -1 75
pc#
When inetd has been signaled with the -1, or SIGHUP, it rereads the /etc/inetd.conf file and
applies the new configuration immediately.
Note You might have to send a second SIGHUP signal to inetd to make the changes
permanent. Specific systems are IRIX and some versions of SunOS.
This is the most common problem that system administrators have when changing the
configuration file. They make the change, but forget to restart inetd.
Configuring the Telnet Proxy
The telnet proxy, tn-gw, provides passthrough telnet services. In many circumstances, a system
administrator may not want to allow telnet access through the firewall and either into or out of
the private network. The telnet proxy does not provide the same type of access to the firewall
host as the netacl program. The intent behind using Telnet with netacl is to allow access to the
firewall host. With the proxy, the intent is to provide passthrough telnet with logging control.
Because of the dilemma of allowing remote administrative access and establishing a proxy
telnet, it is common for the firewall administrator to run the real telnetd on a TCP port other
than the default, and to place the proxy on the standard TCP port. This is accomplished by
editing the /etc/services file and changing it to be something similar to the following:
334 Part II: Gaining Access and Securing the Gateway
telnet 23/tcp
telnet-a 2023/tcp
These changes are only effective after /etc/inetd.conf has been changed to reflect the configuration
shown here:
telnet stream tcp nowait root /usr/local/etc/tn-gw tn-gw
telnet-a stream tcp nowait root /usr/local/etc/netacl telnetd
When an incoming connection is received on the telnet port with this configuration, the tn-gw
application is started. When tn-gw receives a request, it first verifies that the requesting host is
permitted to connect to the proxy. Access to the proxy is determined by the rules established in
the netperm-table. These rules resemble those seen previously for the netacl application.
However, there are application-specific parameters. The rule clauses for tn-gw are listed in
table 7.3.
Table 7.3
tn-gw Rules and Clauses
Option Description
userid user Specify a numeric user-id or the name of a password file entry. If
this value is specified, tn-gw will set its user-id before providing
service.
directory pathname Specifies a directory to which tn-gw will chroot(2) prior to
providing service.
prompt string Specifies a prompt for tn-gw to use while it is in command mode.
denial-msg filename Specifies the name of a file to display to the remote user if he or she
is denied permission to use the proxy. If this option is not set, a
default message is generated.
timeout seconds Specifies the number of seconds of idleness after which the proxy
should disconnect. Default is no timeout.
welcome-msg filename Specifies the name of a file to display as a welcome banner upon
successful connection. If this option is not set, a default message is
generated.
help-msg filename Specifies the name of a file to display if the “help” command is
issued. If this option is not set, a list of the internal commands is
printed.
denydest-msg filename Specifies the name of a file to display if a user attempts to connect
to a remote server for which he or she is not authorized. If this
option is not set, a default message is generated.
How to Build a Firewall 335
authserver hostname Specifies the name or address of a system to use for network
[portnumber [cipherkey]] authentication. If tn-gw is built with a compiled-in value for the
server and port, these values will be used as defaults but can be
overridden if specified in the authserver rule. If support for
DES-encryption of traffic is present in the server, an optional
cipherkey can be provided to secure communications with the
server.
hosts host-pattern Rules specify host and access permissions.
[host-pattern2...] [options]
The initial configuration for the tn-gw application is shown here.
tn-gw: denial-msg /usr/local/etc/tn-deny.txt
tn-gw: welcome-msg /usr/local/etc/tn-welcome.txt
tn-gw: help-msg /usr/local/etc/tn-help.txt
tn-gw: timeout 3600
tn-gw: permit-hosts 204.191.3.* -dest *.fonorola.net -dest !* -passok -
åxok
Note If any of the files identified in the denial-msg, welcome-msg, help-msg, or denydestmsg
clauses are missing, the connection will be dropped as soon as a request is
made for that file.
This configuration informs users when they are or are not allowed to connect to the proxy
server, and when connections are denied due to their destination. The timeout line indicates
how long the telnet connection can be idle before the firewall will terminate it. The last line
establishes an access rule to the tn-gw application. This rule and the optional parameters are
discussed shortly. A sample connection showing the host denial message is shown as follows:
$ telnet pc
Connecting to pc ...
**** ATTENTION ****
Your attempt to use this server’s telnet proxy is not permitted due to
organizational security policies. Your connection attempt has been logged
and recorded.
Use of the telnet proxy Service on this machine is restricted to specific sites.
Option Description
336 Part II: Gaining Access and Securing the Gateway
If you believe that you are an authorized site, please contact Jon Smith
at 555-1212 ext 502, or e-mail to ftpadmin@org.com.
Connection closed by foreign host
$
If the host is permitted to converse with the tn-gw application, tn-gw enters a command loop
where it accepts commands to connect to remote hosts. The commands available within the
tn-gw shell are listed in table 7.4.
Table 7.4
tn-gw Commands
Command Description
c[onnect] hostname [port] Connects to a remote host. Access to the remote host may be
telnet hostname [port] denied based on a host destination rule.
open
x[-gw] [display/hostname] This command invokes the X Windows gateway for a connection
to the user’s display. By default, the display name is the connecting
machine followed by :0.0, as in pc.myorg.com:0.0. The x-gw
command is discussed later in this chapter.
help Displays a user-definable help file.
?
quit Exits the gateway.
exit
close
Connecting through the Telnet Proxy
When a permitted host connects to the proxy, it is greeted by the contents of the welcome
file—configured in the tn-gw options—and by a prompt. At the prompt, tn-gw expects to
receive one of the commands listed in table 7.4. When the connect request is made, the access
rules are applied to the destination host to confirm that a connection to that host is permitted.
If the connection is permitted, the connection is made. A successful connection is shown as
follows:
Welcome to the URG Firewall Telnet Proxy
Supported commands are
c[onnect] hostname [port]
x-gw
help
exit
How to Build a Firewall 337
To report problems, please contact Network Security Services at 555-1212 or
by e-mail at security@org.com
Enter Command>c sco.sco.com
Not permitted to connect to sco.sco.com
Enter Command>c nds.fonorola.net
Trying 204.191.124.252 port 23...
SunOS Unix (nds.fonorola.net)
login:
In this output you can see that a telnet connection is established to the firewall, from which
the tn-gw application is started. The user first attempts to contact sco.sco.com, which is
denied. A second connection request to nds.fonorola.net is then permitted. This sequence begs
the question “what’s the difference?” The answer is that host destination rules are in force.
This means that a given system may be blocked through options on the host command in the
tn-gw rules.
Host Access Rules
The host rules that permit and deny access to the telnet proxy can be modified by a number of
additional options, or rules that have other host access permissions. As seen in table 7.3, the
host rules are stated:
tn-gw: deny-hosts unknown
tn-gw: hosts 192.33.112.* 192.94.214.*
These statements indicate that hosts that cannot be found in the DNS in-addr.arpa domain are
unknown, and therefore denied, or that hosts connecting from the network 192.33.112 and
192.94.214 are allowed to connect to the proxy. Optional parameters, which begin with a
hyphen, further restrict the hosts that can connect to the proxy, or where the remote host can
connect to behind the firewall.
Earlier output showed that the connect request to sco.scolcom was denied by the proxy
because the user was not permitted to connect to that host. This was configured by using the
rule:
tn-gw: permit-hosts 204.191.3.* -dest *.fonorola.net -dest !* -passok -xok
This rule states that any host from the 204.191.3 network is allowed to contact any machine in
the fonorola.net domain, but no others. This example illustrates the -dest option, which
restricts which hosts can be connected. The -dest parameter, described in table 7.5 with the
other optional parameters, is used to specify a list of valid destinations. If no list is specified,
then the user is not restricted to connecting to any host.
338 Part II: Gaining Access and Securing the Gateway
Table 7.5
Host Access Rules
Rule Description
-dest pattern
-dest { pattern1 pattern2 ... } Specifies a list of valid destinations. If no list is specified, all
destinations are considered valid. The -dest list is processed in
order as it appears on the options line. -dest entries preceded
with a “!” character are treated as negation entries.
-auth Specifies that the proxy should require a user to authenticate
with a valid user id prior to being permitted to use the gateway.
-passok Specifies that the proxy should permit users to change their
passwords if they are connected from the designated host. Only
hosts on a trusted network should be permitted to change
passwords, unless token-type authenticators are distributed to
all users.
The -dest options are applied in the order that they appear in the line. Consequently, in the
example used so far in this chapter, if the machine you are connecting to is sco.sco.com, then
the first option describing a machine in the fonorola.net domain is not matched. This means
that the second destination specification is matched, which is a denial. The “!” is a negation
operator, indicates that this is not permitted. The end result is that users on the 204.191.3
network can only connect to systems in the fonorola.net domain, and no others.
The use of an IP address instead of a domain name does not alter the rule. Before the connection
is permitted, the tn-gw application attempts to validate the IP address. If the returned
host matches one of the rules, then the rule is applied. Otherwise, the connection is dropped.
Verifying the Telnet Proxy
The operation of the proxy rules can be determined by attempting a connection through
each of the rules, and verifying whether the correct files are displayed when information is
requested. For example, if a user connects to tn-gw and enters the help command, does
the user get the requested information? Are the restricted sites in fact restricted?
This verification is accomplished by exercising each of the rules. For example, consider the
following rule:
tn-gw: permit-hosts 204.191.3.* -dest *.fonorola.net -dest !*
How to Build a Firewall 339
The operation of this rule can be easily verified, once it is clear what is being controlled. This
rule says: “Permit any host in the 204.191.3 network to connect to any machine in the
fonorola.net domain. All connections to machines outside that domain are denied.”
This can be easily verified by using telnet to contact tn-gw and attempting to connect to a site
within the fonorola.net domain space, and then attempting to connect to any other site. If the
fonorla.net site is accessible, but no other site is, then it is safe to say that the telnet is working
as it should.
For example, consider the following rules:
tn-gw: permit-hosts 204.191.3.* -dest *.fonorola.net -dest !* -passok -xok
tn-gw: deny-hosts * -dest 204.191.3.150
If the connecting host is from the 204.191.3 network, access is granted to the proxy, but the
user can only connect to the sites in the fonorola.net domain. The second line says that any
host attempting to access 204.191.3.150 will be denied. Should the second line be first in the
file, access to the proxy server itself would not be permitted.
Tip When entering the rules in the netperm-table, remember to write them from least to
most specific. Or, write them in order of use, after conducting some traffic analysis
to determine where the traffic is going. This can be difficult and time-consuming.
This type of configuration is advantageous because it ensures that the firewall cannot be
accessed through the proxy, and leaves the telnet server available through the netacl program,
which has been configured to listen on a different port.
Even though the firewall host is not available through the proxy, it can still be accessed
through the netacl program and the telnet server running on the alternate port.
Configuring the rlogin Gateway
The rlogin proxy provides a service similar to the telnet proxy with the exception of access
being provided through the rlogin service rather than telnet. Typically, access to the firewall
using rlogin would not be allowed because of the large number of problems that can occur.
Consequently, the only access to the firewall host is through telnet.
Regardless, there are requirements that justify the need for an rlogin proxy service. For
example, the rlogin service provides rules for additional authentication that allow the connection
to be granted without the user logging in like telnet. The process of configuring the
relogin-gw rules is similar to the tn-gw application; they both support the same options. The
rules that are available for the rlogin-gw service are listed and explained in table 7.6.
340 Part II: Gaining Access and Securing the Gateway
Table 7.6
rlogin-gw Rules and Clauses
Option Description
userid user Specifies a numeric user id or the name of a
password file entry. If this value is specified, tngw
will set its user id before providing service.
directory pathname Specifies a directory to which tn-gw will
chroot(2) prior to providing service.
prompt string Specifies a prompt for tn-gw to use while it is in
command mode.
denial-msg filename Specifies the name of a file to display to the
remote user if he or she is denied permission to
use the proxy. If this option is not set, a default
message is generated.
timeout seconds Specifies the number of seconds the system
remains idle before the proxy disconnects.
Default is no timeout.
welcome-msg filename Specifies the name of a file to display as a
welcome banner after the system successfully
connects. If this option is not set, a default
message is generated.
help-msg filename Specifies the name of a file to display if the “help”
command is issued. If this option is not set, a list
of the internal commands is printed.
denydest-msg filename Specifies the name of a file to display if a user
attempts to connect to a remote server from
which he or she is restricted. If this option is not
set, a default message is generated.
authserver hostname [portnumber [cipherkey]] Specifies the name or address of a system to use
for network authentication. If tn-gw is built with
a compiled-in value for the server and port, these
will be used as defaults but can be overridden if
specified on this line. If support exists for DESencryption
of traffic in the server, an optional
cipherkey can be provided to secure communication
with the server.
hosts host-pattern [host-pattern2...] [options] Specifies host and access permissions.
How to Build a Firewall 341
To illustrate the use of these rules to configure the rlogin-gw service, examine these sample
rules from the netperm-table file:
rlogin-gw: denial-msg /usr/local/etc/rlogin-deny.txt
rlogin-gw: welcome-msg /usr/local/etc/rlogin-welcome.txt
rlogin-gw: help-msg /usr/local/etc/rlogin-help.txt
rlogin-gw: denydest-msg /usr/local/etc/rlogin-dest.txt
rlogin-gw: timeout 3600
rlogin-gw: prompt “Enter Command>”
rlogin-gw: permit-hosts 204.191.3.* -dest *.fonorola.net -dest !* -passok -xok
rlogin-gw: deny-hosts * -dest 204.191.3.150
Note If any of the files identified in the denial-msg, welcome-msg, help-msg, or denydestmsg
clauses are missing, the connection will be dropped as soon as a request is
made for that file.
These rules are virtually identical to the rules used to configure the tn-gw. One exception is
that the rlogin-gw is configured to display a different message when a connection request is
made for a restricted host. The following output shows the different message for rlogin:
pc# rlogin pc
Welcome to the URG Firewall Rlogin Proxy
Supported commands are
c[onnect] hostname [port]
x-gw
help
password
exit
To report problems, please contact Network Security Services at 555-1212 or
by e-mail at security@org.com
Enter Command>c fox.nstn.ca
*** ATTENTION ***
You have attempted to contact a restricted host from this rlogin proxy. Your
attempt has been recorded.
To report problems, please contact Network Security Services at 555-1212 or
by e-mail at security@org.com
Enter Command>
Now that the proxy configuration is finished, you can move on to establishing a connection.
342 Part II: Gaining Access and Securing the Gateway
Connecting through the rlogin Proxy
Connecting through the rlogin proxy requires a process similar to the telnet proxy. A connection
is first established with the firewall host, and then the user requests a connection to the
remote host. The commands supported by the rlogin proxy are the same as for the telnet
proxy. The following output illustrates a successful connection to a remote host using the
rlogin proxy:
pc.unilabs.org$ rlogin pc
Welcome to the URG Firewall Rlogin Proxy
Supported commands are
c[onnect] hostname [port]
x-gw
help
password
exit
To report problems, please contact Network Security Services at 555-1212 or
by e-mail at security@org.com
Enter Command>c nds.fonorola.net
Trying chrish@204.191.124.252...
Password:
Last login: Sun Oct 8 20:33:26 from pc.unilabs.org
SunOS Release 4.1.4 (GENERIC) #1: Wed Sep 13 19:50:02 EDT 1995
You have mail.
bash$
The user enters the name of the host he or she wants to connect to by using the c[onnect]
command followed by the hostname. Before the connection request is made, the local
username is added to the left of the requested hostname. Consequently,
nds.fonorola.net
becomes
chrish@nds.fonorola.net.
The establishment of the rlogin session to the remote host is then a matter of how the service is
configured on that host. Remember that the name or IP address of the gateway must be in the
.rhosts file because that is the machine where the connection is coming from, not the real
originating host.
Host Access Rules
Host rules that permit and deny access to the rlogin proxy can be modified by a number of
additional options, or rules. The host rules use the following format:
rlogin-gw: deny-hosts unknown
rlogin-gw: hosts 192.33.112.* 192.94.214.*
How to Build a Firewall 343
In this example, hosts that cannot be found in the DNS in-addr.arpa domain are unknown,
and therefore denied; hosts connecting from the networks 192.33.112 and 192.94.214 are
allowed to connect to the proxy. The optional parameters—each begin with a hyphen—
further restrict the hosts that can connect to the proxy by limiting where they can connect.
Verifying the rlogin Proxy
Operation of the rlogin proxy is verified by attempting to circumvent the established rules, and
checking to see that the text from each of the configured files displays when it should display.
For example, if your security policy states that only certain hosts can connect to the rlogin
proxy, you must test this from each of the permitted hosts, and also test the connection from a
few hosts that are not permitted.
Each rule for rlogin-gw must be carefully evaluated to ensure that it is operating as it should.
Configuring the FTP Gateway
The FTP proxy allows FTP traffic through the firewall to either private or public networks.
The FTP proxy executes when a connection is made to the FTP port on the firewall. From
there a connection could be made to the firewall, although it is not a good idea to allow FTP
traffic to the firewall on the default port. It is better to have an additional FTP server system
running elsewhere. A more secure setup would be to run the FTP server processes when a
connection is made to a different port. By not publishing this port number, it is harder to have
an FTP session established directly on the firewall.
Remember that the FTP service is found on port 21 as stated in the /etc/services file. To
change this, edit the /etc/services file and add a second ftp entry called ftp-a—like the telnet-a
that was added earlier. Establish this ftp-a service to run on a different port, such as 2021. The
new /etc/services file will look like:
ftp 21/tcp
ftp-a 2021/tcp
This new ftp-a entry only addresses part of the problem. The /etc/inetd.conf file is where the
actual specification is made regarding which service is executed when a connection is made.
The trick here is to configure the inetd.conf file so that when a connection is made to the ftp
port, the ftp-gw application is started. When a connection is made to the ftp-a port, the real
ftp server is started through the netacl application:
# ftp stream tcp nowait root /usr/libexec/tcpd ftpd -l -A
ftp stream tcp nowait root /usr/local/etc/ftp-gw ftp-gw
ftp-a stream tcp nowait root /usr/local/etc/netacl ftpd
Three entries for the FTP service are included here to illustrate a point. The first entry is
uncommented out and is provided to show you how the FTP service was originally started.
344 