programming] [can] be applied to software engineering, and in particular to the systems analysis stage of software development" (Kowalski, 1984,p. 92). He credits the Japanese with drawing world attention to the potential for logic programming, especially when combined with parallel processing machines.It is easy to appreciate the potential benefits that may accrue from a sensible marriage of parallel hardware and logic programming. It stems from the earlier point that logic is purely declarative, and so programming in logic banishes control flow concerns from the domain of the programmer. At a general level, we can appreciate that if programs are declarative objects (i.e. the traditional notion of specific sequence of control flow through the algorithm no longer exists) then there ought to be great opportunities for parallel processing of components of the algorithm—because the typically strict requirements on sequential processing have gone. Let me illustrate this with reference to the (much) earlier example (Chapter 1) of sorting a list. For the sorting program to be correct when it generates a list y from any input list x, two relationships must hold:SORT(x) › y where,y is a permutation of xandy is orderedAs a statement in logic no notion of sequencing is involved. It is simply that if both relationships hold true (i.e. permutation and ordered), then the SORT procedure is correct. There is no implication that permutation must be checked before (or after) ordered—they just must both be true.  Page 122So, if this sort of logical statement were executable by a computer, we would expect a parallel-processing computer to be able to execute it more quickly as it could check the truth of the two relationships in parallel. Hence, the interest in parallel architectures together with logic programming.We have seen how some control flow constraints do have to be observed in Prolog programming. Prolog is a sequential, logic-program-ming language (which is, of course, something of a contradiction in terms), but it's only a first cut at a tricky problem. There has been a great deal of work on the development of parallel Prologs (e.g. PARLOG) that should allow some exploitation of the promises of parallelism in logic programming, in the near future. As another example, in the Godel language of Burt, Hill and Lloyd (1990) every effort has been made to remedy the problems that the inter-tanglement of declarative logic and procedural interpretation cause in Prolog. A program in Godel will have a simple declarative meaning and the procedural interpretation is a deduction from it—i.e. the logical meaning is primary and the necessary computational procedures should not distort nor undermine it as they do in sequential Prolog.Kowalski (1984) summarizes the general situation with the diagrams in Figures 5.8, 5.9, and 5.10. I trust that the first two are now completely self explanatory, and that 5.10 makes sense even it is not clear what this ''new software technology" is exactly. We shall now see Kowalski's elaboration of the this "new software technology.""So what is this new software technology? The new technology allows knowledge to be represented explicitly. It disentangles what the computer knows from how the computer uses it." (Kowalski, 1984, p.92). And this is clearly a restatement of our earlier discussion of how logic programming allows the separation of declarative information (Kowalski's "what the computer knows" or "knowledge") from control structure information ("how the computer uses it").I don't like to keep throwing wet blankets on exciting notions, like the notion that programming in Prolog is programming in logic, but I must interject just one more dampening observation. I refer to the widespread, almost universal, cavalier use of the word 'knowledge'. Modern computer technologists, expert systems enthusiasts in particular, have  Page 123Figures 5.8 "The conventional view"              5.9 "The Japanese view"succeeded in stripping this word of most of the depth and richness of association that it used to possess, and indeed still possesses for that rapidly shrinking portion of humanity that has not heard of expert systems. In short, when 'knowledge' is mentioned, fight off the welter of rich and complex connotations that try to force themselves upon your consciousness, and keep telling yourself that it only means a set of facts and rules. And in the current context it means an axiom set in logic—i.e. facts and rules that specify only absolute truths in some timeless, abstract, closed world.  Page 124Figure 5.10 "The Kowalski view" all from Kowalski, 1984, AI and Software Engineering, Datamation, vol. 30. no. 10, pages 94 and 95To continue: Kowalski mentions the structured analysis techniques that are typically employed in the development of large-scale, practical software systems. As an example, he gives the software development life cycle of DeMarco (1979)—Figure 5.11.  Page 125Figure 5.11"The software development life cycle of DeMarco" from Kowalski, 1984, p.98He draws our attention to the bottom half of the life cycle diagram—i.e. user requirements analysis, functional specification, design, and implementation. Systems analysts often clarify user requirements by recourse to data flow diagrams. A data flow diagram (DFD)is a graphical representation of information flow and the transformations that are applied to it as data is input, and moves through to the output of a program. A DFD representation of the SORT procedure is given in Figure 5.12.Kowalski reminds us that DFDs are a particularly convenient way of communicating with the user. He then points out that DFDs can be interpreted as an alternative graphical syntax for logic programming. Thus the DFD, given above, is an alternative representation for the rule:an ordered list y can be computed from a list x if y can be permuted from x and y is ordered  Page 126Figure 5.12 A DFD of the sorting problemThis sort of equivalence "shows that logic-based programming is not necessarily programming, or even formal specification... logic-based programming is an executable analysis of the user requirement. Therefore it can assist the conventional software development life cycle at the earliest possible stage. The user requirement can be analyzed and executed before we derive a functional specification, design, or program" (Kowalski, 1984, p. 94).Clearly, Kowalski is claiming that logic-based programming allows us to strengthen the software design process right at the outset even before we reach the specification stage. The simple equivalence between DFDs (which experience has shown to be a good notation for sorting out user requirements) and logic-like rules has opened the possibility of mechanically executing, and thus checking and exploring, user requirements before they become transformed into a specification.  Page 127Kowalski goes on to elaborate on the benefits that accrue from the state of affairs in which logic is a programming language (if only it were!—but it's close). A major weakness of structured systems analysis is that "users don't know what they want; and often, when they do, they don't need what they want" (p. 94). But having an executable representation of the result of requirements analysis allows us to sort out the "wants" and "needs" of the user by prototyping. By running trial representations of what the user seems to want, the hidden (and missing) implications can be explicitly exposed, thereby speeding up the process of homing in on a statement of the necessary and sufficient requirements for the proposed system. And, on top of all this, because logic is the basic notation in use, we can expect to reap considerable benefits from the fact that logic is a well-defined and well-understood formal notation—e.g. we can expect to prove that the requirements satisfy certain criteria.Kowalski sums up his "new logic-based software technology"(p. 94) as follows:I have concentrated attention on those applications of AI technology to software engineering that revolutionize the software life cycle, and which in many cases do away with program implementation, and even system specification (p. 100).But, of course, you, the practicing software engineer, are not about to witness a revolution as logic-based software technology sweeps across the world of software engineering. Why is this? It is because the technology has some problems, although they were not mentioned.To run through just a few reasons why (apart from pig-headed resistance to new ideas) logic-based software technology is not about to take over: first, logic is not a programming language (and it's not totally clear that it ever can be)—Prolog is, but logic isn't. Secondly, there is always the awkward problem that comes with neat formal techniques of distinguishing what can be done in principle from what can be done in practice on realistically sized software. In this particular case there are questions of whether a rule-based representation of a large requirements DFD is too cumbersome or inefficient to actually execute. And whether a logical execution of it (basically a theorem-proving exercise) will yield the sort of information that is needed to properly explore the users wants and needs. Related to this question of whether the logical manipulation can really tell you what you need to know, there is the further question of how much of the essentials of requirements analysis will be missed in a rule-based representation of a DFD. A DFD may be the hard-copy representation that  Page 128forms the basis for discussion between user and systems analyst, but how many of the problems are exposed and resolved by information explicitly in the DFD? Are none of the crucial exchanges being instigated and settled in terms of difficult-to-formally-represent use of English combined with impossible-to-formally-represent use of body language (particularly hand waves and head nods)? It seems unlikely, particularly if you subscribe to the Rich and Waters (1988) view that requirements can never be complete.Suffice it to say that there are some neat ideas coming from the logic-based software technologists, but they are not yet solutions to the major problems of the practical software engineer. Use of a logic-like specification language which is also machine executable provides us with, for example, a useful scheme for rapid prototyping. This sort of benefit will be extended and others will surely emerge in the wake of Prolog's successors.We have now looked at two representative examples of new methodologies for software development. They both explicitly recognize the need for prototyping in some guise or other to help sort out what the user really wants and how the software engineer is going to supply it. Gone from both methodologies is the simple linearity of more conventional methodologies—although they both try to hang on (especially the logic-based technology) to an exclusively left-to-right flow of system development—i.e. flow from specification through implementation to testing. The SAT core is still quite sound within both paradigms (although it is likely to be closer to SAV for the logic-based one).Both schemes tacitly admit that there is much more to building a software system which accurately reflects user needs than having an agreed specification. For such a necessarily complex object will hide undesired features of system behavior from, as well as falsely promise desired characteristics of the final system to, both the user and the analyst. Its implications must then be explicitly explored. But notice that both methodologies try to pack the exploratory features at the front end. Clearly, it is more cost effective to sort out the problems as early as possible. And it is traditional to take the specification as the keystone of the whole development process, so you can't really mess about after you've settled that. But the point that I want to make is, nice as it may be to do all the exploration at the front end, will it solve the essential problems for the development of practical AI software? I think not, because we are building a behav-iorally-adequate approximation to some ideal and hence behavioral feedback is the primary force driving system evolution. But more on this anon.  Page 129For the moment, I'll complete this brief survey of responses to the perceived inadequacies of the conventional software development methodologies with a look at one more paradigm. This one, the POLITE methodology, is directly aimed at improving on the basic RUDE cycle (not hard to do, you might think).The POLITE methodologyBader, Edwards, Harris-Jones, and Hannaford (1988) maintain that "knowledge-based systems" (KBS) are not yet associated with an accepted software development life cycle (SDLC) or development methodology. And if KBSs are to become an established technology within the data processing industry an appropriate SDLC will be needed so that the standards expected in commercial and industrial software are met by future KBSs. They describe "a practical approach to building KBSs and, in particular, how the development of hybrid systems, containing both conventional and knowledge-based components, can be managed effectively" (abstract, p. 266).They make the point that the major system development feature that KBSs bring to the fore is a necessity for iterative refinement, and so something like the RUDE cycle is a likely basis for the required methodology. Figure 5.13 is their simplified view of the RUDE cycle.Two fundamental flaws are singled out for treatment: "an engineering methodology for KBSs needs to provide a method for constructing an initial system from which the RUDE cycle can begin, as well as encompassing some form of control of the iterative process of development" (p. 270, authors' emphasis). As it stands, RUDE development is likely to lead to problems of documentation, maintenance and testing, all of which must be easily accomplished in an engineering methodology.Rather than generate a more disciplined version of the RUDE cycle, and thereby correct the two flaws, it is suggested that "the iterative features of the RUDE paradigm need to be incorporated within a structured and controllable framework" (p. 270). They select the waterfall model of software development (see Figure 4.6) as the "structured and controllable framework," and what was RUDE (plus waterfall) becomes POLITE, which is derived from:Produce Objectives - Logical/physical design - Implement - Test - Edit  Page 130Figure 5.13 "A simplified view of the RUDE cycle" from Bader et al. 1988, Figure 1, p. 270and, as we all know, POLITE is always preferable to RUDE. This is, of course, a slightly underhand way to introduce a possible enhancement. (But one that the RUDE paradigm seems to encourage—see, for a further example, Mostow's [1985] COURTEOUS alternative, and, as a counterexample, Trenouth's [1990b] VERY RUDE development.)As much fun as it is to work on acronym derivation and development, we, in this thoroughly serious book, must look beneath the name. A schematic illustration of the POLITE life-cycle is given in Figure 5.14.  Page 131Figure 5.14 "The POLITE life-cycle" from Bader et al., 1988, Figure 2, p. 270As you can see, this scheme is definitely waterfall based. The methodological enhancements come with elaboration of the infrastructure. To begin with: each step in the waterfall is now divided into two. "The left side is related to conventional components and the other side to  Page 132the knowledge-based or cognitive elements of the system'' (p. 270). For, as they state, the methodology as designed to deal "with the development of hybrid systems comprising both conventional and heuristic components"(p. 270). Personally, I would not separate off such "hybrid" systems as all systems are some sort of hybrid, it seems to me. (What would be a purely AI system?) The development of any AI system involves a large measure of totally conventional system development, and the lessons of conventional software engineering must be exploited to the full wherever appropriate. But Bader et al. do provide a useful three-way division of overall system structuring, and one that has application beyond the so-called "knowledge-based" systems. Their suggested tri-morphism is illustrated in Figure 5.15. Figure5.15 "Types of KBS interaction with other systems" from Bador et al., 1988, Fig. 4, p. 271  Page 133They name these three structures:•  stand-alone—when the interaction is with the user only•  integrated—when the interaction is with other systems, such as company databases, as well as with the user•  embedded—when the KBS is buried within a larger system and thus the user only interacts with the KBS through the host system interface.The second infrastructural addition is a RUDE cycle within each step of the process. So RUDE development is not the monolithic object that has to be disciplined; it has been broken down and distributed throughout the waterfall framework. This move is either an example of divide and conquer where the elemental RUDE cycles are sufficiently small and constrained to be manageable, or else it's the result of a hydra-like response in which the destruction of the one major RUDE cycle has spawned a sequence of six RUDE cycles, none of which is indisputably less troublesome than the original. Clearly, the authors view their rearrangement as fitting into the former category.To return to the ways that the POLITE paradigm deals with the two fundamental flaws in the RUDE cycle: great stress is laid on the production of performance objectives at the start of a project. Performance objectives "are a statement, in the problem owner's terms, of how the KBS should operate in the chosen domain"(p. 270). The existence of such objectives, clearly stated, is essential for validation, and it provides a framework within which any RUDE development that is required can be controlled.The authors view the production of performance objectives as part of the initial feasibility phase which, of course, directly addresses the problem of obtaining a first operational version of the system. Figure 5.16 illustrates the POLITE view of this crucial initial stage of system development.As you can see, management oversees the process of input from four information sources (the problem itself, the developers, the experts in the problem domain, and the eventual system users) and the generation of a number of outputs. In particular, we get the performance objectives and a prototype system.  Page 134Figure 5.16 "Feasibility and requirements definition" from Bader et al., Figure 3, p. 271So, the POLITE paradigm can be summarized as an attempt to exploit the necessity for iterative system development but to keep it in check by allowing RUDE cycles only within steps of the conventional waterfall model. Clearly, one of the tests of this paradigm concerns the degree to which iterative development can indeed be modularized and encapsulated within the analysis step, or the design step. etc. It may be, as I tend to believe, that the iteration necessarily swings from end to end of the development paradigm—certainly the less the better, but some such multi-step,  Page 135module-busting evolution seems inevitable. For example, as the need for prototyping tacitly admits, much useful information about the desirability of prior decisions (both explicit and implicit ones) is gained from the behavior of an implementation. So information gained at the far end of the development process can feed back to impact on any earlier step—design, specification, or even requirements. It is difficult to imagine (however convenient it would be) that all such informational feedback can be neatly encapsulated in the modular steps of the waterfall model, or even that non-local feedback can be propagated back effectively through a series of such steps.The POLITE paradigm is thus rather different from the two previous ones that we've considered, and a good deal less radical than either. But whether we can generate the necessary new paradigm by introducing perturbations to a thoroughly conventional scheme is an open question. In his book Building Knowledge-Based Systems, Edwards(1991) gives a full presentation of the POLITE methodology as applied to "knowledge-based systems" which he sees "as different from 'conventional' computer systems, but not very different" (p.1).This book is specifically aimed at exposing the problems peculiar to the task of engineering AI-software, and at presenting and discussing the alternative approaches to solution of these problems. In the current chapter we have seen a number of new paradigms for software development, but the new models are not always motivated by concerns for AI. If they are not interested in AI software then why are they devising radically new paradigms for software development—and incremental ones at that? seems a reasonable question to ask.If we ignore the possibility that our paradigm creators are motivated merely by a desire for novelty, we must assume that there is perceived to be a real need—i.e. that the conventional paradigms are unsatisfactory. And there is indeed a growing awareness in some sectors of the software engineering community that some sort of fundamentally incremental paradigm is required for all practical software development—AI-ish or not. Arango, Baxter and Freeman (in press), for example, report on their experiences at several workshops on software development. One recurring theme is that (as Brooks, 1979, first made clear) there are no silver bullets—i.e. no simple answers. "A natural conclusion is that for the time being we must strive for incremental approaches. The questions are 'how can we identify opportunities for incremental advances?' and 'how can we achieve these advances?" (p. 3, of draft).It is time to move on and examine some of the likely components of a discipline of exploratory programming.  Page 137CHAPTER 6Towards a Discipline of Exploratory ProgrammingAt this point in the book we've subjected the conventional software system development methodologies to scrutiny and exposed their weaknesses, especially with respect to the possibility of engineering AI software. We've also taken a brief look at a few proposals for schemes, or new paradigms, for overcoming certain of the weaknesses that are apparent; they do not solve, or circumvent, the fundamental problems, I hope that I've convinced you of that as well. And finally, I've been promoting the need for an iterative, evolutionary approach to engineering AI systems. The RUDE cycle was presented, but within it we could see even worse problems for the possibility of engineering robust, reliable and maintainable software systems. But in the absence of serious schemes that do solve the important problems, I propose to persist with the RUDE cycle and to examine its potential as a basis for AI-software development.What we need is a discipline of exploratory programming, or, more grandly, a discipline of exploratory system design—a discipline of ESD. Now, in this life there are many wondrous things that it would be just terrific to get hold of for various purposes. Many of these things we just can't afford (personal chauffeured transport springs to my mind in this category of desiderata), some are excluded by local context (I, for example, would very much like a mango tree in the garden, but this is not possible in this sceptred but oft-times frosty isle wherein I live), and others simply refuse to exist anywhere in this particular world (for example,  Page 138weightless solids, frictionless wheels). So, we may know what we need, but what we also need to know is that it is not in one of these unobtainable categories, particularly the last.I can find no guarantees that the necessary discipline of ESD is not in the same category as the excluded middles of logic, nevertheless there is every reason to be optimistic. In this chapter I shall discuss some of the likely components of this hypothesized paradigm. This will stand us in good stead for consideration of a further source of problems (machine learning) and some possible cause for optimism (expert systems) before we attempt to frame a general superstructure for a discipline of ESD.Reverse engineeringThe term reverse engineering has, in the last few years, been boosted to the forefront of general concerns that occupy the time of software engineers. Most software engineering books merely mention it at best, but it's a term that now peppers the papers of the practical software engineering world.As the name suggests, reverse engineering is a process of moving backwards from an engineered product (in our case a software system—a program) to extract the representations (such as specification, and general design) that would have been generated en route to the product had it been developed in accordance with a proper SDLC. In fact, my use of "would have been generated" really ought to be watered down to "might have been generated", for, as we shall later see, any given product will map comfortably back to any number of possible design schemes and specifications. The relationship of a program to possible design sequences is one-many: any given program could have been the final outcome from any one of a wide range of design sequences. This fact is important, as we shall subsequently see, because there can be a real need for a selection of alternative, roughly equivalent, but different representations of the possible 'designs' for a given program. I have put the word "designs" in qualifying quotes to emphasize the special usage here. It is not really potential alternative designs that we shall need to represent, but alternative, differently biased abstractions from the detailed complexity of the program. Such abstractions (of which the actual design is just one) provide the software developer or maintainer with a less complex and therefore more conceptually manageable representation of the program. And the need for alternatives arises from the fact that the software person will want to focus on different aspects of the program in order to pursue  Page 139different software development or enhancement goals. Each specific soft-ware-modification task will emphasize and de-emphasize different aspects of a program, and a representation that reflects this pattern of emphasis can provide the best framework for reasoning about the program. Figures 6.5 and 6.6 provide concrete examples of alternative, rather different representations of program infrastructure—there is potentially much more underlying a given program that the actual design and specification.We are now in a position to fully appreciate the lack of promotion that reverse engineering has received in the software world (especially the academic one), and why it can claim very little page space in treatises on software engineering. In a nutshell: reverse engineering is also the reverse of good practice. In addition, it is, I think, a less glamorous exercise for the scientist or technician—fiddling with a detailed mechanism in order to conjure up a possible design strategy is a challenge to the compulsive problem-solver, but can it be a formal science?So, the need for reverse engineering (e.g. the boss has dumped a huge listing of uncommented code on your desk with orders to debug it, or to add a functional enhancement) arises only as a result of bad practice, and you are often better advised to redesign a comparable piece of software rather than waste endless days trying to work backwards from the (apparently, if not actually) tangled mess of code in front of you—unravelling an entangled mass of wool is no one's idea of fun. Thus, on two rather different counts, we can dismiss the need for serious consideration of reverse engineering: it can only arise as a result of thoroughly bad practice, and so the need should be avoidable; and when totally unavoidable, it is more productive to re-engineer than to reverse engineer.Now, I'm clearly not spending all these words on something that is better dead and buried, so why am I doing it? The point is that as soon as we countenance the use of an evolutionary system development paradigm, and especially one that is driven by behavioral feedback, then reverse engineering is suddenly elevated to a position of both respectable and essential practice. This dramatic change in status (which we've seen emerging slowly from the world of software practitioners) occurs because reverse engineering is the key process behind transforming a behavioral observation into a specification change. Once we abandon the simple, linear SDLCs, and admit the necessity of prototyping, we are required to transform an observation of system behavior into a modification of some earlier representation—we are required to reverse engineer.As a specific example of a manifestation of reverse engineering, and one that was developed explicitly to support "the production of robust  Page 140exploratory software", we can look at the "type flow analysis" of Johnson (1990). The classic AI programming languages, primarily LISP but Prolog too can now be so classified, offer the programmer a flexibility and freedom that facilitates the rapid evolution of software. Neither language requires, for example, an extensive definition of data types as do the more conventional languages such as Pascal and Ada. But freedom has its price, and in this case the absence of type declarations is paid for in terms of inability to guarantee that type-level consistency in, say, a LISP program. As Johnson says: "This means that executing exploratory programs may contain an entire class of type-level errors that are absent from their non-exploratory counterparts. The inability to detect these errors automatically, compounded with the lack of explicit structural information and the high amount of structural change, is a principal cause of exploratory brittleness'' p. 3.Type flow analysis is used to generate from the LISP code a representation of the type level structure implicit in the program. This technique, which has been implemented in a system called ESSIE, is based on the observation that, although it is impossible to verify the type-level consistency of any arbitrary LISP program, it is possible to assess the type-level consistency of an interesting and large subset of all possible LISP programs. Type flow analysis thus provides us with a classic illustration of the sort of technique that we shall see occurring repeatedly in our survey of component elements for a discipline of ESD—i.e. a special-purpose, limited technique is substituted for a general impossibility without eliminating practical effectiveness.The fundamental representation of type-flow analysis is the braid which represents the set of execution strands through a function at the type level. As an example, consider the following function "size" which exploits the ad-hoc polymorphism that is typically available in exploratory languages.(defun size (obj)  (cond ((listp obj) (list-length obj))((hash-table-p obj) (hash-table-count obj))((vectorp obj) (array-length obj))  ))This function returns the length of different types of objects using a length function that is specific to the particular object type. Given this function, ESSIE will generate the braid Brl which is composed of the   Page 141three execution strands Stll, St12 and St13. The resultant type-flow analysis can be illustrated as follows.The feasibility conditions (FC) represent the type-related constraints that must be satisfied in order for the execution path represented by the strand to be valid; they are normally produced from the presence of type predicates such as "listp". The constraint environment (CE) holds the type-level properties of variables that must be satisfied whenever the execution path is traversed. The result type (RT) indicates what type would be returned from the execution of the code represented by the strand. A type-level error, for example, is signalled when the composition of two execution paths is found to be feasible but the two CEs cannot be successfully composed.ESSIE's analysis of a Lisp system is expected to provide three benefits:1. the verification of type safety, i.e. that the system does not contain any type level inconsistencies;2. the detection of type-level errors;3. the signalling of anomalies which may or may not be errors.Use of this reverse engineering technique is an attempt to reconcile the implementation freedom that supports exploratory programming with implementation constraints, such as type-level consistency, that support the development of robust software. By tackling this issue through reverse engineering, rather than strongly-typed languages (the conventional approach), perhaps we can begin to obtain the best of both worlds. Instead of forcing the programmer to work in a tight harness of a priori constraints, reverse engineering permits the products of exploratory freedom to be checked (and corrected if necessary) to ensure that agreed  Page 142discipline and structure is, in fact, exhibited by them. As long as it is clear what the desired constraints are and how they can be satisfied, why force a programmer to work continually under them when final products can be positively vetted for adherence? And, of course, this philosophy of subsequent, rather than simultaneous, vetting makes more sense in the context of programming as an exploratory activity than when programming is seen as a formal transformation exercise. When software development is seen as a creative pursuit, we can argue that creativity demands freedom of expression, but then the need for efficiency suggests the guidance of constraints. We need both, but in what mix, and how the mix should vary with circumstances are open problems—conventional programming languages, such as Ada, offer us one extreme and Johnson's type-flow analysis tries to offer us the other.Curiously, reverse engineering provides us with a point of contrast between software science and classical experimental sciences. The fundamental mechanism in the classical sciences is reverse engineering: they are presented with the products of say, biological science, and the role of the scientist is to figure out a plausible 'specification and design sequence'. It is not usually phrased that way, but clearly the scientist has the products as the givens and the principles and theories embodied in them as the unknowns. The classical scientist is primarily engaged in reverse engineering. Why this difference? Put another way, why is software science 'constructivist' or a process of synthesis, and classical science 'de-constructivist' (is that 'destructivist'?) or analytic? One answer is, of course, that software persons are not scientists, they are engineers. But I've already explored the ramifications of this labeling choice.Apart from the obvious difference that technologists are primarily trying to build things rather than (or as well as) understand them, I think that this question also harks back to the fundamental belief of computer scientists that their primary concerns are with with formal abstractions and not with real artefacts. Whether there is a real artefact (i.e. a working software system) at the end of any sequence of specification, design and verification is somewhat secondary for the computer scientist who has solved (or aims to solve) all the essential problems within the formal abstractions that should (in any proper scheme) precede actual coding and running of an actual piece of software.We shall see several of the subsequent sections in this chapter addressing problems that are part of the general problem of effective and efficient reverse engineering. But first, another major ingredient of the needed paradigm.  Page 143Reusable softwareReusability is another general concern, and one that risen quite dramatically in level of awareness within software engineering during the recent past. The term reusable software is, I think, self-explanatory, but perhaps I won't risk it. Here's Biggerstaff and Perlis' (1989) definition from their two-volume work on software reusability:Software reuse is the reapplication of a variety of kinds of knowledge about one system to another similar system in order to reduce the effort of development and maintenance of that other system. This reused knowledge includes artefacts such as domain knowledge, development experience, design decisions, architectural structures, requirements, designs, code, documentation, and so forth.Biggerstaff and Perlis (1989) p. xvThis is, as the authors concede, a broad definition and thus covers the full scope of possibilities.Software reusability refers to the desire to minimize reinventions of the wheel (as it were), or to avoid continual re-writing of much the same code, to be more precise. If certain functions could be specified, algorithms designed and tested thoroughly (if not verified), then subsequent software systems that involved the same functionality could use the module developed earlier. This has two big advantages: firstly, it cuts down the lengthy process of software development, and, secondly, it can provide software reliability in its strongest sense—i.e. much-reused modules will be thoroughly tried and tested in use.So secondhand software salesmen have a much better public image than their analogs in the automotive world, or at least they would do if they existed. Software reusability has been very much more of a desire than a reality in the software world. It is true that there are, and have been for a long time, substantial libraries of statistical and mathematical functions which are reused continually with a high success rate. But mathematical software is the exception, not the rule, in this regard. And this is because mathematical functions are well-defined, context-free abstractions (recall the distinguished category of model CS problems characterized in Chapter 3). In other domains we find much similar functionality required in one program and the next, but all too often the difference between the functionality offered by an existing piece of software and the functionality you desire are sufficiently different that (when you also add interface mismatches, documentation vagaries, etc.) it is preferable to reconstruct exactly what you need rather than work on someone else's  Page 144handiwork that doesn't quite fit your needs. A less defensible, but no less real, further reason for lack of reuse in the software world, is that programmers tend to prefer to write their own code than to re-work someone else's—the urge to create anew faces no real competition when the alternative is the drudgery of delving into an unknown code in order to modify it (or even to be sure that it is not in need of modification).In sum, the lack of practical exploitation of the notion of software reuse is due to both technical problems with making it possible and the nature of programmers who would rather re-create code than re-model it. The lesson to be taken from this is that successful promotion of software reusability will require 'social' constraints on the programmer as well as purely technical advances in this field.Halpern (1990) makes an eloquent plea for reusability of code as a key to software reliability. He credits McIlroy (1969) with being the first to write at length on reusable software. He notes that if achieving software reliability is viewed as a matter of defeating bugs (and not one of better requirements analysis and specification, nor one of proving abstract correctness) then the obvious tactic is not to introduce bugs in the first place. "This in turn suggests that we write no code, code being the swamp in which bugs breed" p. 136. But not only do we need to avoid writing code we must also guard against other peoples "fresh code (that is, untested code, whether newly written or not)" p. 136. But sadly code, unlike wine, fails to register its maturity—fresh code and thoroughly well-tested code are indistinguishable. Certain portions of a much and widely used software system may be completely fresh. And only when presented with input that in some dimension exceeds anything it has been given before does the computation crash through the fresh code to our utter amazement and dismay. Halpern calls this the ''crevasse problem".So finding code rather than writing it is the general strategy advocated. But ensuring that the code is not fresh, and deciding how best to chunk-up software into reusable modules, are both open problems. To deal with the fresh-code problem, he suggests the notion of a "usage history" associated with each reusable component, and a "Software Factory" to ensure that standards are adhered to, and to maintain stocks of mature (i.e. well-tried and tested) code modules.As Halpern notes, construction of modular software is almost universally reckoned to be a good thing: "everyone is for it, some know what it is, and few practice it." He provides three senses in which the term is used, but the one that is, he claims, relevant in the current context of reusability is:  Page 145The gathering into one routine of all the connecting links between a program and some function it will need at many points, so as to form a single standard interface between the two. A typical subject of modularization in this sense is an I/O package, which accepts all input/output requests from a program in a machine-independent or operating system independent form, and generates from them calls on the hardware or operating system functions that actually provide the needed service. The primary motive behind this kind of modularization is that of limiting the impact of change; the adoption of a new type of printer, for example, could be dealt with in a program so modularized by changing the single I/O module rather than all the many places in the program where I/O requests originate. These objects might better be called 'damage limiters' or 'change insulators' or 'responsibility compartments.'Halpern (1990) p. 139Nevertheless, he is not entirely happy with this definition of a module, and proposes another (but calls it a "box" to avoid the module muddle).A box is a unit of code whose effects within a program are exactly and only what its specification promises; it can be used in any context, and without prior knowledge of its contents, wherever these effects are wanted, provided only that its communications protocol is followed.As you can see, Halpern's definition of boxes bears a striking similarity to my earlier description of why mathematical software is reusable. This is no coincidence (neither is it because I wrote my description after reading his definition with the intention of mimicking it!). The similarity arises because Halpern intends to achieve the same level of certainty as can be exhibited by mathematical software. He goes to outline the resultant problems and the means of dealing with them.Halpern focuses exclusively on the code level. 'After all that's where the programs really are', he might say. He is in fact quite disdainful of approaches that are limited to abstract representations (e.g. proofs of correctness). But general interest in reusability runs through all representational levels of a typical SDLC. In fact, some people insist that the real benefits of reusability are to be found in the more abstract representations—e.g. we may have more success with composing designs from a library of design modules than composing executable code from code modules.  Page 146One of the threads of the reusability issue that connects us back to the notion of transformational implementation of software, discussed in the previous chapter, is reuse of the sequence of transformations that take a specification to an implementation. Recall, for example, the "new paradigm" of Balzer, Cheatham and Green (1983, but it is quicker to flip back a few pages and see Figure 5.6). Working on the widely accepted assumption that system evolution should work through the specification and not the implementation, they ran into the problem that this entails repeated reimplementation of the modified specification, and implementation is typically a long, tedious, and error-prone activity. The long-term solution is thus to automate it, but in the shorter-term (i.e. the next few hundred years) the answer is to semi-automate it and save the design-and-implementation sequence for reuse with the modified specification. Clearly, it can't all be used, but hopefully much of it can, thereby considerably reducing the re-implementation burden that the software engineer has to bear. This general strategy is known as replaying a derivation sequence or reusing derivations.In the "Knowledge-Based Software Engineering" chapter of the Handbook of AI, volume 4 (Bart and Cohen, 1990) it is suggested that there are three contexts in which reusing derivations is feasible and profitable: adaptive maintenance, i.e. updating a system to meet changing needs; within SLDCs that view experimentation and evolution as fundamental components; and when implementing a new specification, but one that is similar to some previous derivation.The Handbook goes on to address the problems posed by this general idea of reusing derivations, in particular, the problem that we never want to reuse ALL of some previous derivation sequence. So clearly, such sequences cannot be recorded as a monolithic block and replayed whenever required. Derivation sequences will have to be structured objects, and structured in such a way as to mesh with a control strategy that selects, deletes, substitutes, etc. appropriate elements to generate the new (and perhaps quite similar) derivation sequence. There is, of course, a vast fund of difficult, unsolved problems here—a limitless supply of PhDs for computer scientists perhaps. This offers the comfort that comes with job security for those researching in computer science, but for the practicing software engineer it means that no comprehensive software-reuse systems are likely to be available to him or her for quite some time. Nevertheless, because this is not an all or nothing notion, we can confidently expect to see elements of reuse technology appearing in commercial software development environments in the near future.  Page 147The Handbook tells us that when a derivation is recorded its hierarchical structure must be made explicit. For although it appears to be merely a sequence of transformation steps, "the internal structure of a derivation is a goal/subgoal tree whose leaves are transformation steps... A derivation is reused during adaptive maintenance by traversing down the hierarchical goal structure and replaying the derivation steps until one doesn't apply because the relevant part of the specification was changed" (draft p. 60). At this point the system might try some automatic derivation, or if all else fails it calls for human assistance. But reusing a derivation on a new specification looks like being an even more difficult problem. The key notion is one of analogy between the new specification and some previous one, and we have very little idea how to deal with this problem in general. Analogy has long been thought to be a key to much of the power of human intelligence. There is thus a long history of tinkering with it in Artificial Intelligence, but it has proved surprisingly resistant to effective understanding in terms of anything as precise as a programmable mechanism. Nevertheless, a number of research groups are pursuing this approach to reusability, but it looks like being one of the least tractable.But some forms of software reusability are finding immediate practical application. Joyce (1990) mentions a number of current commercial exploitations of this general philosophy. The Toshiba Corporation, he claims, "realized annual productivity rates in excess of 20,000 lines of source code per person-year as a result of utilizing reusable designs" (p. 97). Another company, the Hartford Insurance Group, is quoted as realizing significant savings as a result of the establishment and use of a reusable products library. They state that "by reusing code in the library, we realize a savings sic of 250 person-days per month at a cost of 25 per-son-days in support and maintenance time" (p.98). A study of Hartford's 14 applications development divisions indicates that 30-40 per cent of the code in new systems comes from the reusable library. Important factors in the success of this particular reusability venture are thought to be:1. making the library of reusable modules easy to use;2. establishing the view that all programmers are either contributors to or consumers of library code—i.e. the company programmer can't just ignore the reusability library.  Page 148Cavaliere (1989) reports on the experiences of the Hartford Insurance Group with their Reusable Code Project. Reusable code was defined "as any technique that increases productivity by eliminating redundant practices in program generation" (p. 132). As reported above, considerable resultant savings were identified by the company. They are now looking into reuse of design and specification information (both textual and graphic). And for companies contemplating their own reuse projects Cavaliere give us the following recommendations generated from the Hartford experience with successful code reuse.• Develop and maintain an automated index of the program functions existing at the installation. This serves two purposes: identification of potentially reusable modules, and identification of redundancy in the application functions which may flag a need for code reuse.• Make full-time staff resources available to both sort out potentially reusable code modules, and make the chosen modules more generic.• Implement productivity measurements associated with the reusability.• Set up a 'Reusability User Group' to share experiences and ideas.Prieto-Diaz and Freeman (1987) note that "For code reuse to be attractive, the overall effort to reuse code must be less than the effort to create new code. Code reuse involves three steps:1. accessing the code,2. understanding it, and3. adapting it" (p. 6).They proposed a classification scheme based on reusability-related attributes. The following table lists the five attributes that they selected as the most relevant indicators of reuse effort together with their associated metric. In addition, to devising this classification scheme and building an environment that helps both locate suitable components for reuse and estimate the effort that will be involved in the reuse, the authors consider that there are two levels of potential reuse:  Page 1491. the reuse of ideas and knowledge, and2. the reuse of particular artefacts and components (p. 7).Table 6.1 Metrics chosen for the five reuse attributes from Prieto-Diaz and Freeman (1987), IEEE Software (January) Table 3, p. 15.Attribute MetricProgram size Lines of codeProgram structure Number of modules, number of links, and cyclomatic complexityProgram documentation Subjective overall rating (1 to 10)Programming language Relative language closenessReuser experience Proficiency levels in two areas: programming language and domain of applicationThey are clearly focusing on the second and more well-defined (although not necessarily easier in the long run) level.Freeman's research group at the University of California, Irvine, now the Advanced Software Engineering Project (but formerly the Reuse Project) has explored many ideas centered around the notion of software reuse. The DRACO system (see, for example, Freeman, 1987) is an approach to the construction of similar software systems from reusable software components. The stated rationale behind DRACO is to improve both software productivity and quality of the systems produced. The DRACO approach includes the reuse of designs as well as of code, and thus "amortizing the cost of a piece of software over the largest possible number of systems" p.830. Clearly, this is a laudable but currently unachievable goal.Fully recognizing the difficulty of this task, the DRACO approach is to exploit the notion of an application domain within which numerous similar systems will be created over time. And for a given application domain an analysis of this domain must be made and defined to DRACO before it can be used to generate programs in the domain. As with many  Page 150of the difficult problems being addressed in this general area, DRACO does not have to be a complete solution before it will become a useful system. The initial implementation of DRACO was not (and did not have to be) a fully automatic program generator; it was designed to aid the system creator in an interactive manner—the more help it could give the better, but any automatic assistance is preferable to none. We shall see this situation recurring constantly throughout the rest of this book, and this provides a measure of comfort in an area where all the problems are daunting but partial solutions can constitute significant practical (and theoretical) advances.What does DRACO actually do? Two things it seems:1. it manages definitions and implementations of languages of various types (properly viewed as specification languages);2. it provides assistance and partial automation of the task of refining a specification of a desired system (given in one of the languages known to DRACO) into another language, presumably more concrete or executable (and also known to DRACO).Reusability in DRACO comes to the fore as it assists in the process of refining a specification to an implementation. This process of software development involves many decisions including those of design (at the specification end of the process) and those of use of specific code modules (at the implementation end). Thus there is clearly scope for the full spectrum of reusability options in this project. In addition, there is also an intent to exploit reusability in problem analysis, more than this, such reuse is seen by Neighbors (1989), DRACO's implementor, as "the most powerful brand of reuse" p. 9. The analysis of new system requirements, by an organization's systems analysts, can be considered in the light of DRACO domains that already exist. Given some appreciable overlap between the new problem and the known domains (including information on the previous analysis), there is potential scope for assisting in the new analysis by reusing elements of the earlier ones.DRACO was implemented in LISP (some few thousand lines of), but is not a production tool. The DRACO team see the key to eventual success as the existence of an effective library of domains—i.e. domains that can be built upon. Examples of domains already built are for augmented transition networks (i.e. sentence parsing mechanisms), for dictionary construction, and for generation of sentences in natural language.Before moving on from the general notion of reusability we should briefly look at it within the context of OOP (object-oriented  Page 151programming, introduced in Chapter 1). As mentioned in passing earlier, objects (the code-data capsules that dominate this style of programming) exist within an inheritance hierarchy. This means that any object can be viewed as a specialization of one (if only single inheritance) or more (multiple inheritance) general objects or classes—a class in OOP is roughly equivalent to a data type which is a precise characterization of the properties that a collection of entities all share. Booch (1991, p. 54) defines a hierarchy as follows:Hierarchy is a ranking or ordering of abstractions.And the notion of inheritance comes in because elements in the hierarchy can inherit properties from the more abstract levels. It is time for an example. Figure 6.1 A single inheritance hierarchyIn Figure 6.1 the most general class, "solid objects", is specialized into three subclasses: "cuboid", "pyramid" and "sphere". Each of these subclasses is then specialized further. Inheritance comes in because the specification of, say, "ball" is partially inherited from "spherical object" and from "solid object". Thus part of the definition of "ball" might be the relationship of its volume to its radius, but this part applies to all "spherical objects" and so would be defined there and inherited by "ball" and by  Page 152"my football" and by "orange". So this inheritance notion allows us to specify certain general characteristics of our computational objects just once, at the appropriate level of abstraction in the hierarchy, and then all subsequent specializations of this particular abstraction can automatically reap the benefits of our generalized characterization.The important point about inheritance from the software reusability perspective is that once the software developer has an appropriate generalized hierarchical structure built (i.e. a hierarchy tailored to the application domain), the creation of software within this domain is primarily a process of customizing the general framework to suit specific needs—i.e. of creating objects low down in the hierarchy which will automatically inherit properties from the more abstract structure above them. In general, the lower down in the hierarchy the software developer operates the more that previously defined structure and functions are being reused. It is not too much of a distortion to claim that a significant point of difference between the conventional programming paradigm (say, programming in Pascal) and OOP is that in the former software is built up from agglomerations of elemental bricks (the statements in the language) while in the latter software is built by specializing a general framework to fit particular computational needs—one could almost say that in OOP we are 'building down'. Or as Yourdon (1990) puts it:People using structured methods as their development paradigm tend to treat each new project as an intellectual exercise never before contemplated; analysis and design literally begin with a blank sheet of paper. People using object-oriented methods, on the other hand, tend to practice 'design by extension.' That is, they assume that the new system they have been asked to develop is merely an extension, or refinement, of something that has already been built; so they approach the problem by asking, 'What new subclasses do I need to create, and what attributes do I need to inherit?'Yourdon (1990) p. 258So among its many attractions OOP also seems to naturally promote the concept of reusability in software development, but only when the build-up-from-scratch mentality of programmers has been supplanted by the build-by-extension notion—and this 'not invented here' mindset has proved difficult to displace. As is often pointed out, with libraries of reusable code it is a no-lose situation from a purely technical viewpoint—  Page 153there is the short-term benefit of programming at a high level of abstraction and the long-term one knowing that every contribution will be not only to the current project but to all the ones that follow it as well.In sum, there are some immediately practical applications of the software reusability notion, and, although there are clearly some technical problems with full exploitation of this general idea, it does appear to be an underutilized notion that can provide considerable leverage once the programming milieu within a company is oriented towards capitalizing on it. Within their survey and assessment of automatic programming, Rich and Waters (1988) claim that "that the benefits of automatic programming can be traced almost exclusively to reuse" (p. 47). They also point out that "progress in any kind of automation is always obstructed by management problems as much as by technical hurdles... [and] given that the heart of automatic programming is reuse, economic incentives in software development and acquisition need to be revised to foster reuse... Policies whereby contractors would increase their profit by reusing software developed by others—or were paid extra if they produced something that someone else reused—would be steps in the right direction" p. 50.Design knowledgeIf we're contemplating reverse engineering or the reusability of modules that occur prior to code modules in a conventional SDLC, then we shall need to store, in a machine-manipulable form, representations of the design process—both design modules and the reasoning behind the choices made. It is this sort of information that is referred to in the term design knowledge.As I've already said, it is one thing to decide that we must store design knowledge, but it is quite another to know exactly what to store and how to best store it. We've seen one suggestion that the derivation sequence should be represented as a goal/subgoal tree. Another scheme is described by Potts (1989a).Potts describes a general scheme for representing process information, and in particular the design process in software engineering. It is a generic model which, with the aid of specialization mechanisms, can be customized for any design method. Potts lists the objects that it is necessary to represent as "design artefacts, steps and heuristics"(p. 66). The motivation for his work is presented as:  Page 154To provide intelligent tool support for the early phases of system design, including software requirements analysis and domain modeling, it is necessary to develop a theory of the early design process that allows one to reason about design steps, sequences of steps, goals, open issues, and so forth. This ambitious goal is made even more difficult by the fact that there is no commonly accepted procedure for performing early system design (p. 66).He lists three ways in which such a theory of design, a design method, will provide assistance to designers:1. It provides a standard repertoire of notations, which are amenable to various analysis.2. It helps control the technical progression of the project.3. It contains local heuristics, in the form of standard procedures and guidance in well-defined design situations.He draws our attention to the fact that it is the latter two points that address design as a process, and yet the first point is the only facet of design methods to be supported by traditional CASE tools (i.e. computer-aided design tools). These CASE tools operate on a design state and assist in, for example, obtaining consistency. But, of course, such tools provide little assistance for the process of design—i.e. what design actions need to be performed, what issues are open and require decisions, and how to perform design actions, such as refinement of detail. Tools to assist the process of design will have to be based on explicit realizations of the design method's steps and heuristics.Potts makes the further point that design methods are fluid. Each designer (and even the same designer at different times) will use a given design method differently. So a design method should not be a fixed procedure; we need a language or schema than can represent families of methods, at least. This leads him to address two issues:1. What should the primitives be for generic method-independent representation?2. How can this generic model be customized for specific methods?For his generic schema he adopts an entity-relationship-attribute data model. The entity classes are: artefacts,which hold design state information, design steps which are the means by which refinements and  Page 155revisions are performed, issues, positions and arguments are used to represent the reasoning behind design decisions. ''Issues pose questions about some focus of concern (e.g. 'how should functionality be assigned among the processors?'). A position is a candidate response to an issue (e.g. 'Function F should be allocated to its own processor'). An argument may support or object to a position ('Function F is time-critical')" (p. 67).There are eight legal binary relationships between the five entity types (as illustrated in Figure 6.2). Figure 6.2 "The generic model of Potts" from Potts(1989a), Figure 1, p. 67• Modifies—steps modify artefacts: in a revision a new version of the artefact is created, in derivation a new artefact may be created.• Raises—steps raise issues: performing a step may automatically raise an issue which may, or may not, have to be addressed immediately.• Reviews—issues review artefacts: e.g. an issue may be to review some property of an artefact.• Responds to—a position is a response to an issue.• Supports—arguments support positions.  Page 156• Objects to—arguments can also object to positions.• Cites—arguments can cite artefacts: the artefact can provide evidence for the argument.• Contributes to—positions contribute to steps: a step is performed because a set of commitments (selected positions) has been made.Potts (1989a) then goes on to demonstrate how his generic model can be customized for the pre-implementation phases of the Jackson System Design (JSD) method (Jackson, 1983), as an example. The full details of this customization of the generic model to the "Hi-Ride Elevator" problem in Jackson (1983), can be found in Potts (1989b).In general terms, the customization is accomplished by specialization of entity classes. "A design method's entity classes form a collection of class hierarchies, one for artefact classes, another for issue classes, and so on... the different issue classes may be resolvable in different ways. These relational constraints dictate which steps modify which artefacts, which artefact conditions can raise which issues, which positions can respond to which issues" (p.68) etc.Potts concludes with the observation that, although some research seeks to automate the process of requirements analysis and design, "there are many recurrent design situations where the constraints cannot be formalized strictly enough to support automatic constraint propagation. In these cases, some degree of intelligent automated task management and book-keeping of open issues and their possible solutions would nevertheless be very helpful" (p. 70) and his "issue-based information system" (IBIS) would be a possible route to kind of support for software engineering.Just like a number of the other schemes that we have looked at, this is an ambitious project, but one whose place in a book that claims to eschew blue-sky research is justified by the fact that almost any step along the road to this long-term goal should provide immediate practical assistance to the software engineer (and the Eiffel system, described later, is one such small step within a commercial product).Stepwise abstractionTo the software engineer who has delved into the world of software design methods and principles, the title of this subsection should elicit a feeling of deja vu but nevertheless seem somewhat odd. Stepwise refinement or stepwise decomposition are the terms with which I would  Page 157expect you to posses some familiarity already. These terms are used to label the general process of developing in intricate algorithm from a specification—we manage the complexity by decomposing the overall problem into a collection of more-or-less independent subproblems, and we develop the necessary detail using a series of refinement steps rather than all at once. This is, of course, the dominant process in classical software engineering, i.e. engineering a specific, detailed artefact (a program) from a specification. Once we begin to countenance the possibility of reverse engineering, it should come as no great surprise that some reversal of these processes tums out to be necessary. I have called this process stepwise abstraction (Partridge, 1986), and it was described using, as a basis, the five points presented by Wirth (1971) in the classic description of stepwise refinement. The five points are as follows:1. The effective communication of an AI program is based upon a sequence of abstraction steps. Typically in each step a number of substructures are condensed into a single, simple structure (often a structureless label). But on occasion, translation from an obscure to a less obscure notation may be involved.2. The degree of conciseness and modularity of the abstract representation obtained in this way will determine the ease or difficulty with which the program can be understood and facilitate changes in the abstraction process so that the representation obtained can be understood in different ways for different purposes.3. During the process of stepwise abstraction, a notation which is natural to the program at hand should be used as long as possible. The direction in which the notation develops during the process of abstraction is determined by the language most suitable within a particular target audience and for the type of understanding desired. This language should therefore allow us to express as naturally and as clearly as possible the structures which emerge during the design of the effectively communicable representations. At the same time, it must give guidance in the abstraction process by exhibiting each abstract representation in terms of basic features and structuring principles which are natural to the target audience.4. Each abstraction implies a number of design decisions based upon a set of design criteria. Among these criteria are succinctness, clarity and the preservation of significant features of the program.  Page 1585. The design of an effectively communicable sequence of representations from an AI program is not a trivial process. It is a major problem area in our efforts to transform the products of a RUDE-based paradigm into practical software. It will remain a problem area until guidelines for the varieties of stepwise abstraction are refined and honed to the extent that they are for stepwise refinement, or until AI problem solutions can be specified in more readily comprehensible machine-executable notations, free from the customary non-significant clutter (from Partridge, 1986, pp. 152-153).It's an absolute certainty that the foregoing description of stepwise abstraction is not totally comprehensible on its own. Let me now try to lessen the mystification, if not eliminate it altogether. First, I can give you a picture of stepwise abstraction in action, as it were (Figure 6.3). Figure 6.3 "The process of stepwise abstraction" from Partridge, 1986, p.1511926-0158A.jpg  Page 159If the behavior of the artefact is to be an effective force in driving system modification, we need all the support we can get for the difficult task of reasoning back from program behavior to specification changes that will produce the desired behavioral change, and will also introduce a minimum increment to overall system complexity. The answer is to work and reason through the intervening representations that bridge the gap between specification and implementation. You may find this an acceptable approach, but still fail to see why we would need to abstract these intervening design structures. Clearly, they should be readily available if the software was developed properly in the first place. There seems to be a valid reason for traversing them in reverse order, but no real need to generate them backwards.I suspect that full-scale stepwise abstraction is a seldom-required task, although something approaching it is necessary when faced with a pile of totally undocumented code and a pressing need to debug or enhance the system. But in the context of developing AI software, given that some incremental and exploratory methodology is necessary, minor examples (at least) of stepwise refinement are constantly in demand. There are several different reasons for this:• There is no one 'best' sequence of representations—different types of representation will best support different types of understanding (by different target audiences) of the specification-implementation relationship. So it should not be surprising that the design sequence favored by the original designer is not always the best (or even a good) sequence of representations to promote the understanding of an end-user, or of a software engineer charged with introducing a specific enhancement.• Within the context of an incremental and evolutionary development methodology (and within totally conventional methodologies, if the truth were admitted), surprising system behavior is surprising just because the design representations in use fail to support some aspect of understanding of the program—changes in the nature of 