I. Overview of Theories of Anarchism

Is it GENERALLY immoral to kill, to torture, to pain? The answer seems obvious and it automatically applies to animals. Is it generally immoral to destroy? Yes, it is and this answer pertains to the inanimate as well. There are exceptions: it is permissible to kill and to inflict pain in order to prevent a (quantitatively or qualitatively) greater evil, to protect life, and when no reasonable and feasible alternative is available.
The chain of food in nature is morally neutral and so are death and disease. Any act which is intended to sustain life of a higher order (and a higher order in life) – is morally positive or, at least neutral. Nature decreed so. Animals do it to other animals – though, admittedly, they optimize their consumption and avoid waste and unnecessary pain. Waste and pain are morally wrong. This is not a question of hierarchy of more or less important Beings (an outcome of the fallacy of anthropomorphizing Nature).
The distinction between what is (essentially) US – and what just looks and behaves like us (but is NOT us) is false, superfluous and superficial. Sociobiology is already blurring these lines. Quantum Mechanics has taught us that we can say nothing about what the world really IS. If things look the same and behave the same, we better assume that they are the same.
The attempt to claim that moral responsibility is reserved to the human species is self defeating. If it is so, then we definitely have a moral obligation towards the weaker and meeker. If it isn't, what right do we have to decide who shall live and who shall die (in pain)?
The increasingly shaky "fact" that species do not interbreed "proves" that species are distinct, say some. But who can deny that we share most of our genetic material with the fly and the mouse? We are not as dissimilar as we wish we were. And ever-escalating cruelty towards other species will not establish our genetic supremacy - merely our moral inferiority.
Note: Why Do We Love Pets?
The presence of pets activates in us two primitive psychological defense mechanisms: projection and narcissism.
Projection is a defense mechanism intended to cope with internal or external stressors and emotional conflict by attributing to another person or object (such as a pet) - usually falsely - thoughts, feelings, wishes, impulses, needs, and hopes deemed forbidden or unacceptable by the projecting party.
In the case of pets, projection works through anthropomorphism: we attribute to animals our traits, behavior patterns, needs, wishes, emotions, and cognitive processes. This perceived similarity endears them to us and motivates us to care for our pets and cherish them.
But, why do people become pet-owners in the first place? 
Caring for pets comprises equal measures of satisfaction and frustration. Pet-owners often employ a psychological defense mechanism - known as "cognitive dissonance" - to suppress the negative aspects of having pets and to deny the unpalatable fact that raising pets and caring for them may be time consuming, exhausting, and strains otherwise pleasurable and tranquil relationships to their limits.
Pet-ownership is possibly an irrational vocation, but humanity keeps keeping pets. It may well be the call of nature. All living species reproduce and most of them parent. Pets sometimes serve as surrogate children and friends. Is this maternity (and paternity) by proxy proof that, beneath the ephemeral veneer of civilization, we are still merely a kind of beast, subject to the impulses and hard-wired behavior that permeate the rest of the animal kingdom? Is our existential loneliness so extreme that it crosses the species barrier?
There is no denying that most people want their pets and love them. They are attached to them and experience grief and bereavement when they die, depart, or are sick. Most pet-owners find keeping pets emotionally fulfilling, happiness-inducing, and highly satisfying. This pertains even to unplanned and initially unwanted new arrivals. 
Could this be the missing link? Does pet-ownership revolve around self-gratification? Does it all boil down to the pleasure principle?
Pet-keeping may, indeed, be habit forming. Months of raising pups and cubs and a host of social positive reinforcements and expectations condition pet-owners to do the job. Still, a living pet is nothing like the abstract concept. Pets wail, soil themselves and their environment, stink, and severely disrupt the lives of their owners. Nothing too enticing here.
If you eliminate the impossible, what is left - however improbable - must be the truth. People keep pets because it provides them with narcissistic supply. 
A Narcissist is a person who projects a (false) image unto others and uses the interest this generates to regulate a labile and grandiose sense of self-worth. The reactions garnered by the narcissist - attention, unconditional acceptance, adulation, admiration, affirmation - are collectively known as "narcissistic supply". The narcissist treats pets as mere instruments of gratification. 
Infants go through a phase of unbridled fantasy, tyrannical behavior, and perceived omnipotence. An adult narcissist, in other words, is still stuck in his "terrible twos" and is possessed with the emotional maturity of a toddler. To some degree, we are all narcissists. Yet, as we grow, we learn to empathize and to love ourselves and others. 
This edifice of maturity is severely tested by pet-ownership. 
Pets evoke in their keepers the most primordial drives, protective, animalistic instincts, the desire to merge with the pet and a sense of terror generated by such a desire (a fear of vanishing and of being assimilated). Pets engender in their owners an emotional regression. 
The owners find themselves revisiting their own childhood even as they are caring for their pets. The crumbling of decades and layers of personal growth is accompanied by a resurgence of the aforementioned early infancy narcissistic defenses. Pet-keepers - especially new ones - are gradually transformed into narcissists by this encounter and find in their pets the perfect sources of narcissistic supply, euphemistically known as love. Really it is a form of symbiotic codependence of both parties. 
Even the most balanced, most mature, most psychodynamically stable of pet-owners finds such a flood of narcissistic supply irresistible and addictive. It enhances his or her self-confidence, buttresses self esteem, regulates the sense of self-worth, and projects a complimentary image of the parent to himself or herself. It fast becomes indispensable.
The key to our determination to have pets is our wish to experience the same unconditional love that we received from our mothers, this intoxicating feeling of being adored without caveats, for what we are, with no limits, reservations, or calculations. This is the most powerful, crystallized form of narcissistic supply. It nourishes our self-love, self worth and self-confidence. It infuses us with feelings of omnipotence and omniscience. In these, and other respects, pet-ownership is a return to infancy.
Anthropy (Also see: Universe,Fine-tuned)
The Second Law of Thermodynamics predicts the gradual energetic decay of physical closed systems ("entropy"). Arguably, the Universe as a whole is precisely such a system. 
Locally, though, order is often fighting disorder for dominance. In other words, in localized, open systems, order sometimes tends to increase and, by definition, statistical entropy tends to decrease. This is the orthodoxy. Personally, I believe otherwise.
Some physical systems increase disorder, either by decaying or by actively spreading disorder onto other systems. Such vectors we call "Entropic Agents".
Conversely, some physical systems increase order or decrease disorder either in themselves or in their environment. We call these vectors "Negentropic Agents".
Human Beings are Negentropic Agents gone awry. Now, through its excesses, Mankind is slowly being transformed into an Entropic Agent.
Antibiotics, herbicides, insecticides, pollution, deforestation, etc. are all detrimental to the environment and reduce the amount of order in the open system that is Earth.
Nature must balance this shift of allegiance, this deviation from equilibrium, by constraining the number of other Entropic Agents on Earth – or by reducing the numbers of humans. 
To achieve the latter (which is the path of least resistance and a typical self-regulatory mechanism), Nature causes humans to begin to internalize and assimilate the Entropy that they themselves generate. This is done through a series of intricate and intertwined mechanisms:
The Malthusian Mechanism – Limited resources lead to wars, famine, diseases and to a decrease in the populace (and, thus, in the number of human Entropic Agents).
The Assimilative Mechanism – Diseases, old and new, and other phenomena yield negative demographic effects directly related to the entropic actions of humans.
Examples: excessive use of antibiotics leads to drug-resistant strains of pathogens, cancer is caused by pollution, heart ailments are related to modern Western diet, AIDS, avian flu, SARS, and other diseases are a result of hitherto unknown or mutated strains of viruses.
The Cognitive Mechanism – Humans limit their own propagation, using "rational", cognitive arguments, devices, and procedures: abortion, birth control, the pill.
Thus, combining these three mechanisms, nature controls the damage and disorder that Mankind spreads and restores equilibrium to the terrestrial ecosystem.
Appendix - Order and the Universe
Earth is a complex, orderly, and open system. If it were an intelligent being, we would have been compelled to say that it had "chosen" to preserve and locally increase form (structure), order and complexity. 
This explains why evolution did not stop at the protozoa level. After all, these mono-cellular organisms were (and still are, hundreds of millions of years later) superbly adapted to their environment. It was Bergson who posed the question: why did nature prefer the risk of unstable complexity over predictable and reliable and durable simplicity?
The answer seems to be that Nature has a predilection (not confined to the biological realm) to increase complexity and order and that this principle takes precedence over "utilitarian" calculations of stability. The battle between the entropic arrow and the negentropic one is more important than any other (in-built) "consideration". Time and the Third Law of Thermodynamics are pitted against Life (as an integral and ubiquitous part of the Universe) and Order (a systemic, extensive parameter) against Disorder.
In this context, natural selection is no more "blind" or "random" than its subjects. It is discriminating, encourages structure, complexity and order. The contrast that Bergson stipulated between Natural Selection and Élan Vitale is misplaced: Natural Selection IS the vital power itself.
Modern Physics is converging with Philosophy (possibly with the philosophical side of Religion as well) and the convergence is precisely where concepts of order and disorder emerge. String theories, for instance, come in numerous versions which describe many possible different worlds (though, admittedly, they may all be facets of the same Being - distant echoes of the new versions of the Many Worlds Interpretation of Quantum Mechanics).
Still, why do we, intelligent conscious observers, see (why are we exposed to) only one kind of world? How is our world as we know it "selected"? The Universe is constrained in this "selection process" by its own history, but its history is not synonymous with the Laws of Nature. We know that the latter determine the former - but did the former also determine the latter? In other words: were the Laws of Nature "selected" as well and, if so, how?
The answer seems self evident: the Universe "selected" both the Natural Laws and, as a result, its own history, in a process akin to Natural Selection. Whatever increased order, complexity, and structure - survived. Our Universe - having itself survived - must be have been naturally selected.
We can assume that only order-increasing Universes do not succumb to entropy and death (the weak hypothesis). It could even be argued (as we do here) that our Universe is the only possible kind of Universe (the semi-strong hypothesis) or even the only Universe (the strong hypothesis). This is the essence of the Anthropic Principle.
By definition, universal rules pervade all the realms of existence. Biological systems obey the same order-increasing (natural) laws as do physical and social ones. We are part of the Universe in the sense that we are subject to the same discipline and adhere to the same "religion". We are an inevitable result - not a chance happening.
We are the culmination of orderly processes - not the outcome of random events. The Universe enables us and our world because - and only for as long as - we increase order. That is not to imply that there is an "intention" involved on the part of the Universe (or the existence of a "higher being" or a "higher power"). There is no conscious or God-like spirit. All I am saying is that a system founded on order as a fundamental principle will tend to favor order and opt for it, to proactively select its proponents and deselect its opponents, and to give birth to increasingly more sophisticated weapons in the pro-order arsenal. We, humans, were such an order-increasing weapon until recently.
These intuitive assertions can be easily converted into a formalism. In Quantum Mechanics, the State Vector can be constrained to collapse to the most order-enhancing event. If we had a computer the size of the Universe that could infallibly model it, we would have been able to predict which events will increase order in the Universe overall. These, then, would be the likeliest events.
It is easy to prove that events follow a path of maximum order, simply because the world is orderly and getting ever more so. Had this not been the case, statistically evenly-scattered events would have led to an increase in entropy (thermodynamic laws are the offspring of statistical mechanics). But this simply does not happen. 
And it is wrong to think that order increases only in isolated "pockets", in local regions of our universe.
It is increasing everywhere, all the time, on all scales of measurement. Therefore, we are forced to conclude that quantum events are guided by some non-random principle (such as the increase in order). This, exactly, is the case in biology. There is no reason in principle why not to construct a life wavefunction which will always collapse to the most order increasing event. If we were to construct and apply this wave function to our world - we, humans, would probably have found ourselves as one of the events selected by its collapse. Both now-discarded Lamarckism (the supposed inheritance of acquired characteristics) and Evolution Theory postulate that function determines form. Natural selection rewards those forms best suited to carry out the function of survival ("survival of the fittest") in each and every habitat (through the mechanism of adaptive radiation). 
But whose survival is natural selection concerned with? Is it the survival of the individual? Of the species? Of the habitat or ecosystem? These three - individual, species, habitat - are not necessarily compatible or mutually reinforcing in their goals and actions. 
If we set aside the dewy-eyed arguments of altruism, we are compelled to accept that individual survival sometimes threatens and endangers the survival of the species (for instance, if the individual is sick, weak, or evil). As every environmental scientist can attest, the thriving of some species puts at risk the existence of whole habitats and ecological niches and leads other species to extinction.
To prevent the potential excesses of egotistic self-propagation, survival is self-limiting and self-regulating. Consider epidemics: rather than go on forever, they abate after a certain number of hosts have been infected. It is a kind of Nash equilibrium. Macroevolution (the coordinated emergence of entire groups of organisms) trumps microevolution (the selective dynamics of species, races, and subspecies) every time.
This delicate and self-correcting balance between the needs and pressures of competing populations is manifest even in the single organism or species. Different parts of the phenotype invariably develop at different rates, thus preventing an all-out scramble for resources and maladaptive changes. This is known as "mosaic evolution". It is reminiscent of the "invisible hand of the market" that allegedly allocates resources optimally among various players and agents.
Moreover, evolution favors organisms whose rate of reproduction is such that their populations expand to no more than the number of individuals that the habitat can support (the habitat's carrying capacity). These are called K-selection species, or K-strategists and are considered the poster children of adaptation.
Live and let live is what evolution is all about - not the law of the jungle. The survival of all the species that are fit to survive is preferred to the hegemony of a few rapacious, highly-adapted, belligerent predators. Nature is about compromise, not about conquest.
Anti-Semitism
“Only loss is universal and true cosmopolitanism in this world must be based on suffering.”
Ignacio Silone
Rabid anti-Semitism, coupled with inane and outlandish conspiracy theories of world dominion, is easy to counter and dispel. It is the more "reasoned", subtle, and stealthy variety that it pernicious. "No smoke without fire," - say people - "there must be something to it!".
In this dialog I try to deconstruct a "mild" anti-Semitic text. I myself wrote the text - not an easy task considering my ancestry (a Jew) and my citizenship (an Israeli). But to penetrate the pertinent layers - historical, psychological, semantic, and semiotic - I had to "enter the skin" of "rational", classic anti-Semites, to grasp what makes them click and tick, and to think and reason like them.
I dedicated the last few months to ploughing through reams of anti-Semitic tracts and texts. Steeped in more or less nauseating verbal insanity and sheer paranoia, I emerged to compose the following.
The Anti-Semite:
The rising tide of anti-Semitism the world over is universally decried. The proponents of ant-Semitism are cast as ignorant, prejudiced, lawless, and atavistic. Their arguments are dismissed off-handedly. 
But it takes one Jew to really know another. Conditioned by millennia of persecution, Jews are paranoid, defensive, and obsessively secretive. It is impossible for a gentile - whom they hold to be inferior and reflexively hostile - to penetrate their counsels.
Let us examine anti-Semitic arguments more closely and in an unbiased manner:
Argument number one - Being Jewish is a racial distinction - not only a religious one
If race is defined in terms of genetic purity, then Jews are as much a race as the remotest and most isolated of the tribes of the Amazon. Genetic studies revealed that Jews throughout the world - largely due to centuries of in-breeding - share the same genetic makeup. Hereditary diseases which afflict only the Jews attest to the veracity of this discovery. 
Judaism is founded on shared biology as much as shared history and customs. As a religion, it proscribes a conjugal union with non-Jews. Jews are not even allowed to partake the food and wine of gentiles and have kept their distance from the communities which they inhabited - maintaining tenaciously, through countless generations, their language, habits, creed, dress, and national ethos. Only Jews become automatic citizens of Israel (the infamous Law of Return).
The Jewish Response:
Race has been invariably used as an argument against the Jews. It is ironic that racial purists have always been the most fervent anti-Semites. Jews are not so much a race as a community, united in age-old traditions and beliefs, lore and myths, history and language. Anyone can become a Jew by following a set of clear (though, admittedly, demanding) rules. There is absolutely no biological test or restriction on joining the collective that is known as the Jewish people or the religion that is Judaism.
It is true that some Jews are differentiated from their gentile environments. But this distinction has largely been imposed on us by countless generations of hostile hosts and neighbors. The yellow Star of David was only the latest in a series of measures to isolate the Jews, clearly mark them, restrict their economic and intellectual activities, and limit their social interactions. The only way to survive was to stick together. Can you blame us for responding to what you yourselves have so enthusiastically instigated?
The Anti-Semite:
Argument number two - The Jews regard themselves as Chosen, Superior, or Pure
Vehement protestations to the contrary notwithstanding - this is largely true. Orthodox Jews and secular Jews differ, of course, in their perception of this supremacy. The religious attribute it to divine will, intellectuals to the outstanding achievements of Jewish scientists and scholars, the modern Israeli is proud of his invincible army and thriving economy. But they all share a sense of privilege and commensurate obligation to civilize their inferiors and to spread progress and enlightenment wherever they are. This is a pernicious rendition of the colonial White Man's Burden and it is coupled with disdain and contempt for the lowly and the great unwashed (namely, the gentiles).
The Jewish Response:
There were precious few Jews among the great colonizers and ideologues of imperialism (Disraeli being the exception). Moreover, to compare the dissemination of knowledge and enlightenment to colonialism is, indeed, a travesty. 
We, the Jews, are proud of our achievements. Show me one group of people (including the anti-Semites) who isn't? But there is an abyss between being justly proud of one's true accomplishments and feeling superior as a result. Granted, there are narcissists and megalomaniacs everywhere and among the members of any human collective. Hitler and his Aryan superiority is a good example. 
The Anti-Semite:
Argument number three - Jews have divided loyalties
It is false to say that Jews are first and foremost Jews and only then are they the loyal citizens of their respective countries. Jews have unreservedly fought and sacrificed in the service of their homelands, often killing their coreligionists in the process. But it is true that Jews believe that what is good for the Jews is good for the country they reside in. By aligning the interests of their adopted habitat with their narrower and selfish agenda, Jews feel justified to promote their own interests to the exclusion of all else and all others.
Moreover, the rebirth of the Jewish State presented the Jews with countless ethical dilemmas which they typically resolved by adhering uncritically to Tel-Aviv's official line. This often brought them into direct conflict with their governments and non-Jewish compatriots and enhanced their reputation as untrustworthy and treacherous.
Hence the Jewish propensity to infiltrate decision-making centers, such as politics and the media. Their aim is to minimize conflicts of interests by transforming their peculiar concerns and preferences into official, if not always consensual, policy. This viral hijacking of the host country's agenda is particularly evident in the United States where the interest of Jewry and of the only superpower have become inextricable.
It is a fact - not a rant - that Jews are over-represented in certain, influential, professions (in banking, finance, the media, politics, the film industry, publishing, science, the humanities, etc.). This is partly the result of their emphases on education and social upward mobility. But it is also due to the tendency of well-placed Jews to promote their brethren and provide them with privileged access to opportunities, funding, and jobs.
The Jewish Response:
Most modern polities are multi-ethnic and multi-cultural (an anathema to anti-Semites, I know). Every ethnic, religious, cultural, political, intellectual, and economic or business group tries to influence policy-making by various means. This is both legitimate and desirable. Lobbying has been an integral and essential part of democracy since it was invented in Athens 2500 years ago. The Jews and Israelis are no exception.
Jews are, indeed, over-represented in certain professions in the United States. But they are under-represented in other, equally important, vocations (for instance, among company CEOs, politicians, diplomats, managers of higher education institutions, and senior bankers). Globally, Jews are severely under-represented or not-existent in virtually all professions due to their demography (aging population, low birth-rates, unnatural deaths in wars and slaughters).
 
The Anti-Semite:
Argument number four - Jews act as a cabal or mafia
There is no organized, hierarchical, and centralized worldwide Jewish conspiracy. Rather the Jews act in a manner similar to al-Qaida: they freelance and self-assemble ad hoc in cross-border networks to tackle specific issues. Jewish organizations - many in cahoots with the Israeli government - serve as administrative backup, same as some Islamic charities do for militant Islam. The Jews' ability and readiness to mobilize and act to further their plans is a matter of record and the source of the inordinate influence of their lobby organizations in Washington, for instance.
When two Jews meet, even randomly, and regardless of the disparities in their background, they immediately endeavor to see how they can further each other's interests, even and often at the expense of everyone else's.
Still, the Jewish diaspora, now two millennia old, is the first truly global phenomenon in world affairs. Bound by a common history, a common set of languages, a common ethos, a common religion, common defenses and ubiquitous enemies - Jews learned to closely cooperate in order to survive.
No wonder that all modern global networks - from Rothschild to Reuters - were established by Jews. Jews also featured prominently in all the revolutionary movements of the past three centuries. Individual Jews - though rarely the Jewish community as a whole - seem to benefit no matter what. 
When Czarist Russia collapsed, Jews occupied 7 out of 10 prominent positions in both the Kerensky (a Jew himself) government and in the Lenin and early Stalin administrations. When the Soviet Union crumbled, Jews again benefited mightily. Three quarters of the famous "oligarchs" (robber barons) that absconded with the bulk of the defunct empire's assets were - you guessed it - Jews. 
The Jewish Response:
Ignoring the purposefully inflammatory language for a minute, what group does not behave this way? Harvard alumni, the British Commonwealth, the European Union, the Irish or the Italians in the United States, political parties the world over ... As long as people co-operate legally and for legal ends, without breaching ethics and without discriminating against deserving non-members - what is wrong with that? 
The Anti-Semite:
Argument number five - The Jews are planning to take over the world and establish a world government
This is the kind of nonsense that discredits a serious study of the Jews and their role in history, past and present. Endless lists of prominent people of Jewish descent are produced in support of the above contention. Yet, governments are not the mere sum of their constituent individuals. The dynamics of power subsist on more than the religious affiliation of office-holders, kingmakers, and string-pullers.
Granted, Jews are well introduced in the echelons of power almost everywhere. But this is still a very far cry from a world government. Neither were Jews prominent in any of the recent moves - mostly by the Europeans - to strengthen the role of international law and attendant supranational organizations.
The Jewish Response:
What can I say? I agree with you. I would only like to set the record straight by pointing out the fact that Jews are actually under-represented in the echelons of power everywhere (including in the United States). Only in Israel - where they constitute an overwhelming majority - do Jews run things.
The Anti-Semite:
Argument number six - Jews are selfish, narcissistic, haughty, double-faced, dissemblers. Zionism is an extension of this pathological narcissism as a colonial movement
Judaism is not missionary. It is elitist. But Zionism has always regarded itself as both a (19th century) national movement and a (colonial) civilizing force. Nationalist narcissism transformed Zionism into a mission of acculturation ("White Man's Burden"). 
In "Altneuland" (translated to Hebrew as "Tel Aviv"), the feverish tome composed by Theodore Herzl, Judaism's improbable visionary - Herzl refers to the Arabs as pliant and compliant butlers, replete with gloves and tarbushes. In the book, a German Jewish family prophetically lands at Jaffa, the only port in erstwhile Palestine. They are welcomed and escorted by "Briticized" Arab gentlemen's gentlemen who are only too happy to assist their future masters and colonizers to disembark.
This age-old narcissistic defence - the Jewish superiority complex - was only exacerbated by the Holocaust.
Nazism posed as a rebellion against the "old ways" - against the hegemonic culture, the upper classes, the established religions, the superpowers, the European order. The Nazis borrowed the Leninist vocabulary and assimilated it effectively. Hitler and the Nazis were an adolescent movement, a reaction to narcissistic injuries inflicted upon a narcissistic (and rather psychopathic) toddler nation-state. Hitler himself was a malignant narcissist, as Fromm correctly noted.
The Jews constituted a perfect, easily identifiable, embodiment of all that was "wrong" with Europe. They were an old nation, they were eerily disembodied (without a territory), they were cosmopolitan, they were part of the establishment, they were "decadent", they were hated on religious and socio-economic grounds (see Goldhagen's "Hitler's Willing Executioners"), they were different, they were narcissistic (felt and acted as morally superior), they were everywhere, they were defenseless, they were credulous, they were adaptable (and thus could be co-opted to collaborate in their own destruction). They were the perfect hated father figure and parricide was in fashion.
The Holocaust was a massive trauma not because of its dimensions - but because Germans, the epitome of Western civilization, have turned on the Jews, the self-proclaimed missionaries of Western civilization in the Levant and Arabia. It was the betrayal that mattered. Rejected by East (as colonial stooges) and West (as agents of racial contamination) alike - the Jews resorted to a series of narcissistic responses reified by the State of Israel. 
The long term occupation of territories (metaphorical or physical) is a classic narcissistic behavior (of "annexation" of the other). The Six Days War was a war of self defence - but the swift victory only exacerbated the grandiose fantasies of the Jews. Mastery over the Palestinians became an important component in the psychological makeup of the nation (especially the more rightwing and religious elements) because it constitutes "Narcissistic Supply".
The Jewish Response:
Happily, sooner or later most anti-Semitic arguments descend into incoherent diatribe. This dialog is no exception. 
Zionism was not conceived out of time. It was born in an age of colonialism, Kipling's "white man's burden", and Western narcissism. Regrettably, Herzl did not transcend the political discourse of his period. But Zionism is far more than Altneuland. Herzl died in 1904, having actually been deposed by Zionists from Russia who espoused ideals of equality for all, Jews and non-Jews alike. 
The Holocaust was an enormous trauma and a clarion call. It taught the Jews that they cannot continue with their historically abnormal existence and that all the formulas for accommodation and co-existence failed. There remained only one viable solution: a Jewish state as a member of the international community of nations. 
The Six Days War was, indeed, a classic example of preemptive self-defense. Its outcomes, however, deeply divide Jewish communities everywhere, especially in Israel. Many of us believe that occupation corrupts and reject the Messianic and millennial delusions of some Jews as dangerous and nefarious. 
Perhaps this is the most important thing to remember:
Like every other group of humans, though molded by common experience, Jews are not a monolith. There are liberal Jews and orthodox Jews, narcissists and altruists, unscrupulous and moral, educated and ignorant, criminals and law-abiding citizens. Jews, in other words, are like everyone else. Can we say the same about anti-Semites? I wonder.
The Anti-Israeli:
The State of Israel is likely to end as did the seven previous stabs at Jewish statehood - in total annihilation. And for the same reasons: conflicts between secular and religious Jews and a racist-colonialist pattern of deplorable behavior. The UN has noted this recidivist misconduct in numerous resolutions and when it justly compared Zionism to racism.
The Jewish Response:
Zionism is undoubtedly a typical 19th century national movement, promoting the interests of an ethnically-homogeneous  nation. But it is not and never has been a racist movement. Zionists of all stripes never believed in the inherent inferiority or malevolence or impurity of any group of people (however arbitrarily defined or capriciously delimited) just because of their common origin or habitation. The State of Israel is not exclusionary. There are a million Israelis who are Arabs, both Christians and Muslims. 
It is true, though, that Jews have a special standing in Israel. The Law of Return grants them immediate citizenship. Because of obvious conflicts of interest, Arabs cannot serve in the Israel Defense Forces (IDF). Consequently, they don't enjoy the special benefits conferred on war veterans and ex-soldiers. 
Regrettably, it is also true that Arabs are discriminated against and hated by many Israelis, though rarely as a matter of official policy. These are the bitter fruits of the ongoing conflict. Budget priorities are also heavily skewed in favor of schools and infrastructure in Jewish municipalities. A lot remains to be done.
The Anti-Israeli:
Zionism started off as a counter-revolution. It presented itself as an alternative to both orthodox religion and to assimilation in the age of European "Enlightenment". But it was soon hijacked by East European Jews who espoused a pernicious type of Stalinism and virulent anti-Arab racism. 
The Jewish Response:
East European Jews were no doubt more nationalistic and etatist than the West European visionaries who gave birth to Zionism. But, again, they were not racist. On the very contrary. Their socialist roots called for close collaboration and integration of all the ethnicities and nationalities in Israel/Palestine.
The Anti-Israeli:
The "Status Quo" promulgated by Israel's first Prime Minister, David Ben-Gurion, confined institutionalized religion to matters of civil law and to communal issues. All affairs of state became the exclusive domain of the secular-leftist nomenclature and its attendant bureaucratic apparatus.
All this changed after the Six Days War in 1967 and, even more so, after the Yom Kippur War. Militant Messianic Jews with radical fundamentalist religious ideologies sought to eradicate the distinction between state and synagogue. They propounded a political agenda, thus invading the traditionally secular turf, to the great consternation of their compatriots.
This schism is unlikely to heal and will be further exacerbated by the inevitable need to confront harsh demographic and geopolitical realities. No matter how much occupied territory Israel gives up and how many ersatz Jews it imports from East Europe, the Palestinians are likely to become a majority within the next 50 years.
Israel will sooner or later face the need to choose whether to institute a policy of strict and racist apartheid - or shrink into an indefensible (though majority Jewish) enclave. The fanatics of the religious right are likely to enthusiastically opt for the first alternative. All the rest of the Jews in Israel are bound to recoil. Civil war will then become unavoidable and with it the demise of yet another short-lived Jewish polity.
The Jewish Response:
Israel is, indeed, faced with the unpalatable choice and demographic realities described above. But don't bet on civil war and total annihilation just yet. There are numerous other political solutions - for instance, a confederacy of two national states, or one state with two nations. But, I agree, this is a serious problem further compounded by Palestinian demands for the right to return to their ancestral territories, now firmly within the Jewish State, even in its pre-1967 borders.
With regards to the hijacking of the national agenda by right-wing, religious fundamentalist Jewish militants - as the recent pullout from Gaza and some of the West Bank proves conclusively, Israelis are pragmatists. The influence of Messianic groups on Israeli decision-making is blown out of proportion. They are an increasingly isolated - though vocal and sometimes violent - minority.
The Anti-Israeli:
Israel could, perhaps, have survived, had it not committed a second mortal sin by transforming itself into an outpost and beacon of Western (first British-French, then American) neo-colonialism. As the representative of the oppressors, it was forced to resort to an official policy of unceasing war crimes and repeated grave violations of human and civil rights. 
 
The Jewish Response:
Israel aligned itself with successive colonial powers in the region because it felt it had no choice, surrounded and outnumbered as it was by hostile, trigger-happy, and heavily armed neighbors. Israel did miss, though, quite a few chances to make peace, however intermittent and hesitant, with its erstwhile enemies. It is also true that it committed itself to a policy of settlements and oppression within the occupied territories which inevitably gave rise to grave and repeated violations on international law. Overlording another people had a corrosive corrupting influence on Israeli society.
The Anti-Israeli:
The Arabs, who first welcomed the Jewish settlers and the economic opportunities they represented, turned against the new emigrants when they learned of their agenda of occupation, displacement, and ethnic cleansing. Israel became a pivot of destabilization in the Middle East, embroiled in conflicts and wars too numerous to count. Unscrupulous and corrupt Arab rulers used its existence and the menace it reified as a pretext to avoid democratization, transparency, and accountability.
The Jewish Response:
With the exception of the 1919 Faisal-Weitzman declaration, Arabs never really welcomed the Jews. Attacks on Jewish outposts and settlers started as early as 1921 and never ceased. The wars in 1948 and in 1967 were initiated or provoked by the Arab states. It is true, though, that Israel unwisely leveraged its victories to oppress the Palestinians and for territorial gains, sometimes in cahoots with much despised colonial powers, such as Britain and France in 1956.
The Anti-Israeli:
This volatile mixture of ideological racism, Messianic empire-building, malignant theocracy much resented by the vast majority of secular Jews, and alignment with all entities anti-Arab and anti-Muslim will doom the Jewish country. In the long run, the real inheritors and proprietors of the Middle East are its long-term inhabitants, the Arabs. A strong army is not a guarantee of longevity - see the examples of the USSR and Yugoslavia. 
Even now, it is not too late. Israel can transform itself into an important and benevolent regional player by embracing its Arab neighbors and by championing the causes of economic and scientific development, integration, and opposition to outside interference in the region's internal affairs. The Arabs, exhausted by decades of conflict and backwardness, are likely to heave a collective sigh of relief and embrace Israel - reluctantly at first and more warmly as it proves itself a reliable ally and friend.
Israel's demographic problem is more difficult to resolve. It requires Israel to renounce its exclusive racist and theocratic nature. Israel must suppress, by force if need be, the lunatic fringe of militant religious fanatics that has been haunting its politics in the last three decades. And it must extend a welcoming hand to its Arab citizens by legislating and enforcing a set of Civil Rights Laws.
 
The Jewish Response:
Whether this Jewish state is doomed or not, time will tell. Peace with our Arab neighbors and equal treatment of our Arab citizens should be our two over-riding strategic priorities. The Jewish State cannot continue to live by the sword, lest it perishes by it.
If the will is there it can be done. The alternative is too horrible to contemplate.
Art (as Private Language)
"I know of no 'new programme'. Only that art is forever manifesting itself in new forms, since there are forever new personalities-its essence can never alter, I believe. Perhaps I am wrong. But speaking for myself, I know that I have no programme, only the unaccountable longing to grasp what I see and feel, and to find the purest means of expression for it." 

Karl Schmidt-Rottluff 
The psychophysical problem is long standing and, probably, intractable.
We have a corporeal body. It is a physical entity, subject to all the laws of physics. Yet, we experience ourselves, our internal lives, external events in a manner which provokes us to postulate the existence of a corresponding, non-physical ontos, entity. This corresponding entity ostensibly incorporates a dimension of our being which, in principle, can never be tackled with the instruments and the formal logic of science.
A compromise was proposed long ago: the soul is nothing but our self awareness or the way that we experience ourselves. But this is a flawed solution. It is flawed because it assumes that the human experience is uniform, unequivocal and identical. It might well be so - but there is no methodologically rigorous way of proving it. We have no way to objectively ascertain that all of us experience pain in the same manner or that pain that we experience is the same in all of us. This is even when the causes of the sensation are carefully controlled and monitored.
A scientist might say that it is only a matter of time before we find the exact part of the brain which is responsible for the specific pain in our gedankenexperiment. Moreover, will add our gedankenscientist, in due course, science will even be able to demonstrate a monovalent relationship between a pattern of brain activity in situ and the aforementioned pain. In other words, the scientific claim is that the patterns of brain activity ARE the pain itself.
Such an argument is, prima facie, inadmissible. The fact that two events coincide (even if they do so forever) does not make them identical. The serial occurrence of two events does not make one of them the cause and the other the effect, as is well known. Similarly, the contemporaneous occurrence of two events only means that they are correlated. A correlate is not an alter ego. It is not an aspect of the same event. The brain activity is what appears WHEN pain happens - it by no means follows that it IS the pain itself.
A stronger argument would crystallize if it was convincingly and repeatedly demonstrated that playing back these patterns of brain activity induces the same pain. Even in such a case, we would be talking about cause and effect rather than identity of pain and its correlate in the brain.
The gap is even bigger when we try to apply natural languages to the description of emotions and sensations. This seems close to impossible. How can one even half accurately communicate one's anguish, love, fear, or desire? We are prisoners in the universe of our emotions, never to emerge and the weapons of language are useless. Each one of us develops his or her own, idiosyncratic, unique emotional language. It is not a jargon, or a dialect because it cannot be translated or communicated. No dictionary can ever be constructed to bridge this lingual gap. In principle, experience is incommunicable. People - in the very far future - may be able to harbour the same emotions, chemically or otherwise induced in them. One brain could directly take over another and make it feel the same. Yet, even then these experiences will not be communicable and we will have no way available to us to compare and decide whether there was an identity of sensations or of emotions.
Still, when we say "sadness", we all seem to understand what we are talking about. In the remotest and furthest reaches of the earth people share this feeling of being sad. The feeling might be evoked by disparate circumstances - yet, we all seem to share some basic element of "being sad". So, what is this element?
We have already said that we are confined to using idiosyncratic emotional languages and that no dictionary is possible between them.
Now we will postulate the existence of a meta language. This is a language common to all humans, indeed, it seems to be the language of being human. Emotions are but phrases in this language. This language must exist - otherwise all communication between humans would have ceased to exist. It would appear that the relationship between this universal language and the idiosyncratic, individualistic languages is a relation of correlation. Pain is correlated to brain activity, on the one hand - and to this universal language, on the other. We would, therefore, tend to parsimoniously assume that the two correlates are but one and the same. In other words, it may well be that the brain activity which "goes together" is but the physical manifestation of the meta-lingual element "PAIN". We feel pain and this is our experience, unique, incommunicable, expressed solely in our idiosyncratic language.
We know that we are feeling pain and we communicate it to others. As we do so, we use the meta, universal language. The very use (or even the thought of using) this language provokes the brain activity which is so closely correlated with pain.
It is important to clarify that the universal language could well be a physical one. Possibly, even genetic. Nature might have endowed us with this universal language to improve our chances to survive. The communication of emotions is of an unparalleled evolutionary importance and a species devoid of the ability to communicate the existence of pain - would perish. Pain is our guardian against the perils of our surroundings.
To summarize: we manage our inter-human emotional communication using a universal language which is either physical or, at least, has strong physical correlates.
The function of bridging the gap between an idiosyncratic language (his or her own) and a more universal one was relegated to a group of special individuals called artists. Theirs is the job to experience (mostly emotions), to mould it into a the grammar, syntax and vocabulary of a universal language in order to communicate the echo of their idiosyncratic language. They are forever mediating between us and their experience. Rightly so, the quality of an artist is measured by his ability to loyally represent his unique language to us. The smaller the distance between the original experience (the emotion of the artist) and its external representation - the more prominent the artist.
We declare artistic success when the universally communicable representation succeeds at recreating the original emotion (felt by the artist) with us. It is very much like those science fiction contraptions which allow for the decomposition of the astronaut's body in one spot - and its recreation, atom for atom in another (teleportation).
Even if the artist fails to do so but succeeds in calling forth any kind of emotional response in his viewers/readers/listeners, he is deemed successful.
Every artist has a reference group, his audience. They could be alive or dead (for instance, he could measure himself against past artists). They could be few or many, but they must exist for art, in its fullest sense, to exist. Modern theories of art speak about the audience as an integral and defining part of the artistic creation and even of the artefact itself.
But this, precisely, is the source of the dilemma of the artist:
Who is to determine who is a good, qualitative artist and who is not?
Put differently, who is to measure the distance between the original experience and its representation?
After all, if the original experience is an element of an idiosyncratic, non-communicable, language - we have no access to any information regarding it and, therefore, we are in no position to judge it. Only the artist has access to it and only he can decide how far is his representation from his original experience. Art criticism is impossible.
Granted, his reference group (his audience, however limited, whether among the living, or among the dead) has access to that meta language, that universal dictionary available to all humans. But this is already a long way towards the representation (the work of art). No one in the audience has access to the original experience and their capacity to pass judgement is, therefore, in great doubt.
On the other hand, only the reference group, only the audience can aptly judge the representation for what it is. The artist is too emotionally involved. True, the cold, objective facts concerning the work of art are available to both artist and reference group - but the audience is in a privileged status, its bias is less pronounced.
Normally, the reference group will use the meta language embedded in us as humans, some empathy, some vague comparisons of emotions to try and grasp the emotional foundation laid by the artist. But this is very much like substituting verbal intercourse for the real thing. Talking about emotions - let alone making assumptions about what the artist may have felt that we also, maybe, share - is a far cry from what really transpired in the artist's mind.
We are faced with a dichotomy:The epistemological elements in the artistic process belong exclusively and incommunicably to the artist.The ontological aspects of the artistic process belong largely to the group of reference but they have no access to the epistemological domain.
And the work of art can be judged only by comparing the epistemological to the ontological.
Nor the artist, neither his group of reference can do it. This mission is nigh impossible.
Thus, an artist must make a decision early on in his career:
Should he remain loyal and close to his emotional experiences and studies and forgo the warmth and comfort of being reassured and directed from the outside, through the reactions of the reference group, or should he consider the views, criticism and advice of the reference group in his artistic creation - and, most probably, have to compromise the quality and the intensity of his original emotion in order to be more communicative.
I wish to thank my brother, Sharon Vaknin, a gifted painter and illustrator, for raising these issues. Why do we celebrate birthdays? What is it that we are toasting? Is it the fact that we have survived another year against many odds? Are we marking the progress we have made, our cumulative achievements and possessions? Is a birthday the expression of hope sprung eternal to live another year? 
None of the above, it would seem. 
If it is the past year that we are commemorating, would we still drink to it if we were to receive some bad news about our health and imminent demise? Not likely. But why? What is the relevance of information about the future (our own looming death) when one is celebrating the past? The past is immutable. No future event can vitiate the fact that we have made it through another 12 months of struggle. Then why not celebrate this fact? 
Because it is not the past that is foremost on our minds. Our birthdays are about the future, not about the past. We are celebrating having arrived so far because such successful resilience allows us to continue forward. We proclaim our potential to further enjoy the gifts of life. Birthdays are expressions of unbridled, blind faith in our own suspended mortality. 
But, if this were true, surely as we grow older we have less and less cause to celebrate. What reason do octogenarians have to drink to another year if that gift is far from guaranteed? Life offers diminishing returns: the longer you are invested, the less likely you are to reap the dividenda of survival. Indeed, based on actuary tables, it becomes increasingly less rational to celebrate one's future the older one gets. 
Thus, we are forced into the conclusion that birthdays are about self-delusionally defying death. Birthdays are about preserving the illusion of immortality. Birthdays are forms of acting out our magical thinking. By celebrating our existence, we bestow on ourselves protective charms against the meaninglessness and arbitrariness of a cold, impersonal, and often hostile universe. 
And, more often than not, it works. Happy birthday!
Brain, Metaphors of
The brain (and, by implication, the mind) have been compared to the latest technological innovation in every generation. The computer metaphor is now in vogue. Computer hardware metaphors were replaced by software metaphors and, lately, by (neuronal) network metaphors.
Metaphors are not confined to the philosophy of neurology. Architects and mathematicians, for instance, have lately come up with the structural concept of "tensegrity" to explain the phenomenon of life. The tendency of humans to see patterns and structures everywhere (even where there are none) is well documented and probably has its survival value.
Another trend is to discount these metaphors as erroneous, irrelevant, deceptive, and misleading. Understanding the mind is a recursive business, rife with self-reference. The entities or processes to which the brain is compared are also "brain-children", the results of "brain-storming", conceived by "minds". What is a computer, a software application, a communications network if not a (material) representation of cerebral events?
A necessary and sufficient connection surely exists between man-made things, tangible and intangible, and human minds. Even a gas pump has a "mind-correlate". It is also conceivable that representations of the "non-human" parts of the Universe exist in our minds, whether a-priori (not deriving from experience) or a-posteriori (dependent upon experience). This "correlation", "emulation", "simulation", "representation" (in short : close connection) between the "excretions", "output", "spin-offs", "products" of the human mind and the human mind itself - is a key to understanding it.
This claim is an instance of a much broader category of claims: that we can learn about the artist by his art, about a creator by his creation, and generally: about the origin by any of the derivatives, inheritors, successors, products and similes thereof.
This general contention is especially strong when the origin and the product share the same nature. If the origin is human (father) and the product is human (child) - there is an enormous amount of data that can be derived from the product and safely applied to the origin. The closer the origin to the product - the more we can learn about the origin from the product.
We have said that knowing the product - we can usually know the origin. The reason is that knowledge about product "collapses" the set of probabilities and increases our knowledge about the origin.  Yet, the converse is not always true. The same origin can give rise to many types of entirely unrelated products. There are too many free variables here. The origin exists as a "wave function": a series of potentialities with attached probabilities, the potentials being the logically and physically possible products.
What can we learn about the origin by a crude perusal to the product? Mostly observable structural and functional traits and attributes. We cannot learn a thing about the "true nature" of the origin. We can not know the "true nature" of anything. This is the realm of metaphysics, not of physics.
Take Quantum Mechanics. It provides an astonishingly accurate description of micro-processes and of the Universe without saying much about their "essence". Modern physics strives to provide correct predictions - rather than to expound upon this or that worldview. It describes - it does not explain. Where interpretations are offered (e.g., the Copenhagen interpretation of Quantum Mechanics) they invariably run into philosophical snags. Modern science uses metaphors (e.g., particles and waves). Metaphors have proven to be useful scientific tools in the "thinking scientist's" kit. As these metaphors develop, they trace the developmental phases of the origin.
Consider the software-mind metaphor.
The computer is a "thinking machine" (however limited, simulated, recursive and mechanical). Similarly, the brain is a "thinking machine" (admittedly much more agile, versatile, non-linear, maybe even qualitatively different). Whatever the disparity between the two, they must be related to one another.
This relation is by virtue of two facts: (1) Both the brain and the computer are "thinking machines" and (2) the latter is the product of the former. Thus, the computer metaphor is an unusually tenable and potent one. It is likely to be further enhanced should organic or quantum computers transpire.
At the dawn of computing, software applications were authored serially, in machine language and with strict separation of data (called: "structures") and instruction code (called: "functions" or "procedures"). The machine language reflected the physical wiring of the hardware.
This is akin to the development of the embryonic brain (mind). In the early life of the human embryo, instructions (DNA) are also insulated from data (i.e., from amino acids and other life substances).
In early computing, databases were handled on a "listing" basis ("flat file"), were serial, and had no intrinsic relationship to one another. Early databases constituted a sort of substrate, ready to be acted upon. Only when "intermixed" in the computer (as a software application was run) were functions able to operate on structures.
This phase was followed by the "relational" organization of data (a primitive example of which is the spreadsheet). Data items were related to each other through mathematical formulas. This is the equivalent of the increasing complexity of the wiring of the brain as pregnancy progresses.
The latest evolutionary phase in programming is OOPS (Object Oriented Programming Systems). Objects are modules which encompass both data and instructions in self contained units. The user communicates with the functions performed by these objects - but not with their structure and internal processes.
Programming objects, in other words, are "black boxes" (an engineering term). The programmer is unable to tell how the object does what it does, or how does an external, useful function arise from internal, hidden functions or structures. Objects are epiphenomenal, emergent, phase transient. In short: much closer to reality as described by modern physics.
Though these black boxes communicate - it is not the communication, its speed, or efficacy which determine the overall efficiency of the system. It is the hierarchical and at the same time fuzzy organization of the objects which does the trick. Objects are organized in classes which define their (actualized and potential) properties. The object's behaviour (what it does and what it reacts to) is defined by its membership of a class of objects.
Moreover, objects can be organized in new (sub) classes while inheriting all the definitions and characteristics of the original class in addition to new properties. In a way, these newly emergent classes are the products while the classes they are derived from are the origin. This process so closely resembles natural - and especially biological - phenomena that it lends additional force to the software metaphor.
Thus, classes can be used as building blocks. Their permutations define the set of all soluble problems. It can be proven that Turing Machines are a private instance of a general, much stronger, class theory (a-la Principia Mathematica). The integration of hardware (computer, brain) and software (computer applications, mind) is done through "framework applications" which match the two elements structurally and functionally. The equivalent in the brain  is sometimes called by philosophers and psychologists "a-priori categories", or "the collective unconscious".
Computers and their programming evolve. Relational databases cannot be integrated with object oriented ones, for instance. To run Java applets, a "virtual machine" needs to be embedded in the operating system. These phases closely resemble the development of the brain-mind couplet.
When is a metaphor a good metaphor? When it teaches us something new about the origin. It must possess some structural and functional resemblance. But this quantitative and observational facet is not enough. There is also a qualitative one: the metaphor must be instructive, revealing, insightful, aesthetic, and parsimonious - in short, it must constitute a theory and produce falsifiable predictions. A metaphor is also subject to logical and aesthetic rules and to the rigors of the scientific method.
If the software metaphor is correct, the brain must contain the following features:
1.	Parity checks through back propagation of signals. The brain's electrochemical signals must move back (to the origin) and forward, simultaneously, in order to establish a feedback parity loop. 
2.	The neuron cannot be a binary (two state) machine (a quantum computer is multi-state). It must have many levels of excitation (i.e., many modes of representation of information). The threshold ("all or nothing" firing) hypothesis must be wrong. 
3.	Redundancy must be built into all the aspects and dimensions of the brain and its activities. Redundant hardware -different centers to perform similar tasks. Redundant communications channels with the same information simultaneously transferred across them. Redundant retrieval of data and redundant usage of obtained data (through working, "upper" memory). 
4.	The basic concept of the workings of the brain must be the comparison of "representational elements" to "models of the world". Thus, a coherent picture is obtained which yields predictions and allows to manipulate the environment effectively. 
5.	Many of the functions tackled by the brain must be recursive. We can expect to find that we can reduce all the activities of the brain to computational, mechanically solvable, recursive functions. The brain can be regarded as a Turing Machine and the dreams of Artificial Intelligence are likely come true. 
6.	The brain must be a learning, self organizing, entity. The brain's very hardware must disassemble, reassemble, reorganize, restructure, reroute, reconnect, disconnect, and, in general, alter itself in response to data. In most man-made machines, the data is external to the processing unit. It enters and exits the machine through designated ports but does not affect the machine's structure or functioning. Not so the brain. It reconfigures itself with every bit of data. One can say that a new brain is created every time a single bit of information is processed. 
Only if these six cumulative requirements are met - can we say that the software metaphor is useful.
II. Non-consensual consumption of human flesh from a live source 
For example, when prisoners of war are butchered for the express purpose of being eaten by their victorious enemies. 
A notorious and rare representative of this category of cannibalism is the punitive ritual of being eaten alive. The kings of the tribes of the Cook Islands were thought to embody the gods. They punished dissent by dissecting their screaming and conscious adversaries and consuming their flesh piecemeal, eyeballs first.
The Sawney Bean family in Scotland, during the reign of King James I, survived for decades on the remains (and personal belongings) of victims of their murderous sprees.
Real-life serial killers, like Jeffrey Dahmer, Albert Fish, Sascha Spesiwtsew, Fritz Haarmann, Issei Sagawa, and Ed Gein, lured, abducted, and massacred countless people and then consumed their flesh and preserved the inedible parts as trophies. These lurid deeds inspired a slew of books and films, most notably The Silence of the Lambs with Hannibal (Lecter) the Cannibal as its protagonist.
III. Consensual consumption of human flesh from live and dead human bodies
Armin Meiwes, the "Master Butcher (Der Metzgermeister)", arranged over the Internet to meet Bernd Jurgen Brandes on March 2001. Meiwes amputated the penis of his guest and they both ate it. He then proceeded to kill Brandes (with the latter's consent recorded on video), and snack on what remained of him. Sexual cannibalism is a paraphilia and an extreme - and thankfully, rare - form of fetishism. 
The Aztecs willingly volunteered to serve as human sacrifices (and to be tucked into afterwards). They firmly believed that they were offerings, chosen by the gods themselves, thus being rendered immortal. 
Dutiful sons and daughters in China made their amputated organs and sliced tissues (mainly the liver) available to their sick parents (practices known as Ko Ku and Ko Kan). Such donation were considered remedial. Princess Miao Chuang who surrendered her severed hands to her ailing father was henceforth deified.
Non-consensual cannibalism is murder, pure and simple. The attendant act of cannibalism, though aesthetically and ethically reprehensible, cannot aggravate this supreme assault on all that we hold sacred.
But consensual cannibalism is a lot trickier. Modern medicine, for instance, has blurred the already thin line between right and wrong. 
What is the ethical difference between consensual, post-mortem, organ harvesting and consensual, post-mortem cannibalism?
Why is stem cell harvesting (from aborted fetuses) morally superior to consensual post-mortem cannibalism?
When members of a plane-wrecked rugby team, stranded on an inaccessible, snow-piled, mountain range resort to eating each other in order to survive, we turn a blind eye to their repeated acts of cannibalism - but we condemn the very same deed in the harshest terms if it takes place between two consenting, and even eager adults in Germany. Surely, we don't treat murder, pedophilia, and incest the same way! 
As the Auxiliary Bishop of Montevideo said after the crash:
"... Eating someone who has died in order to survive is incorporating their substance, and it is quite possible to compare this with a graft. Flesh survives when assimilated by someone in extreme need, just as it does when an eye or heart of a dead man is grafted onto a living man..."
(Read, P.P. 1974. Alive. Avon, New York)
Complex ethical issues are involved in the apparently straightforward practice of consensual cannibalism.
Consensual, in vivo, cannibalism (a-la Messrs. Meiwes and Brandes) resembles suicide. The cannibal is merely the instrument of voluntary self-destruction. Why would we treat it different to the way we treat any other form of suicide pact?
Consensual cannibalism is not the equivalent of drug abuse because it has no social costs. Unlike junkies, the cannibal and his meal are unlikely to harm others. What gives society the right to intervene, therefore? 
If we own our bodies and, thus, have the right to smoke, drink, have an abortion, commit suicide, and will our organs to science after we die - why don't we possess the inalienable right to will our delectable tissues to a discerning cannibal post-mortem (or to victims of famine in Africa)?
When does our right to dispose of our organs in any way we see fit crystallize? Is it when we die? Or after we are dead? If so, what is the meaning and legal validity of a living will? And why can't we make a living will and bequeath our cadaverous selves to the nearest cannibal? 
Do dead people have rights and can they claim and invoke them while they are still alive? Is the live person the same as his dead body, does he "own" it, does the state have any rights in it? Does the corpse stll retain its previous occupant's "personhood"? Are cadavers still human, in any sense of the word?
We find all three culinary variants abhorrent. Yet, this instinctive repulsion is a curious matter. The onerous demands of survival should have encouraged cannibalism rather than make it a taboo. Human flesh is protein-rich. Most societies, past and present (with the exception of the industrialized West), need to make efficient use of rare protein-intensive resources.
If cannibalism enhances the chances of survival - why is it universally prohibited? For many a reason.
I. The Sanctity of Life
Historically, cannibalism preceded, followed, or precipitated an act of murder or extreme deprivation (such as torture). It habitually clashed with the principle of the sanctity of life. Once allowed, even under the strictest guidelines, cannibalism tended to debase and devalue human life and foster homicide, propelling its practitioners down a slippery ethical slope towards bloodlust and orgiastic massacres.
II. The Afterlife
Moreover, in life, the human body and form are considered by most religions (and philosophers) to be the abode of the soul, the divine spark that animates us all. The post-mortem integrity of this shrine is widely thought to guarantee a faster, unhindered access to the afterlife, to immortality, and eventual reincarnation (or karmic cycle in eastern religions). 
For this reason, to this very day, orthodox Jews refuse to subject their relatives to a post-mortem autopsy and organ harvesting. Fijians and Cook Islanders used to consume their enemies' carcasses in order to prevent their souls from joining hostile ancestors in heaven.
III. Chastening Reminders
Cannibalism is a chilling reminder of our humble origins in the animal kingdom. To the cannibal, we are no better and no more than cattle or sheep. Cannibalism confronts us with the irreversibility of our death and its finality. Surely, we cannot survive our demise with our cadaver mutilated and gutted and our skeletal bones scattered, gnawed, and chewed on?
IV. Medical Reasons
Infrequently, cannibalism results in prion diseases of the nervous system, such as kuru. The same paternalism that gave rise to the banning of drug abuse, the outlawing of suicide, and the Prohibition of alcoholic drinks in the 1920s - seeks to shelter us from the pernicious medical outcomes of cannibalism and to protect others who might become our victims.
V. The Fear of Being Objectified
Being treated as an object (being objectified) is the most torturous form of abuse. People go to great lengths to seek empathy and to be perceived by others as three dimensional entities with emotions, needs, priorities, wishes, and preferences. 
The cannibal reduces others by treating them as so much meat. Many cannibal serial killers transformed the organs of their victims into trophies. The Cook Islanders sought to humiliate their enemies by eating, digesting, and then defecating them - having absorbed their mana (prowess, life force) in the process.
VI. The Argument from Nature
Cannibalism is often castigated as "unnatural". Animals, goes the myth, don't prey on their own kind.
Alas, like so many other romantic lores, this is untrue. Most species - including our closest relatives, the chimpanzees - do cannibalize. Cannibalism in nature is widespread and serves diverse purposes such as population control (chickens, salamanders, toads), food and protein security in conditions of scarcity (hippopotamuses, scorpions, certain types of dinosaurs), threat avoidance (rabbits, mice, rats, and hamsters), and the propagation of genetic material through exclusive mating (Red-back spider and many mantids).
Moreover, humans are a part of nature. Our deeds and misdeeds are natural by definition. Seeking to tame nature is a natural act. Seeking to establish hierarchies and subdue or relinquish our enemies are natural propensities. By avoiding cannibalism we seek to transcend nature. Refraining from cannibalism is the unnatural act.
VIII. The Argument from Progress
It is a circular syllogism involving a tautology and goes like this:
Cannibalism is barbaric. Cannibals are, therefore, barbarians. Progress entails the abolition of this practice.
The premises - both explicit and implicit - are axiomatic and, therefore, shaky. What makes cannibalism barbarian? And why is progress a desirable outcome? There is a prescriptive fallacy involved, as well:
Because we do not eat the bodies of dead people - we ought not to eat them.
VIII. Arguments from Religious Ethics
The major monotheistic religions are curiously mute when it comes to cannibalism. Human sacrifice is denounced numerous times in the Old Testament - but man-eating goes virtually unmentioned. The Eucharist in Christianity - when the believers consume the actual body and blood of Jesus - is an act of undisguised cannibalism:
"That the consequence of Transubstantiation, as a conversion of the total substance, is the transition of the entire substance of the bread and wine into the Body and Blood of Christ, is the express doctrine of the Church ...."
(Catholic Encyclopedia)
"CANON lI.-If any one saith, that, in the sacred and holy sacrament of the Eucharist, the substance of the bread and wine remains conjointly with the body and blood of our Lord Jesus Christ, and denieth that wonderful and singular conversion of the whole substance of the bread into the Body, and of the whole substance of the wine into the Blood-the species Only of the bread and wine remaining-which conversion indeed the Catholic Church most aptly calls Transubstantiation; let him be anathema. 
CANON VIII.-lf any one saith, that Christ, given in the Eucharist, is eaten spiritually only, and not also sacramentally and really; let him be anathema."
(The Council of Trent, The Thirteenth Session - The canons and decrees of the sacred and oecumenical Council of Trent, Ed. and trans. J. Waterworth (London: Dolman, 1848), 75-91.)
Still, most systems of morality and ethics impute to Man a privileged position in the scheme of things (having been created in the "image of God"). Men and women are supposed to transcend their animal roots and inhibit their baser instincts (an idea incorporated into Freud's tripartite model of the human psyche). The anthropocentric chauvinistic view is that it is permissible to kill all other animals in order to consume their flesh. Man, in this respect, is sui generis.
Yet, it is impossible to rigorously derive a prohibition to eat human flesh from any known moral system. As Richard Routley-Silvan observes in his essay "In Defence of Cannibalism", that something is innately repugnant does not make it morally prohibited. Moreover, that we find cannibalism nauseating is probably the outcome of upbringing and conditioning rather than anything innate.
Causes, External
Some philosophers say that our life is meaningless because it has a prescribed end. This is a strange assertion: is a movie rendered meaningless because of its finiteness? Some things acquire a meaning precisely because they are finite: consider academic studies, for instance. It would seem that meaningfulness does not depend upon matters temporary.
We all share the belief that we derive meaning from external sources. Something bigger than us – and outside us – bestows meaning upon our lives: God, the State, a social institution, an historical cause.
Yet, this belief is misplaced and mistaken. If such an external source of meaning were to depend upon us for its definition (hence, for its meaning) – how could we derive meaning from it? A cyclical argument ensues. We can never derive meaning from that whose very meaning (or definition) is dependent on us. The defined cannot define the definer. To use the defined as part of its own definition (by the vice of its inclusion in the definer) is the very definition of a tautology, the gravest of logical fallacies.
On the other hand: if such an external source of meaning were NOT dependent on us for its definition or meaning – again it would have been of no use in our quest for meaning and definition. That which is absolutely independent of us – is absolutely free of any interaction with us because such an interaction would inevitably have constituted a part of its definition or meaning. And that, which is devoid of any interaction with us – cannot be known to us. We know about something by interacting with it. The very exchange of information – through the senses - is an interaction.
Thus, either we serve as part of the definition or the meaning of an external source – or we do not. In the first case, it cannot constitute a part of our own definition or meaning. In the second case, it cannot be known to us and, therefore, cannot be discussed at all. Put differently: no meaning can be derived from an external source.
Despite the above said, people derive meaning almost exclusively from external sources. If a sufficient number of questions is asked, we will always reach an external source of meaning. People believe in God and in a divine plan, an order inspired by Him and manifest in both the inanimate and the animate universe. Their lives acquire meaning by realizing the roles assigned to them by this Supreme Being. They are defined by the degree with which they adhere to this divine design. Others relegate the same functions to the Universe (to Nature). It is perceived by them to be a grand, perfected, design, or mechanism. Humans fit into this mechanism and have roles to play in it. It is the degree of their fulfilment of these roles which characterizes them, provides their lives with meaning and defines them.
Other people attach the same endowments of meaning and definition to human society, to Mankind, to a given culture or civilization, to specific human institutions (the Church, the State, the Army), or to an ideology. These human constructs allocate roles to individuals. These roles define the individuals and infuse their lives with meaning. By becoming part of a bigger (external) whole – people acquire a sense of purposefulness, which is confused with meaningfulness. Similarly, individuals confuse their functions, mistaking them for their own definitions. In other words: people become defined by their functions and through them. They find meaning in their striving to attain goals.
Perhaps the biggest and most powerful fallacy of all is teleology. Again, meaning is derived from an external source: the future. People adopt goals, make plans to achieve them and then turn these into the raisons d'etre of their lives. They believe that their acts can influence the future in a manner conducive to the achievement of their pre-set goals. They believe, in other words, that they are possessed of free will and of the ability to exercise it in a manner commensurate with the attainment of their goals in accordance with their set plans. Furthermore, they believe that there is a physical, unequivocal, monovalent interaction between their free will and the world.
This is not the place to review the mountainous literature pertaining to these (near eternal) questions: is there such a thing as free will or is the world deterministic? Is there causality or just coincidence and correlation? Suffice it to say that the answers are far from being clear-cut. To base one's notions of meaningfulness and definition on any of them would be a rather risky act, at least philosophically.
But, can we derive meaning from an inner source? After all, we all "emotionally, intuitively, know" what is meaning and that it exists. If we ignore the evolutionary explanation (a false sense of meaning was instilled in us by Nature because it is conducive to survival and it motivates us to successfully prevail in hostile environments) - it follows that it must have a source somewhere. If the source is internal – it cannot be universal and it must be idiosyncratic. Each one of us has a different inner environment. No two humans are alike. A meaning that springs forth from a unique inner source – must be equally unique and specific to each and every individual. Each person, therefore, is bound to have a different definition and a different meaning. This may not be true on the biological level. We all act in order to maintain life and increase bodily pleasures. But it should definitely hold true on the psychological and spiritual levels. On those levels, we all form our own narratives. Some of them are derived from external sources of meaning – but all of them rely heavily on inner sources of meaning. The answer to the last in a chain of questions will always be: "Because it makes me feel good".
In the absence of an external, indisputable, source of meaning – no rating and no hierarchy of actions are possible. An act is preferable to another (using any criterion of preference) only if there is an outside source of judgement or of comparison.
Paradoxically, it is much easier to prioritize acts with the use of an inner source of meaning and definition. The pleasure principle ("what gives me more pleasure") is an efficient (inner-sourced) rating mechanism. To this eminently and impeccably workable criterion, we usually attach another, external, one (ethical and moral, for instance). The inner criterion is really ours and is a credible and reliable judge of real and relevant preferences. The external criterion is nothing but a defence mechanism embedded in us by an external source of meaning. It comes to defend the external source from the inevitable discovery that it is meaningless.
Child Labor
From the comfort of their plush offices and five to six figure salaries, self-appointed NGO's often denounce child labor as their employees rush from one five star hotel to another, $3000 subnotebooks and PDA's in hand. The hairsplitting distinction made by the ILO between "child work" and "child labor" conveniently targets impoverished countries while letting its budget contributors - the developed ones - off-the-hook.
Reports regarding child labor surface periodically. Children crawling in mines, faces ashen, body deformed. The agile fingers of famished infants weaving soccer balls for their more privileged counterparts in the USA. Tiny figures huddled in sweatshops, toiling in unspeakable conditions. It is all heart-rending and it gave rise to a veritable not-so-cottage industry of activists, commentators, legal eagles, scholars, and opportunistically sympathetic politicians.
Ask the denizens of Thailand, sub-Saharan Africa, Brazil, or Morocco and they will tell you how they regard this altruistic hyperactivity - with suspicion and resentment. Underneath the compelling arguments lurks an agenda of trade protectionism, they wholeheartedly believe. Stringent - and expensive - labor and environmental provisions in international treaties may well be a ploy to fend off imports based on cheap labor and the competition they wreak on well-ensconced domestic industries and their political stooges.
This is especially galling since the sanctimonious West has amassed its wealth on the broken backs of slaves and kids. The 1900 census in the USA found that 18 percent of all children - almost two million in all - were gainfully employed. The Supreme Court ruled unconstitutional laws banning child labor as late as 1916. This decision was overturned only in 1941.
The GAO published a report last week in which it criticized the Labor Department for paying insufficient attention to working conditions in manufacturing and mining in the USA, where many children are still employed. The Bureau of Labor Statistics pegs the number of working children between the ages of 15-17 in the USA at 3.7 million. One in 16 of these worked in factories and construction. More than 600 teens died of work-related accidents in the last ten years.
Child labor - let alone child prostitution, child soldiers, and child slavery - are phenomena best avoided. But they cannot and should not be tackled in isolation. Nor should underage labor be subjected to blanket castigation. Working in the gold mines or fisheries of the Philippines is hardly comparable to waiting on tables in a Nigerian or, for that matter, American restaurant.
There are gradations and hues of child labor. That children should not be exposed to hazardous conditions, long working hours, used as means of payment, physically punished, or serve as sex slaves is commonly agreed. That they should not help their parents plant and harvest may be more debatable.
As Miriam Wasserman observes in "Eliminating Child Labor", published in the Federal Bank of Boston's "Regional Review", second quarter of 2000, it depends on "family income, education policy, production technologies, and cultural norms." About a quarter of children under-14 throughout the world are regular workers. This statistic masks vast disparities between regions like Africa (42 percent) and Latin America (17 percent).
In many impoverished locales, child labor is all that stands between the family unit and all-pervasive, life threatening, destitution. Child labor declines markedly as income per capita grows. To deprive these bread-earners of the opportunity to lift themselves and their families incrementally above malnutrition, disease, and famine - is an apex of immoral hypocrisy.
Quoted by "The Economist", a representative of the much decried Ecuador Banana Growers Association and Ecuador's Labor Minister, summed up the dilemma neatly: "Just because they are under age doesn't mean we should reject them, they have a right to survive. You can't just say they can't work, you have to provide alternatives."
Regrettably, the debate is so laden with emotions and self-serving arguments that the facts are often overlooked.
The outcry against soccer balls stitched by children in Pakistan led to the relocation of workshops ran by Nike and Reebok. Thousands lost their jobs, including countless women and 7000 of their progeny. The average family income - anyhow meager - fell by 20 percent. Economists Drusilla Brown, Alan Deardorif, and Robert Stern observe wryly:
"While Baden Sports can quite credibly claim that their soccer balls are not sewn by children, the relocation of their production facility undoubtedly did nothing for their former child workers and their families."
Such examples abound. Manufacturers - fearing legal reprisals and "reputation risks" (naming-and-shaming by overzealous NGO's) - engage in preemptive sacking. German garment workshops fired 50,000 children in Bangladesh in 1993 in anticipation of the American never-legislated Child Labor Deterrence Act.
Quoted by Wasserstein, former Secretary of Labor, Robert Reich, notes:
"Stopping child labor without doing anything else could leave children worse off. If they are working out of necessity, as most are, stopping them could force them into prostitution or other employment with greater personal dangers. The most important thing is that they be in school and receive the education to help them leave poverty."
Contrary to hype, three quarters of all children work in agriculture and with their families. Less than 1 percent work in mining and another 2 percent in construction. Most of the rest work in retail outlets and services, including "personal services" - a euphemism for prostitution. UNICEF and the ILO are in the throes of establishing school networks for child laborers and providing their parents with alternative employment.
But this is a drop in the sea of neglect. Poor countries rarely proffer education on a regular basis to more than two thirds of their eligible school-age children. This is especially true in rural areas where child labor is a widespread blight. Education - especially for women - is considered an unaffordable luxury by many hard-pressed parents. In many cultures, work is still considered to be indispensable in shaping the child's morality and strength of character and in teaching him or her a trade.
"The Economist" elaborates:
"In Africa children are generally treated as mini-adults; from an early age every child will have tasks to perform in the home, such as sweeping or fetching water. It is also common to see children working in shops or on the streets. Poor families will often send a child to a richer relation as a housemaid or houseboy, in the hope that he will get an education."
A solution recently gaining steam is to provide families in poor countries with access to loans secured by the future earnings of their educated offspring. The idea - first proposed by Jean-Marie Baland of the University of Namur and James A. Robinson of the University of California at Berkeley - has now permeated the mainstream.
Even the World Bank has contributed a few studies, notably, in June, "Child Labor: The Role of Income Variability and Access to Credit Across Countries" authored by Rajeev Dehejia of the NBER and Roberta Gatti of the Bank's Development Research Group.
Abusive child labor is abhorrent and should be banned and eradicated. All other forms should be phased out gradually. Developing countries already produce millions of unemployable graduates a year - 100,000 in Morocco alone. Unemployment is rife and reaches, in certain countries - such as Macedonia - more than one third of the workforce. Children at work may be harshly treated by their supervisors but at least they are kept off the far more menacing streets. Some kids even end up with a skill and are rendered employable.
Chinese Room
Whole forests have been wasted in the effort to refute the Chinese Room Thought Experiment proposed by Searle in 1980 and refined (really derived from axioms) in 1990. The experiment envisages a room in which an English speaker sits, equipped with a book of instructions in English. Through one window messages in Chinese are passed on to him (in the original experiment, two types of messages). He is supposed to follow the instructions and correlate the messages received with other pieces of paper, already in the room, also in Chinese. This collage he passes on to the outside through yet another window. The comparison with a computer is evident. There is input, a processing unit and output. What Searle tried to demonstrate is that there is no need to assume that the central processing unit (the English speaker) understands (or, for that matter, performs any other cognitive or mental function) the input or the output (both in Chinese). Searle generalized and stated that this shows that computers will never be capable of thinking, being conscious, or having other mental states. In his picturesque language "syntax is not a sufficient base for semantics". Consciousness is not reducible to computations. It takes a certain "stuff" (the brain) to get these results.
Objections to the mode of presentation selected by Searle and to the conclusions that he derived were almost immediately raised. Searle fought back effectively. But throughout these debates a few points seemed to have escaped most of those involved.
First, the English speaker inside the room himself is a conscious entity, replete and complete with mental states, cognition, awareness and emotional powers. Searle went to the extent of introducing himself to the Chinese Room (in his disputation). Whereas Searle would be hard pressed to prove (to himself) that the English speaker in the room is possessed of mental states – this is not the case if he himself were in the room. The Cartesian maxim holds: "Cogito, ergo sum". But this argument – though valid – is not strong. The English speaker (and Searle, for that matter) can easily be replaced in the thought experiment by a Turing machine. His functions are recursive and mechanical.
But there is a much more serious objection. Whomever composed the book of instructions must have been conscious, possessed of mental states and of cognitive processes. Moreover, he must also have had a perfect understanding of Chinese to have authored it. It must have been an entity capable of thinking, analysing, reasoning, theorizing and predicting in the deepest senses of the words. In other words: it must have been intelligent. So, intelligence (we will use it hitherto as a catchphrase for the gamut of mental states) was present in the Chinese Room. It was present in the book of instructions and it was present in the selection of the input of Chinese messages and it was present when the results were deciphered and understood. An intelligent someone must have judged the results to have been coherent and "right". An intelligent agent must have fed the English speaker with the right input. A very intelligent, conscious, being with a multitude of cognitive mental states must have authored the "program" (the book of instructions). Depending on the content of correlated inputs and outputs, it is conceivable that this intelligent being was also possessed of emotions or an aesthetic attitude as we know it. In the case of real life computers – this would be the programmer.
But it is the computer that Searle is talking about – not its programmer, or some other, external source of intelligence. The computer is devoid of intelligence, the English speaker does not understand Chinese (="Mentalese")– not the programmer (or who authored the book of instructions). Yet, is the SOURCE of the intelligence that important? Shouldn't we emphasize the LOCUS (site) of the intelligence, where it is stored and used?
Surely, the programmer is the source of any intelligence that a computer possesses. But is this relevant? If the computer were to effectively make use of the intelligence bestowed upon it by the programmer – wouldn't we say that it is intelligent? If tomorrow we will discover that our mental states are induced in us by a supreme intelligence (known to many as God) – should we then say that we are devoid of mental states? If we were to discover in a distant future that what we call "our" intelligence is really a clever program run from a galactic computer centre – will we then feel less entitled to say that we are intelligent? Will our subjective feelings, the way that we experience our selves, change in the wake of this newly acquired knowledge? Will we no longer feel the mental states and the intelligence that we used to feel prior to these discoveries? If Searle were to live in that era – would he have declared himself devoid of mental, cognitive, emotional and intelligent states – just because the source and the mechanism of these phenomena have been found out to be external or remote? Obviously, not. Where the intelligence emanates from, what is its source, how it is conferred, stored, what are the mechanisms of its bestowal – are all irrelevant to the question whether a given entity is intelligent. The only issue relevant is whether the discussed entity is possessed of intelligence, contains intelligence, has intelligent components, stores intelligence and is able to make a dynamic use of it. The locus and its properties (behaviour) matter. If a programmer chose to store intelligence in a computer – then he created an intelligent computer. He conferred his intelligence onto the computer. Intelligence can be replicated endlessly. There is no quantitative law of conservation of mental states. We teach our youngsters – thereby replicating our knowledge and giving them copies of it without "eroding" the original. We shed tears in the movie theatre because the director succeeded to replicate an emotion in us – without losing one bit of original emotion captured on celluloid.
Consciousness, mental states, intelligence are transferable and can be stored and conferred. Pregnancy is a process of conferring intelligence. The book of instructions is stored in our genetic material. We pass on this book to our off spring. The decoding and unfolding of the book are what we call the embryonic phases. Intelligence, therefore, can (and is) passed on (in this case, through the genetic material, in other words: through hardware).
We can identify an emitter (or transmitter) of mental states and a receiver of mental states (equipped with an independent copy of a book of instructions). The receiver can be passive (as television is). In such a case we will not be justified in saying that it is "intelligent" or has a mental life. But – if it possesses the codes and the instructions – it could make independent use of the data, process it, decide upon it, pass it on, mutate it, transform it, react to it. In the latter case we will not be justified in saying that the receiver does NOT possess intelligence or mental states. Again, the source, the trigger of the mental states are irrelevant. What is relevant is to establish that the receiver has a copy of the intelligence or of the other mental states of the agent (the transmitter). If so, then it is intelligent in its own right and has a mental life of its own.
Must the source be point-like, an identifiable unit? Not necessarily. A programmer is a point-like source of intelligence (in the case of a computer). A parent is a point-like source of mental states (in the case of his child). But other sources are conceivable.
For instance, we could think about mental states as emergent. Each part of an entity might not demonstrate them. A neurone cell in the brain has no mental states of it own. But when a population of such parts crosses a quantitatively critical threshold – an epiphenomenon occurs. When many neurones are interlinked – the results are mental states and intelligence. The quantitative critical mass – happens also to be an important qualitative threshold.
Imagine a Chinese Gymnasium instead of a Chinese Room. Instead of one English speaker – there is a multitude of them. Each English speaker is the equivalent of a neurone. Altogether, they constitute a brain. Searle says that if one English speaker does not understand Chinese, it would be ridiculous to assume that a multitude of English speakers would. But reality shows that this is exactly what will happen. A single molecule of gas has no temperature or pressure. A mass of them – does. Where did the temperature and pressure come from? Not from any single molecule – so we are forced to believe that both these qualities emerged. Temperature and pressure (in the case of gas molecules), thinking (in the case of neurones) – are emergent phenomena.
All we can say is that there seems to be an emergent source of mental states. As an embryo develops, it is only when it crosses a certain quantitative threshold (number of differentiated cells) – that he begins to demonstrate mental states. The source is not clear – but the locus is. The residence of the mental states is always known – whether the source is point-like and identifiable, or diffusely emerges as an epiphenomenon.
It is because we can say very little about the source of mental states – and a lot about their locus, that we developed an observer bias. It is much easier to observe mental states in their locus – because they create behaviour. By observing behaviour – we deduce the existence of mental states. The alternative is solipsism (or religious panpsychism, or mere belief). The dichotomy is clear and painful: either we, as observers, cannot recognize mental states, in principle – or, we can recognize them only through their products.
Consider a comatose person. Does he have a mental life going on? Comatose people have been known to have reawakened in the past. So, we know that they are alive in more than the limited physiological sense. But, while still, do they have a mental life of any sort?
We cannot know. This means that in the absence of observables (behaviour, communication) – we cannot be certain that mental states exist. This does not mean that mental states ARE those observables (a common fallacy). This says nothing about the substance of mental states. This statement is confined to our measurements and observations and to their limitations. Yet, the Chinese Room purports to say something about the black box that we call "mental states". It says that we can know (prove or refute) the existence of a TRUE mental state – as distinct from a simulated one. That, despite appearances, we can tell a "real" mental state apart from its copy. Confusing the source of the intelligence with its locus is at the bottom of this thought experiment. It is conceivable to have an intelligent entity with mental states – that derives (or derived) its intelligence and mental states from a point-like source or acquired these properties in an emergent, epiphenomenal way. The identity of the source and the process through which the mental states were acquired are irrelevant. To say that the entity is not intelligent (the computer, the English speaker) because it got its intelligence from the outside (the programmer) – is like saying that someone is not rich because he got his millions from the national lottery.
Cloning
In a paper, published in "Science" in May 2005, 25 scientists, led by Woo Suk Hwang of Seoul National University, confirmed that they were able to clone dozens of blastocysts (the clusters of tiny cells that develop into embryos). Blastocysts contain stem cells that can be used to generate replacement tissues and, perhaps, one day, whole organs. The fact that cloned cells are identical to the original cell guarantees that they will not be rejected by the immune system of the recipient.
The results were later proven faked by the disgraced scientist - but they pointed the way for future research non the less.
There are two types of cloning. One involves harvesting stem cells from embryos ("therapeutic cloning"). Stem cells are the biological equivalent of a template or a blueprint. They can develop into any kind of mature functional cell and thus help cure many degenerative and auto-immune diseases.
The other kind of cloning, known as "nuclear transfer", is much decried in popular culture - and elsewhere - as the harbinger of a Brave, New World. A nucleus from any cell of a donor is embedded in an (either mouse or human) egg whose own nucleus has been removed. The egg can then be coaxed into growing specific kinds of tissues (e.g., insulin-producing cells or nerve cells). These can be used in a variety of treatments.
Opponents of the procedure point out that when a treated human egg is implanted in a woman's womb a cloned baby will be born nine months later. Biologically, the infant is a genetic replica of the donor. When the donor of both nucleus and egg is the same woman, the process is known as "auto-cloning" (which was achieved by Woo Suk Hwang).
Cloning is often confused with other advances in bio-medicine and bio-engineering - such as genetic selection. It cannot - in itself - be used to produce "perfect humans" or select sex or other traits. Hence, some of the arguments against cloning are either specious or fuelled by ignorance.
It is true, though, that cloning, used in conjunction with other bio-technologies, raises serious bio-ethical questions. Scare scenarios of humans cultivated in sinister labs as sources of spare body parts, "designer babies", "master races", or "genetic sex slaves" - formerly the preserve of B sci-fi movies - have invaded mainstream discourse.
Still, cloning touches upon Mankind's most basic fears and hopes. It invokes the most intractable ethical and moral dilemmas. As an inevitable result, the debate is often more passionate than informed.
See the Appendix - Arguments from the Right to Life
But is the Egg - Alive?
This question is NOT equivalent to the ancient quandary of "when does life begin". Life crystallizes, at the earliest, when an egg and a sperm unite (i.e., at the moment of fertilization). Life is not a potential - it is a process triggered by an event. An unfertilized egg is neither a process - nor an event. It does not even possess the potential to become alive unless and until it merges with a sperm. Should such merger not occur - it will never develop life.
The potential to become X is not the ontological equivalent of actually being X, nor does it spawn moral and ethical rights and obligations pertaining to X. The transition from potential to being is not trivial, nor is it automatic, or inevitable, or independent of context. Atoms of various elements have the potential to become an egg (or, for that matter, a human  being) - yet no one would claim that they ARE an egg (or a human being), or that they should be treated as one (i.e., with the same rights and obligations).
Moreover, it is the donor nucleus embedded in the egg that endows it with life - the life of the cloned baby. Yet, the nucleus is usually extracted from a muscle or the skin. Should we treat a muscle or a skin cell with the same reverence the critics of cloning wish to accord an unfertilized egg?



