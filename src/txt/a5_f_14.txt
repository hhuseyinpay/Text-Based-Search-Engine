Semiconductors
6.1 Electrons through a Vacuum
In the first section of the book, we’ve introduced to electronics, electrical
power, and how it relates to the computer system. In order to continue
our study, we need to start focusing on some of the specifics of what
makes a computer operate. This section of the book is centered around
the processor—the brain that makes the computer tick.
Today’s processors are made of millions of tiny semiconductor transistors.
So before we can get too far into our study of processors we need
to take a look at the building blocks of those transistors.
The Edison Effect
When Thomas Edison was working on his incandescent bulb design in
the 1880s, he ended up choosing a filament made of burnt bamboo.
However, after a few hours of time, carbon from the filament built up
on the inside walls of the bulb causing it to turn black.
Edison wanted to understand why this was happening. The carbon
appeared to be coming from filament toward the power supply and
was moving through the vacuum to the walls of the bulb. He surmised
that the carbon must be able to carry electrical current even through
the vacuum. Edison knew that the particles leaving the filament were
negatively charged. To help, he added a second electrode to the bulb,
between the filament and the bulb, like in Figure 6.1, on the next page.
He reasoned that if he was able to place some positive charge onto this
electrode it would attract the carbon and keep it from sticking to the
wall.
ELECTRONS THROUGH A VACUUM 100
Filament
Metal Plate
Figure 6.1: Edison’s Bulb with Added Electrode and Plate
He found something strange: when the polarity of the electrode was positive
with respect to the filament, current would flow into the electrode.
However, when the polarities were reversed no current would flow.
Edison was not able to explain the reason why (and the electron would
not be identified until some years later). His added electrode did not
change the blackening problem caused by the carbon either. So he
simply filed it away as an interesting concept and moved on to other
projects. He did, however, file a patent on his device in case it turned
out to have some special commercial application.
The Electron (Vacuum) Tube
Edison had showed his invention to many people, including a British
professor named Ambrose Fleming. Fleming had experimented greatly
with the device. He found that it rectified AC current into DC. But there
was still a lack of understanding as to why the device worked. Then,
in 1889 Joseph Thompson discovered subatomic particles. Fleming
quickly realized that the electron was being emitted from the filament
and it gave reason as to why a positively charge electrode would attract
them.
Based on his knowledge, Fleming created what he called an “Oscillation
Valve”, the first formal diode. He had been working a lot with wireless
ELECTRONS THROUGH A VACUUM 101
Filament
Metal Plate
Grid
Figure 6.2: DeForest’s Audion
B B 1
0 1 1
1 0 1
1 1 0
The Buzz. . .
What’s a Crystal Detector?
Some natural minerals are able to detect radio signals. Using
one of these materials along with a very thin wire known as
a cat whisker, a capacitor, and an inductor, a circuit can be
created that is able to receive radio signals.
communications and this invention was very helpful in the detection of
the wireless signals.
Despite its apparent usefulness, the oscillation valve was not widely
used. It was expensive to make and used a large amount of power.
Competing devices resulted including a crystal detector (see The Buzz).
But investigations into vacuum tube technology continued. In 1907,
Lee DeForest added a third electrode made of a grid mesh as shown in
Figure 6.2. He found that by varying the amount of negative charge on
the grid, he could control the amount of current that flowed through
the two other electrodes. He called his invention the Audion.
DeForest had no idea how profound his invention was. Vacuum tubes
SEMICONDUCTORS 102
were ideal for amplification. One interested customer, A.T.&.T. became
interested in being able to broadcast voice signals further—even all the
way across the country. They bought the patent from DeForest.
Over time, new applications for vacuum electron tubes were found. New
devices with more electrodes were invented that allowed other types of
control. But nothing was able to overcome how large and bulky vacuum
tubes were. The heat generated by the electrodes made large scale use
impractical.
Luckily, some scientists were searching for a replacement to the vacuum
tube. We discuss this replacement, the solid state transistor, in
more detail in Chapter 7, Transistors, on page 109. However, to understand
how this replacement works we have to look into the physics of
semiconductors.
6.2 Semiconductors
From the name, you can probably infer that semiconductors are just
average conductors. The main features of a natural semiconductor are:
• A higher resistance than metal conductors, but a lower resistance
than insulators.
• A valence number of +4. (refer to Appendix A, on page 217 for a
refresher on what this means)
The two most commonly used semiconductor elements are Silicon and
Germanium. Their +4 valence numbers mean that they have a very
stable covalent bond structure, as seen in Figure 6.4, on page 104. In
its natural form like this, semiconductor silicon is known as an intrinsic
semiconductor.
One way that semiconductors differ from conductors, such as metals,
is in their how their resistances change with temperature. In metals, a
rise in temperature causes the atoms to exhibit more vibration which
creates collisions in the structure, impeding the flow of electrons. In
a semiconductor, however, added heat actually causes the resistance
to decrease. This is because the added energy goes into the valence
electrons and makes it easier for them to jump into the conduction
band and become charge carriers.
SEMICONDUCTORS 103
Lead Bismuth
+3 +4 +5
Figure 6.3: The periodic table of +3,+4, and +5 valence elements
DOPING 104
Si
Figure 6.4: silicon’s covalent bond structure
6.3 Doping
The usefulness of pure silicon as a semiconductor is limited. However, if
we add small amounts of non-silicon material into the structure things
become much more interesting.
This process of adding impurities to a semiconductor is known as doping.
Doping results in extrinsic semiconductors, meaning they are not
in their natural form.
Since a normal semiconductor has a valence of +4, a small amount of
impurity will cause a charge imbalance. Take for instance the adding
of a phosphorus atom to the structure as in Figure 6.5, on the next
page. This phosphorus atom in the structure bonds with the silicon
atoms around it. However, with its valence of +5, it has an extra electron
available for bonding that is unused in the structure.
Doping a pure semiconductor with a small amount of material with a
valence number of +5 (which inclues Phosphorus, Arsenic, and Anitmony)
creates an n-type semiconductor. It is referred to this because of
the excess of free electrons in the material.
Similiarly, you create a a p-type semiconductor by doping a pure semiconductor
with a small amount of material with valence number of +3
(Boron, Aluminum, Gallium, and Indium). This results because of a
hole that is left by the absence of an electron in the covalent bond
structure.
Note that doping a semiconductor does not add or remove any charge.
The resulting product is still electrically neutral. Doping simply redisDOPING
105
Si
Figure 6.5: A silicon structure with added phosphorus impurity and
free electron
tributes valence electrons so more or less free charges are available for
conduction.
Understanding Holes
The idea of holes is a bit intriguing. A hole really is a place where an
electron could be, or moreso wants to be. If there is an electron nearby,
it will jump into a hole and fill it up.
Electron holes aren’t really holes at all. It’s just a convenient description
for visualizing energy interactions between electrons and nuclei. In
order for there to be an electron hole at all, some energy has to be used
to free an electron from the grasp of the nucleus. The removal of the
electron tips the nucleus slightly out of balance. It then begins using
this energy to attract another nearby electrons to join back up.
In Section 2.4, Current Conventions, on page 23, we talked about the
difference between hole and electron current. The same idea exists in
semiconductors. Within the n-type semiconductor we think of electrons
being the major current carrier. In the p-type semiconductor, holes are
the major current carrier.
One interesting thing to remember about holes is that the movement
of the hole through the p-type material is due to the movement of the
bound electrons in the structure. That is, the crystal re-bonds from
atom to another atom and the hole “moves” in the opposite direction.
Just remember that a hole is nothing more than an empty place where
an electron could be.
THE PN JUNCTION 106
 Free Electrons
Free Holes
Figure 6.6: P-type and N-type materials
6.4 The PN Junction
The first interesting thing we can do with our doped semiconductors
is to put a small piece of n-type semiconductor next to a small piece
of p-type semiconductor. The extra electrons in the n-type conductor
attempt to move over into available holes in the p-type conductor. At the
same time, some of the holes in the p-type conductor end up moving
over to the n-type to meet up with electrons.When this happens, we end
up with an excess of electrons on the p-type side and extra electrons
on the n-type side, creating an electrical imbalance.
This electrical imbalance is known as the barrier potential and is shown
in Figure 6.7, on the next page. In silicon, this barrier potential is about
0.7 Volts.
The p-n junction becomes interesting when we apply an external voltage
to it. But in which direction shall we apply the voltage? There are
two possibilities which we call the forward and reverse bias.
6.5 P-N Bias
Forward Bias
If we apply a positive voltage to the p-type material and a negative voltage
to the n-type material, we are applying a forward bias to the semiconductor.
First, the negative voltage at the n-type material is going
P-N BIAS 107

n
Electrons that moved over
to fill in holes
Holes that moved over
to take electrons
Figure 6.7: The barrier between p-type and n-type materials
n
Figure 6.8: A forward biased p-n junction
to attempt to push electrons towards the junction in the middle. The
positive voltage at the p-type material will push the holes towards the
barrier as well. This reduces the barrier potential.
If the barrier potential is reduced enough, the charge carriers can move
through the barrier and out the other side. This means that current
flows.
P-N BIAS 108
n
Figure 6.9: A reverse biased p-n junction
Reverse Bias
Applying a reverse voltage to our semiconductor material is known as
reverse bias. In this condition, the electrons are pulled away from the
barrier on the n-type side and the holes are pulled away from the barrier
on the p-type side. This results in a larger barrier, which creates a much
greater resistance for charges to flow through. The net result is that no
current flows through the barrier.
If you want to succeed, double your failure rate.
Thomas Watson, Inventor of the Transistor
Chapter 7
Transistors
7.1 The History
After World War II, A.T.&T.’s Bell Laboratories started putting more
research into semiconductor technologies. A team of William Shockley,
Walter Brattain, and John Bardeen was assembled to work on a
semiconductor replacement to the vacuum tube.
In the spring of 1945, Shockley had designed the first semiconductor
amplifier. His group refined the concepts, even competing with one
another to show up each other with a better design.
By 1948, a refined enough product was available and Bell Labs introduced
it to the public. Sales were slow, so Shockley quit Bell Labs to
start Shockley Semiconductor Laboratories to focus on a more desirable
product.
But Shockley’s abrasive personality eventually drove away some of his
top people; they started their own company: Fairchild Semiconductor.
Soon, other companies such as Intel and Texas Instruments started
working on their own transistor designs.
It wasn’t long before the viability of the semiconductor transistor as a
replacement to the vacuum tube caught on.
7.2 The use of transistors
Transistors are three terminal semiconductor devices that are primarily
used for two purposes: amplification and switching. One terminal of
the transistor is typically used as a control terminal, which a voltage or
current applied to the terminal causes the transistor’s characteristics
THE USE OF TRANSISTORS 110
Trans
istor
No
Current
Flow
Trans
istor
Current
Flow
5V
Figure 7.1: A simple transistor switch
to change. This input change results in a change in current or voltage
between the other two terminals.
Switching
In their natural state, transistors (depending on the type) tend to either
act like open circuits or short circuits. That is, they either easily allow
or readily block current flowing through their two main terminals. By
applying a voltage or current to the input terminal, it’s possible to
reverse the transistor into the opposite mode it started in. In this fashion,
the transistor acts like a switch.
A simple model of this can be seen in Figure 7.1. In this instance, the
transistor does not allow current to flow when no voltage is applied to
its input. With 5V applied to the input, current can now flow through
the transistor.
Amplification
Transistor amplification happens when a voltage or current is applied
to the input that is in between the on and off states of the switching
application. Following our example from the previous section, we
would find that the amount of current that flows through the transistor
depends on the voltage applied to the input. For example, a 1V at the
input may allow 20mA of current to flow. 2V may allow 40mA. 3V may
allow 60mA. 5V and above may only allow 80mA of current to flow.
This region of the transistor, between its on and off states, is known as
the active region. Depending on the type of transistor, we can use this
BIPOLAR JUNCTION TRANSISTOR 111
Trans
istor
1V
20mA
100/
Figure 7.2: A simple transistor switch
region to get a large output from a small input. For example, the 20mA
output from the 1V input can be passed on to a 100 Ohm resistor,
creating a 20 V output ( 20 mA * 100 Ohm), as shown in Figure 7.2. 1V
at the input of the transistor is amplified to create 20V at the output.
7.3 Bipolar Junction Transistor
After our diode design from the previous chapter, the next logical step
is to put three doped semiconductors next to each other, like in Figure
7.3, on the following page. This configuration creates what is known
as a Bipolar Junction Transistor (BJT). There are two types, the n-p-n
and the p-n-p. Each material can be connected to a small piece of wire
so we can do interesting things with them. For example, an n-p-n transistor
and the three terminals, the collector, the base, and the emitter
are shown in Figure 7.4, on the next page.
The schematic symbol for a BJT is shown in Figure 7.5, on page 113.
Since we are putting three pieces of semiconductor material together,
we can also think of a BJT as similar to two diodes put together. For
example, in Figure 7.6, on page 113, we see that an n-p-n transistor
is equivalent to two diodes back to back (i.e. the p-type materials are
connected).
A common way of using a BJT is to forward bias the base to the emitter.
Since this connection and junction is effectively a diode, some electron
current will flow from the emitter to the base.
BIPOLAR JUNCTION TRANSISTOR 112
n n
Figure 7.3: An n-p-n material

collector
base
emitter
Figure 7.4: Collector, base, and emitter
BIPOLAR JUNCTION TRANSISTOR 113
npn pnp
collector
base
emitter
Figure 7.5: BJT Schematic Symbols
! "
c
# " Figure 7.6: An n-p-n BJT equivalent circuit
FIELD EFFECT TRANSISTOR 114
$% $
E B & Figure 7.7: Side view of an n-p-n transistor
Similarly, the collector is forward biased to the emitter. This means that
the collector to base connection is reverse biased. Normally, no current
would flow from the base to the collector due to this reverse bias. But
the reason is not the same as that of a diode.
No current would flow because there is no source of current carriers
available to cross the depletion region. However, since we have electrons
flowing from the emitter to the base, they are available to move from the
base to the collector—and they do.
Thinking about current flow in a transistor is both tricky and technical.
In summary, though, a BJT is a current amplifier. For a small amount
of (conventional) current sent into the base, a much larger amount of
current can be drawn through the collector. If you vary the amount of
current in the base, the amount of current going through the collector
will change as well, albeit much more drastically.
7.4 Field Effect Transistor
Another semiconductor transistor is the Field Effect Transistor, or FET.
Much like the BJT, a FET has three terminals known as the Gate,
Drain, and Source. The FET is constructed a little bit differently than a
BJT, and is shown in Figure 7.9, on page 116. The two most common
FIELD EFFECT TRANSISTOR 115
n
Figure 7.8: Current Flow in a BJT
types of FETs, the Metal Oxide Semiconductor FET (MOSFET) and the
Junction FET (JFET) are shown.
Like the BJT, we can use the FET to control and amplify current.
A FET is operated by controlling channel. The examples shown in Figure
7.9, on the next page have n-type channels; p-type channel FETs
are also commonly used.
A voltage is applied between the drain and the source terminals which
are at opposite sides of the channel. The gate is then used to control
the current that flows between the two.
The MOSFET
A MOSFET has a gate that is insulated from the channel.
A voltage that is applied to the gate will attract charge from the channel
toward the gate. This charge cannot move through the gate because of
the insulation. But, this “moved” charge does change the conductivity
of the channel.
The most common MOSFET is the enhancement mode MOSFET. In an
n-channel enhancement mode MOSFET the resistance from the source
to drain is relatively high; therefore, very little current can flow. However,
a positive voltage at the gate causes the channel to induce negative
charges which allows more electrons to flow from the source to the
THE USE OF TRANSISTOR 116
n-type
Gate
Source Drain
Insulator
p substrate
Source Drain
Gate
p-type
MOSFET
JFET
Figure 7.9: Construction of FETs
drain. This means that the resistance of the channel is easily controlled
by the gate.
The JFET
In the JFET, a reverse biased junction is used at the gate instead of an
insulating material like in a MOSFET.
7.5 The Use of Transistor
BJTs and FETs have many uses. Since both can be used to control
a different current or voltage, both are highly suitable as amplifiers.
Circuit designers have some preferences in using one over the other
• BJTs have a higher transconductance than FETs. This means that
their relative ability to amplify a signal is considerably higher.
TRANSISTOR LOGIC 117
Because of this, BJTs are more commonly used as signal amplifiers.
• In their “off” state, FETs have higher resistances than BJTs. This
means that the current they conduct when turned off is very
small. Because of this, FETs are commonly used in switching
applications where power consumption is tightly controlled.
From the standpoint of a microprocessor, we are really only concerned
with the switching abilities of a transistor and not the amplifying abilities.
In the current processor world, the MOSFETs are much more
prevalent than BJTs.
7.6 Transistor Logic
In 1962, Texas Instruments released a series of integrated circuit chips
known as the 7400 series, which provided a wide variety of digital
logic functions such as AND, OR, and NOT gates. The technology was
known as TTL, which stands for Transistor to Transistor Logic. They
were implemented using BJTs and resistors, then were packaged into
chips which could easily be integrated into circuits without the need for
having to worry about how to implement the logic.
As an example of the implementation of some of these circuits, the
NAND and NOR gates are presented below:
A basic logic circuit built with BJTs is shown in Figure 7.10, on the
following page. In this case, we have implemented a NAND logic circuit.
If we consider the A and B terminals as inputs, and the X as an output,
we can see the results in the table in the figure. The output X will always
be 5 volts, because no current can flow through the resistor and down
through the transistors. When BOTH transistor bases active, meaning
that both transistors will conduct current, then the current can flow
down through the transistors. In this condition, the output is now at 0
volts (ground).
Similar to a NAND gate, a BJT NOR gate can be built like in Figure 7.11,
on the next page.
The 7400 TTL series of integrated circuits also provided logic circuits
like flip-flops and shift registers, which we will look more closely at in
Section 7.8, The Flip Flop, on page 120.
TRANSISTOR LOGIC 118
5V
A
B
X
A B X
0 0 1
0 1 1
1 0 1
1 1 0
Figure 7.10: BJT NAND Gate
5V
A B
X
A B X
0 0 1
0 1 0
1 0 0
1 1 0
Figure 7.11: BJT NOR Gate
CMOS 119
n
FET
p-type
FET
Figure 7.12: CMOS Transistors
7.7 CMOS
A replacement for TTL is CMOS, or Complementary Metal Oxide Semiconductor.
CMOS is a circuit design technique that utilizes MOSFETs
in pairs to handle functions similar to the TTL circuits. In 1968, RCA
released the 4000 series of chips that provided many of the same characteristics
as the 7400 series chips. The 4000 series counterparts were
slower, meaning they could not be switched on and off as fast as the
7400 series implementations. On the other hand, the 4000 series chips
consumed much less power and could operate over a much wider range
of voltages.
CMOS uses a pair of MOSFETs, one p-type and one n-type as shown
in Figure 7.12. The advantage to this setup is in power consumption. If
an n-channel and a p-channel FETs are connected up in the same way
with the same controlling gate voltage, one will be “on” when the other
is “off”.
A CMOS based implementation of a NAN D gate is shown in Figure 7.13,
on the following page.
The main advantage to CMOS design is in reduced power consumption.
With other designs, like TTL, some power is required to maintain
one of the switched states. For example, in the NAND gate example in
Figure 7.10, on the previous page, the inputs A and B will draw some
electrical power when high. This is because the base input of the BJTs
draws some current.
TRANSISTOR CIRCUITS 120
+,+ ***))(((,+./*,)(./-
Power
p-channel FETs
n-channel FETs
Figure 7.13: CMOS NAND Gate
In a CMOS design, no power is consumed when the FET pair is switched
either on or off. Instead, the only power consumption occurs during the
switching between states.
7.8 Transistor circuits
Transistors are used as building blocks to create integrated circuits.
This section takes a look at some of the common base circuits we can
create with transistors that will be essential in creating multi-purpose
integrated circuits such as microprocessors.
The Flip Flop
A flip-flop is a circuit that is able to remain in one of two states. They
are an important part of digital logic circuits because they have memory
that normal logic gates, like the NAND and NOR gates, lack.
TRANSISTOR CIRCUITS 121
The RS Flip-flop
The basic type of flip-flop can be created by connecting two NAND gates
like in Figure 7.14, on the following page. This circuit forms an RS,
or reset-set flip-flop. This circuit has two inputs, S and R, and two
outputs, Q and Qbar. Q and Qbar are opposites. When one is on, the
other is off.
The RS flip-flop works like this:
1. Hold.- In this condition, nothing happens. This happens when the
S and R inputs are both HIGH. The outputs stay as they were.
2. Set.- Setting causes the output Q to go HIGH. This happens when
the S input goes LOW.
3. Reset.- Reset causes the output Q to go LOW. This happens when
the R input goes LOW.
The flip-flop is a very simple device, but it is also very profound. It is
able to maintain a state. When we perform a SET operation by making
the S input go LOW and the Q output goes HIGH, later when the S input
goes back to HIGH the Q output stays the same. The flip-flop retains
its state. It has memory. The only way to clear this operation is to later
make the the R input go LOW.
This behavior is commonly referred to as latching.
The RS flip-flop is very easy to implement, as noted in the figure. However,
a small problem arises if both inputs were to go LOW, which is an
undefined/prohibited operation. In this condition, both Q and the Qbar
outputs would be the same (HIGH).
The D Flip-flop
The D flip-flop has only one data input, D, and a clock input, CLK.
The D (for data) input is used to delay the output from the input. The
output, Q, will match the input, D, whenever the clock input CLK transitions
from low to high.
The representation of the D flip-flop is shown in Figure 7.15, on the
next page.
The JK Flip-flop
Another common type of flip-flop is the JK flip-flop, and is shown in
Figure 7.16, on page 123. This flip-flop is considered the universal flipflop.
The JK flip-flop has two data inputs, J and K. It also has a clock
TRANSISTOR CIRCUITS 122
NAND
NAND 01 223 Figure 7.14: RS Flip-Flop
4567
Q
Q!
D flip-flop
Figure 7.15: D Flip-Flop
TRANSISTOR CIRCUITS 123
8:;9
Q
JK flip-flop
J K
0 0
0 1
1 0
1 1
Q
Q
_
Q
_
No Change
clock pulse
0 1
1 0
Change to
opposite
state
HOLD
SET
RESET
TOGGLE
Figure 7.16: JK Flip-Flop
input, CLK. It has the same Q and Qbar outputs as the RS flip-flop
does.
The JK flip-flop is a clocked flip-flop, which means that its outputs will
only change when the clock (CLK) is triggered. This generally happens
during the transition between a LOW state and a HIGH state, known as
a clock pulse.
The operation of the JK flip-flop is as follows:
1. Hold - Whenever the clock pulses, the output remains the same.
2. Set - The output Q goes HIGH when the clock pulses.
3. Reset - The output Q goes LOW when the clock pulses.
4. Toggle - The output Q changes from HIGH to LOW or LOW to HIGH
when the clock pulses.
TRANSISTOR CIRCUITS 124
<=>?
Q <=>?
Q
Q! <=>?
Q
Q! <=>?
Q
Q! @ A C D
INPUT
CLOCK
Figure 7.17: A 4-bit shift register
Flip Flop Circuits
Utilizing flip-flops, we can build various types of functional circuits.
The Shift Register
One such circuit, the shift register, is shown in Figure 7.17. This shift
register is made up of four chained D flip-flops. The clock inputs of
each flip-flop is tied together, and the data outputsput of each flip-flop
is connected to the data input of the next. The shift register works as
follows:
1. Place a bit value (LOW or HIGH) at the INPUT terminal.
2. Pulse the CLOCK input. The value is now latched to the first flipflop.
3. Repeat the process three more times. On the final CLOCK pulse,
all four values have now been latched into each of the four flipflops.
Ripple Counters
A chain of J-K flip-flops can create a ripple counter. A ripple counter
counts the number of input pulses to the CLOCK input and outputs
that value as a binary representation of the number of counts. The circuit
for a 3-bit ripple counter is shown in Figure 7.18, on the following
page.
TRANSISTOR CIRCUITS 125
CDB
J Q
CL
CDB
J Q
CDB
J Q EFG H I
C
Figure 7.18: A 3-bit ripple counter
There is no reason anyone would want a computer in their
home.
Ken Olson, Digital Equipment Corp.
Chapter 8
The Processor
8.1 The history of the processor
The first integrated circuit, with multiple discrete components in a single
package, was invented by Texas Instruments engineer Jack Kilby in
1958. For the next 10 years, the process of packaging transistors into
a small integrated package was refined.
In 1968, Robert Noyce, Gordon Moore, and Andy Grove left Fairchild
Semiconductor, a dominant producer of integrated circuits. They created
a new company called Intel where they could use their talents
towards future integrated circuit design.
Building a Processor
The first commercially available microprocessor was the 4004 created
by Intel released in November 1971. A 16 pin, 4-bit processor, it was
originally designed for use in calculators for the Japanese company
Busicom.
One of the chip designers, Federico Faggin, believed that there were
markets for the chip beyond just Busicom’s calculators. To prove his
point, Faggin used a 4004 chip to create a control circuit for a production
tester of 4004 chips. Faggin started a movement with Intel to consider
the commercial release of the 4004 as a multipurpose processor.
This required re-negotiation of contracts with Busicom, but ultimately
proved to be very successful.
Around the same time, Texas Instruments (TI) developed and released
its own 4-bit microprocessor, the TMS 1000. TI’s processor was a little
bit different in that it didn’t require any external chips to store data like
THE HISTORY OF THE PROCESSOR 127
5V
A
B
X
A B X
0 0 1
0 1 1
1 0 1
1 1 0
The Buzz. . .
Beyond Semiconductors
Robert Noyce, Gordon Moore, and Andy Grove have made
contributions far beyond their initial semiconductor designs.
Robert Noyce was known as the “Mayor of Silicon Valley”.
Beyond his technical contributions, he is largely credited with
beginning the trend of allowing a casual work atmosphere. He
believed in giving freedom to bright young employees to prosper.
These trends are still followed today in many Silicon Valley
companies.
Gordon Moore is most famously known for Moore’s Law, in
which he stated that the number of transistors on a computer
chip would double every 18-24 months. He was Chairman and
CEO from 1979 to 1987, after which he became Chairman of
the Board.
Andy Grove became president of Intel in 1979 and CEO in 1987.
From 1997 to 2005 he served as Chairman of the Board and
currently serves as a management advisor.
the 4004 did. This chip was significantly bigger than the 4004 and had
more pins (28), but was designed to be a multipurpose processor from
the start.
Intel continued moving forward with new chip designs. Its next major
release, the 4040, was the successor to the 4004. Shortly thereafter,
the 8008 was released. It was designed for the Computer Terminal Corporation
for use within one of their programmable terminal products.
The prototype had problems in its memory circuits which required a
redesign. It was delivered late to CTC; too late, in fact, to be used in
their product.
Intel marketed the 8008 to other companies with some success. However,
many customers were requesting things that weren’t in the 8008.
Federico Faggin, as its lead designer, took note of these requests.
PROCESSOR FUNDAMENTALS 128
A Revolution
In 1974, Intel released the 8080 chip. It is widely considered to be the
first general purpose microprocessor. Its use in many early microcomputers,
like the Altair 8800, gave it widespread popularity.
Soon the 8080 had competitors. Motorola released the 6800 and Zilog,
a company founded by Faggin after departing Intel, released the Z80.
Soon, many companies were competing for market share in the processor
world.
However, it was a bit of marketing on Intel’s part that sealed the deal
for their dominance in the processor market. In 1978 Intel released the
8086 and 8088 (the latter of which was the same as the 8086, but had
a reduced data bus size to work more easily with other cheaper chips).
The release of the 8086/8 was done simultaneously with a marketing
program and sales campaign known as “Operation Crush”. Operation
Crush trained Intel employees to focus on customer support, drive
sales, and show long term commitments to supporting their products.
Operation Crush worked. In 1981, IBM chose Intel’s 8088 for use in
their new personal computer line. While the choice of Intel may not
have been what led to the ultimate success of the PC, it certainly helped
Intel become a dominant player in the microprocessor market.
Over time, new processors were released, like the follow-on 80286,
80386, and 80486. Eventually Intel released the Pentium line of processors
which continue to remain popular choices even today.
8.2 Processor Fundamentals
Processors provide the following components:
• Data storage in the form of registers.
• Data manipulation in the form of a logic library.
• Data paths in the form of the pipelines.
• Clock and synchronization circuitry
Data Storage
Registers
Registers are areas of memory internal to the processor. They are used
directly by the processor for calculation and data access. For example,
PROCESSOR FUNDAMENTALS 129
5V
A
B
X
A B X
0 0 1
0 1 1
1 0 1
1 1 0
The Buzz. . .
What about Babbage?
Long before the invention of the transistor, the vacuum tube, or
even electricity, Charles Babbage had created the first analytic
computer known as the Difference Engine. Fed up with
the problems of using mathematical tables for calculations,
Babbage built a machine that could calculate the lookups of
numeric tables mechanically and be correct every time.
Babbage also designed, though never built, the Analytical
Engine. This machine, in theory, was programmable via the use
of cards. The concept of being able to write programs, on
cards, and then reuse them to get calculations is the foundation
for modern day computer processors.
5V
A
B
X
A B X
0 0 1
0 1 1
1 0 1
1 1 0
The Buzz. . .
What is Magnetic Core Memory?
Magnetic core memory was used for data storage on early
computers. It is composed of small iron rings in a grid structure
with wires running through them. By manipulating the various
wires, a magnetic field could be induced in the ring and could
then later be read as a 0 or 1.
if the processor needed to add two numbers together, it would most
likely look for both of the numbers in two different registers, perform
the addition, and store the result back in one of those registers.
Registers are measured by the number of bits they hold. On an Intel
Pentium 4 chip, for example, most of the registers are 32 bit registers.
Registers can be implemented by flip-flops, magnetic core memory, or
more commonly, as a register file.
PROCESSOR PACKAGING 130
Register Files
A register file is a common way of creating and accessing registers
within a processor. It contains the physical registers of the CPU. The
implementation of the register file is the same as Static RAM (see Section
9.3, Static RAM, on page 142). In other words, the CPU registers
are nothing more than special purpose implementations of RAM.
The ALU
The Arithmetic Logic Unit (ALU) is part of the processor that handles
the core mathematical abilities of the processor. In general, it performs
the following types of operations:
• Arithemetic such as addition, subtraction, and sometimes multiplication.
• Logic operations, such as AND, OR, and NOT.
• Bit manipulations, such as shifting or rotating bits within a byte.
Clocks
CPUs as well as most logic circuits are synchronous, meaning that operations
are performed sequentially. The clock signal handles this synchronization.
The clock signal is usually in the form of a square wave
and the frequency of the wave depends on the abilities of the processor
and other electronics and the circuit designer.
The clock frequency has to be set to ensure that all parts of a data
operation are in place before performing that operation. However, some
parts of the processor may work faster than others meaning that some
data may be sitting idle waiting for the next clock signal while other
data parts are still be processed. So, an important part of CPU design
involves making sure that the various parts of the processor are good
at handling parallel tasks.
8.3 Processor Packaging
Dual Inline Packaging
The first commercially available processors were packaged as DIPs, or
Dual Inline Packages (sometimes also called DILs). It is a rectangular
package with two rows of pins protruding downwards. DIPs come in a
wide variety of pin counts, from 8 to 64.
PROCESSOR PACKAGING 131
Figure 8.1: A DIP style chip
For processors, DIPs were very popular in the early days of computers
thorough the early 1980s. They continue to remain popular for
other types of integrated circuits, particularly for hobbyist tools like
programmable memory chips, because they are easy to handle.
By the mid 1980s, however, the number of pins on the processor started
to get very large and it was becoming clear that DIPs were not able to
handle the count.
Pin Grid Array
The next step in processor packaging was PGA, or Pin Grid Array. With
PGA, the pins were moved to the bottom of the processor in a large grid
pattern instead of out the side like in the DIP. The advantage to this
was the number of pins available was a function of the surface area of
the processor. Pin counts were able to go into the hundreds.
Other Packaging Types
Integrated circuits are found in many other package types. Some of the
more common types are:
• PLCC - Plastic Leadless Chip Carrier. This is a four sided package
with the electrical connectors along each of the sides.
PROCESSOR COOLING 132
Figure 8.2: A processor with PGA
• SOIC - Small Outline Integrated Circuit. This package is similar to
DIP, but shorter and more narrow.
• BGA - Ball Grid Array. Similar to PGA, this package type uses
small balls of solder at the connection method instead of physical
pins coming out the bottom of the package. BGA has the advantage
of mounting directly to the surface of the board instead of
having pins that must go completely through the board.
8.4 Processor Cooling
With all of the electronics inside of it, the processor generates heat while
it is working. How much heat the processor generates is dependent on:
• The efficiency of the electronic design.
• The clock speed.
• The operational voltage.
Processors cannot be allowed to get too hot, or they risk damaging
themselves. Modern processors have thermal sensors within the housing
of the processor which can be monitored. If the temperature exceeds
a critical value the sensor can shutdown the processor.
To help with generated heat, it is dissipated by the use of a heat sink
and a fan. A fan blowing air past the CPU aids in heat dissipation
PROCESSOR COOLING 133
5V
A
B
X
A B X
0 0 1
0 1 1
1 0 1
1 1 0
The Buzz. . .
What is the Peltier effect?
In 1821 a physicist named Thomas Seebeck discovered that if
two pieces of wire, made from different metals, were attached
together at one end and heated, a voltage would result
between them. The relationship between the amount of heat
(temperature) and the resulting voltage could be measured,
interpolated, and put into a table. Seebeck’s discovery, known
as the thermocouple, is widely used today as a method for
measuring temperatures.
The Peltier effect, discovered in 1834 by Jean Peltier, is the
opposite of the Seebeck effect.When current is passed through
two different metals at a junction, heat transfers from one junction
to the other. One junction gets colder while the other one
gets warmer.
Simply, a thermoelectric Peltier cooler transfers heat from one
side of the device to the other. This can be used to cool things
such as processors by keeping the cold side of the cooler next
to the processor.
by transferring heat away from the CPU. The heat sink helps as well
by creating more surface area over which the heat can be dissipated.
Because the heat sink contact with the processor may not be ideal, a
thermal paste is sometimes used between the two. The thermal paste
helps conduct heat into the heat sink and away from the processor.
More recently, cooling techniques such as water cooling and thermoelectric
cooling using the Peltier effect are becoming commonplace.
Part of the inhumanity of the computer is that, once it is
competently programmed and working smoothly, it is
completely honest.
Isaac Asimov
Chapter 9
The Motherboard
The processor may be the heart and soul of the computer, but it’s highly
dependent on all sorts of other devices to get things done. We’ll take a
look at these peripheral devices in the next section.
The progression of design of today’s motherboards stems back to the
early 1980s and IBM’s release of the first PC. When it was released,
IBM also released the design of their motherboard and specifications
on how to talk to their BIOS as open standards. The idea behind it
was to keep a proprietary lock on their BIOS design, which meant they
would always be one step ahead of the game in the industry. The plan
failed miserably, however, when competitors quickly reverse engineered
the BIOS.
This opened up the market to IBM compatible clones made by other
companies. Many of the original designs used in IBM’s PC motherboard
are responsible for the designs in motherboards today.
In this chapter we’ll look at what makes up a motherboard, some of the
types of things found on typical motherboards, and some of the issues
facing motherboard design.
9.1 Circuit Connections
Ancillary to the processor, there are many other circuits in the computer
that exist in order for the processor to work its magic. The components
include many of the items we’ve already learned about: resistors,
capacitors, diodes, and more.
So far, our discussion of connecting electrical components together has
been done via wires. This is a great way of making interconnections
CIRCUIT CONNECTIONS 135
Figure 9.1: A printed circuit board
in the lab, but it’s not very practical once the number of components
becomes large. Furthermore, the mobility of computers today is far too
high to make using copper wire to connect individual pieces together
practical. Also, how would the resistors, capacitors, and diodes be fastened
down inside of the computer.
The Printed Circuit Board
The printed circuit board (PCB) is the answer. Most likely you are
already familiar with printed circuit boards, as almost every consumer
electronics item has at least one in them. They are used to both hold
components in place and provide the electrical connections between the
components. A picture of one is shown in Figure 9.1.
The PCB is made up of a number of parts that make everything work
together.
• Components - Various electronic components are attached to the
board. In Figure 9.1, the components are surrounded by white
borders. These borders are made from an ink that is silk screened
on. Each component is also labeled with a designator, like R9. The
letter signifies the component type (R for resistor) and the number
signifies it is the 9th resistor.
Components are attached to the board using solder. In the example
figure, these components are attached to the PCB directly to
the surface by small pads. Parts that are soldered directly to the
surface are known as surface mount components.
CIRCUIT CONNECTIONS 136
J
races
Via
Circuit board top
Circuit board bottom
Figure 9.2: A PCB side view showing traces connection with a via
Some components which have pins may be soldered to the board
through small holes. These components are known as through hole
components.
• Traces - The lines that connect the components together are called
traces. Traces are small copper “wires” that are directly attached
to the board and connect components together. A large number of
traces are seen in the figure.
• Vias - One problem with traces on a printed circuit board is that
they are purely two dimension. There is no way to jump a trace
over another one. This presents a problem when there get to be
a large number of traces—how do you connect up components
where the traces need to jump over each other? The answer is
with vias. Vias are small holes that have been drilled in the board.
A small copper ring lines the hole, and runs through the board
all the way to the other side. Vias allow traces to become three
dimensional. A side view of a PCB showing traces and a via is
shown in Figure 9.2.
Printed circuit boards can have multiple layers. Some boards have just
one or two layers, which consist of the front and back of the board itself.
However, it is possible to sandwich more layers in between. Vias then
can be used to run traces in between multiple layers. It is not uncommon
to see up to 16 different layers in a printed circuit board, though
designing and building these boards is significantly more expensive
than a one or two layer board.
CIRCUIT CONNECTIONS 137
Making a Printed Circuit Board
The first step in making a circuit board, such as a mother board,
involves design. Typically design software is used where a designer can
put down chips, resistors, capacitors, and other devices. The designer
will specify how connections need to be made. For example, she may
indicate to the software that she wants pin 2 from chip U7 to connect
to pin 4 on chip U12.
For small circuit boards, the designer may choose to make the connection
herself by specifying the geometry of the board, where each
component will be placed, and manually drawing the traces and vias.
However, for larger projects such as a motherboard, the whole layout
process is usually automated by software.
Creating the Board
Once the design and layout of the circuit board is complete, the process
of creating the board begins.
Boards are created using the following steps:
1. A blank board is ordered and cut to the size required by the
designer. If the board is to have multiple inner layers, each layer
will be created the same way and bonded together in the end.
2. The blank board has a solid sheet of copper. A negative mask is
applied to the board, after which a chemical is used to remove the
copper from the places on the board where no copper is needed.
The mask is then removed from the board.
3. Vias are drilled into the board using computer controlled milling
machines, or in some cases lasers.
4. The drilled via walls are plated with copper.
5. Pads which will have components attached are plated with solder.
6. Artwork and lettering are silk screened onto the board.
7. Components are placed onto the board by hand or by machine.
They are soldered into place.
8. In some cases, electrical testing is done to ensure the board has
been populated correctly.
BUS TYPES 138
9.2 Bus Types
A bus is a system that transfers data between two components in a
computer.
Today’s PC motherboards typically use a bus architecture known as
Northbridge and Southbridge. The Northbridge is a set of chips that
handle communication between the CPU, memory, and some expansion
slots. The Southbridge handles some of the slower components such as
the serial ports, USB, and the hard drive controllers. The Southbridge
connects to the Northbridge as shown on Figure 9.3, on the next page.
Front Side Bus
The front side bus connects the CPU to other components on the motherboard,
like memory, the BIOS, and expansion slots. A number of
different electrical implementations exist based on the manufacturer.
However, the FSB does contribute to some very important aspects of
the computer.
CPU Frequency
The CPU clock is directly controlled by the FSB. The FSB operates at
a lower frequency than the CPU. The clock signal that controls the
FSB is run through a frequency multiplier (see Section 9.4, Frequency
Multipliers, on page 146) before being fed to the CPU.
Memory Frequency
The clock that controls system memory also derives from the FSB clock.
Expansion Busses
IBM’s original PC had a motherboard with expansion slots designed to
connect peripheral cards to the motherboard.
ISA
ISA, the Industry Standard Architecture, is an expansion bus type originating
with IBM’s PC in 1981. It was originally designed as an 8-bit
system, meaning that 8 bits of data could be transmitted at a time. The
bus data rate was 4.77MHz.
In 1984, with the release of Intel’s 80286 processor, the ISA bus was
enhanced to a 16 bit bus with a clock speed of 8 Mhz.
BUS TYPES 139
5V
A
B
X
A B X
0 0 1
0 1 1
1 0 1
1 1 0
The Buzz. . .
Front side bus logic
Intel processor based FSBs use an implemetation known as
Gunning Transceiver Logic (GTL). GTL is a form of electric signaling
that relies on very small voltage changes (less than a volt)
that allows for high speed data transfers. AMD Athlon based
processors, on the other hand, use a FSB implemenation known
as EV6.
As computers today are starting to see applications with multiple
processors, the scope of the FSB (which was designed
for one processor machines) is changing. Newer replacement
technologies like AMD’s HyperTransport or Intel’s IHA are
replacing traditional front side busses.
CPU Northbridge Southbridge
RAM AGP PCI
USB
Figure 9.3: A CPU with Northbridge and Southbridge Controllers
BUS TYPES 140
One downside to the ISA bus and the expansion cards dealt with configuration.
Almost every card had jumpers which had to be individually
configured to set things like the IRQ line number and IO ports. This led
to possible conflicts with other cards already installed in the system.
Over time, more problems with the ISA bus became apparent. The
fixed bus speed started lagging behind the increasing clock rates that
new processors were starting to run at. The manual configuration via
jumper switches only allowed a limited number of settings, which had
to be fixed in the hardware. These weren’t problems at first; they only
grew out of the increasing number of manufacturers of PCs and peripherals.
MCA
IBM took note of the problems starting to plague the ISA bus type.
They also took notice of how their market share had eroded in the PC
market due to the open design of their motherboards and the ISA. To
combat this, they created a new bus type known as the Micro Channel
Architecture. They would retain the rights to this bus style via patents
and license the rights to create peripherals using it.
MCA was designed as a 32 bit bus, but allowed for a 16 bit mode as
well. The clock rate was set to 10MHz, but also now used an individual
bus controller chip to handle bus communications instead of relying
directly on the processor. Cards were also allowed to bus-master, meaning
they could talk with other cards on the bus without the need of the
processor.
Amongst other improvements, the MCA also added support for something
known as POS, or Portable Option Select which allowed for settings
to be configured in software instead of in hardware.
Save for IBMs own machines, MCA never became widely adopted.
EISA
The industry responded with the Enhanced Industry Standard Architecture.
This expanded bus was a 32-bit design, and supported busmastering
as well. It also had the same shape as previous ISA cards,
meaning individual slots could support older style ISA cards as well.
Though the technical aspects weren’t as great as the MCA, the EISA
was more widely adopted by PC manufacturers.
BUS TYPES 141
PCI
In 1990, Intel started work on the next generation bus style, the Peripheral
Component Interconnect. It took some time to gain steam, but by
the mid 1990s PCI became the industry standard alongside EISA. As of
2006, it is still the industry standard.
PCI supported plug-and-play, meaning that software was used to handle
the configuration of resources. It supported both 32-bit and 64-bit
peripherals. The clock rate was 33.33MHz, and allowed for the use of
3.3V or 5V signals.
Some variants to PCI exist, including PCI-X which has higher data
transfer rates.
AGP
The PCI expansion bus was well suited for general expansion cards. But
as displayed screen graphics became more utilized with the invention
of the graphical user interface and multitasking operating systems, the
needs for display cards rose. PCI was not able to cope with these speed
requirements.
In the late 1990s, Intel released the Accelerated Graphics Port. AGP
provided a direct link to the processor for a graphic card, making it a
superior choice over PCI. The AGP bus is a 32-bit bus with a 66 MHz
clock, providing data transfer of 254 MB/sec. But newer versions with
increased data transfer rates can achieve up to 1018MB/sec.
PCI Express
The latest entry into the expansion bus market, released in late 2004,
is PCI Express, sometimes known as PCX or PCI-e. PCI Express uses
serial data transfer instead of parallel data transfer like all previously
discussed bus types. PCI Express devices don’t rely on a hardware bus,
but instead are connected via a star like network, similiar to ethernet.
PCI Express is designed around a bi-directional “lane” system, where
serial data travels down 1 wire. This can be contrasted to the 32-bit PCI
bus system where all devices shared 32 wires. All PCI Express devices
must support at least 1 lane, though they can support more for greater
data transfer rates.
RAM 142
9.3 RAM
RAM, or Random Access Memory, is the one of the most important parts
of the whole computer system. So named because data can be accessed
at any location at any time (unlike earlier sequential data types, such
as magnetic tapes, in which data had to be accessed in order). RAM
provides the processor and other components with storage for data.
This storage is designed to be short-term, most notably because after
the system powers off the data is not saved.
RAM is normally in the form of integrated circuits, built into small cards
or sticks. These sticks can be placed on the motherboard in slots, similiar
to how expansion cards are placed on the motherboard.
There are two main types of RAM used today, static and dynamic.
Static RAM
Static RAM, or SRAM, is a form of semiconductor memory. This type of
RAM retains its value as long as power is applied.
Every memory bit in static RAM is stored within four transistors, forming
two cross coupled inverters. Two additional transistors are used to
control reading and writing of the value. So, one bit of SRAM requires
6 transitors to implement as shown in Figure 9.4, on the next page.
SRAM operates in three different modes: standby, read, and write.
Standby
If the data stored in the RAM cell is currently not being used, the RAM
is in standby mode. The inner four transistors, being cross coupled
inverters, store the value indefinitely.
Read
To read the value stored in the RAM cell we simply utilizes the two
access transistors on the outer part of the circuit. Enabling these transistors
causes the value stored in the RAM cell to appear on each of the
bit lines. Note that the bit lines are complementary: a HIGH value on
one bit line means a LOW value on the other bit line.
Write
To write a value to the RAM cell, two access transistors are used to tie
the bit lines to the inner RAM cell. In this case there are two options.
We can write the value that is already being stored in the RAM cell, in
SYSTEM CLOCK 143
+V
GND
Word line
bit bit
Figure 9.4: Static Ram
which case nothing changes. Or, we can write the opposite value and
change the state of the cross-coupled inverter.
Dynamic RAM
Dynamic RAM, or DRAM, stores each bit of data as charge in a capacitor.
However, since capacitors tend to slowly discharge, this value must
be constantly refreshed. Because of this refresh requirement, the memory
is considered dynamic.
DRAM is easier to implement than SRAM, because it requires only one
transistor (as a switch) and one capacitor per bit.
9.4 System Clock
In digital electronics, the clock is used to synchronize the actions of
circuits. In this regard, the clock is important because it allows the
ability to consistently perform operations at a set time. For example, if
SYSTEM CLOCK 144
5V
A
B
X
A B X
0 0 1
0 1 1
1 0 1
1 1 0
The Buzz. . .
The scoop on quartz
Quartz is the most common mineral found on Earth. It’s found
in almost every rock type and is frequently the most common
component within a rock. It is composed of a crystal structure
of silica (Silicon Dioxide, or SO2). Major varieties of quartz
include amethyst, onyx, and jasper.
Because of its commonality, quartz is relatively inexpensive.
Since it oscillates stably and predictably, it makes a great
source for a time base for electronic circuits.
Figure 9.5: A crystal oscillator on a circuit board
some data is required at the input to a circuit, the clock signal can be
used to trigger the circuit as to when the data is available.
Clock Generation
Most motherboards generate clock signals by using a crystal oscillator.
In most cases this is built using a small piece of quartz crystal. When
packaged properly, a small piece of quartz exhibits a property known
as piezoelectrity. A piezoelectric material bends slightly when exposed
to an electric field. In addition, a piezoelectric material will produce a
voltage (and thus an electric field) when bended slightly.
SYSTEM CLOCK 145
5V
A
B
X
A B X
0 0 1
0 1 1
1 0 1
1 1 0
The Buzz. . .
Understanding Resonance
Picture a child on a swing set going back and forth. The child
is moving at a certain frequency. If we were pushing the child
to keep them going, we have to push them at a certain part
of the swing in order to do the best amount of work. That is, we
tend to push them just as they start moving downward again.
If we changed how we pushed the child — for example, if we
pushed them every couple of seconds regardless of where they
were located—our pushes do not provide the same amount of
energy transfer as before.
The idea of resonance is that mechanical and electrical systems
tend to absorb the most energy if the frequency of the
inputmatches the natural frequency of the system. Allmechanical
and electrical systems have natural frequencies that they
tend to want to oscillate at, based on their size and composition
(or in the case of electrical systems, their components). The
swinging child’s natural frequency is based on the length of the
ropes of the swing, the weight of the child, and environmental
factors like wind speed.
The crystal, shown in its metallic packaging in Figure 9.5, on the preceding
page, is used in a small circuit known as a crystal oscillator.
Initially, the crystal is given some random noise voltage, which causes
some vibration in the crystal. The crystal is designed to vibrate optimally
at one certain frequency, known as the resonance frequency. The
crystal’s vibration causes a small voltage to be created. This voltage is
then fed back into the circuitry that caused the initial vibration.
Because the crystal tends to want to vibrate at its resonance frequency,
it will generate the most output signal power at that frequency. This
gets fed back into the oscillator circuitry, causing an even stronger
vibration at that frequency. Eventually, all of the other noise and frequencies
die out and the output of the crystal is some waveform oscillating
at a known frequency.
The choice of quartz for the clock oscillator signal is important. For
example, it’s completely possible to build an oscillator using a resisSYSTEM
CLOCK 146
tor, a capacitor, and an inductor. Picking a proper value for each will
give a circuit that oscillates at a desired resonant frequency. However,
these electrical components are not immune to temperature drift,
where the resonance frequency may change slightly based on temperature.
Quartz is less susceptible to temperature drift, though not
immune. Some quartz oscillator applications may measure the temperature
around the oscillator and use that information to compensate for
any drift in the resonance frequency that may occur.
Quartz oscillators can be tuned to vibrate at any frequency, though a
handful of standard frequencies are the most common. In digital clock
applications, a oscillator tuned at 32,768 Hz may be used. This allows
for some digital logic to get down to a base time of one second.
Changing Frequencies
Frequency Dividers
Sometimes its desired to divide down a clock frequency into a lower
frequency. One easy way of accomplishing this is with the use of a ripple
counter as discussed in Section 7.8, Ripple Counters, on page 124. Each
progressive stage of the ripple counter effectively divides the output
frequency by 2.
Frequency Multipliers
The clock frequencies that are generated in today’s computers are simply
too fast for use with crystal oscillators, as there is an upper limit to
where crystal oscillators vibrate reliably. In these cases, we may want to
generate a clock signal that is higher than the output of our oscillator.
This is where the frequency multiplier comes into effect. The logic for
a simple frequency multiplier is shown in Figure 9.6, on the following
page.
A frequency multiplier utilizes an electronic circuit known as a VCO,
or Voltage Controller Oscillator. This circuit is able to vary its output
frequency in relationship to a voltage that is applied to the input.
To make a frequency multipler, the output of a VCO is fed into a frequency
divider. The resulting divided frequency is compared to a reference
frequency created by a crystal oscillator. If the frequencies don’t
match, the difference between then is fed back into the VCO. This feedback
causes the output of the frequency divider to lock on to the frequency
of the crystal oscillator, making an exact copy. Thus, the actual
SYSTEM CLOCK 147
crystal
oscillator
frequency
divider
VCO
multiplied frequency
comparator
Figure 9.6: Frequency Multiplier
output of the VCO, which is on the input side of the frequency divider,
is a multiplied version of the crystal oscillator.
Clock Issues
As the speeds of the clock have increased over the years, so have the
problems associated with the faster clock signals.
Wavetype
Clock signals are usually associated with square waves. This is because
clock circuits are designed to trigger on the transition between the digital
state changes, so a crisp, fast state change like that in a square
wave is desirable.
For many years, the use of a square wave as a clock signal was feasible
because the clock speeds were low, relatively speaking. But as we have
seen from our discussion of the Fourier Series, a square wave is simply
the sum of sine wave harmonics. This means that a given square wave
has many higher frequency components. Unfortunately, these higher
frequency components can generate electromagnetic interference that
causes problems with other parts of the circuits.
Transistor Switching
As the clock cycles back and forth, transistors within the integrated
circuit transition between states. Transistors like FETs dissipate power
during these transistions. As clock frequencies get higher and the transistors
have to switch on and off more rapidly, the amount of power
BIOS 148
that dissipates increases dramatically. Heat issues with higher clock
speeds can be a real issue.
Data Transmission
Internal mechanisms that use clock signals typically do so to operate
on some form of data. Before the clock triggers we need some assurance
that the data is already at the inputs. As the clock frequency gets faster,
this makes it more difficult to ensure that the data is indeed already
available.
Furthermore, electrical signals travel at a finite speed. A transitioning
clock signal at one end of a wire takes some time to reach the other end
of the wire. The timing issues involved with this become much more
apparent at high clock speeds.
9.5 BIOS
BIOS stands for Basic Input/Output System. The BIOS is a small piece
of software that is executed when the computer is first powered on. Its
main function is to make the system ready for the operating system to
take control.
Historically, the BIOS was stored on a ROM chip connected to the motherboard.
However, since ROM chips are only programmable once, this
meant that the BIOS software could never be changed without physically
removing and changing the chip containing the program. As personal
computers became more complex the need for an evolving BIOS
became apparent. By the early 1990s, the system BIOS was distributed
on EEPROM devices, which have the capability to be reprogrammed.
The BIOS connects to nonvolatile memory that contains internal settings
for the computer. Historically these settings were contained within
CMOS, which sometimes led to the terms BIOS and CMOS to be used
interchangeably. Storing these settings in CMOS, however, had one
major drawback. It required a small, but always active power in order
to retain the settings. This was generally accomplished by the placing
of a small battery on the motherboard that provided power to maintain
the BIOS settings in the CMOS even when the system was off. Today,
due to the use of EEPROM and Flash technology which can store data
even when power is removed, the internal battery (which is shown in
Figure 9.7, on the next page) is only used to maintain the internal realtime
clock of the system.
OTHER DEVICES 149
Figure 9.7: The battery on a motherboard
9.6 Other Devices
IDE
IDE, or Integrated Drive Electronics, is a connection type found on
motherboards that is used to connect to internal peripheral devices
like hard disk drives, CD and DVD ROM drives, and other storage
devices. There are other terms used in connection with IDE including
EIDE, an enchanced version that was released later, as well as ATA, the
Advanced Technology Attachment. As more devices became available
for the ATA/IDE interface, an extension known as ATAPI (Advanced
Technology Attachment Packet Interface) also became known. Today,
all of these terms mean roughly the same thing.
Cabling
ATA, or Parallel ATA (PATA) as it is sometimes now called, connects to
devices via 40 pin ribbon cables. Each cable connects from the mother
board and runs to one or two devices known as a master/slave configuration.
There are 16 data pins available on the 40-pin cable, so data
is transferred 16 bits at a time.
The 40 pin ribbon cable was suitable for many years, but recently has
cause a bit of an issue for designers.
• Flat cables such as ribbon cables are much more susceptible to
electrical noise from their surroundings.
• The cables have short maximum length specifications (up to 18
inches) and make it difficult to connect devices that aren’t very
OTHER DEVICES 150
close to the motherboard.
• The large flat cables can get in the way of circulating air within the
computer chassis and create issues when it comes to cooling.
• Most cables have connectors to allow two peripherals to be connected.
The signaling aspects of having one or two devices connected
change as the termination of the cable changes, causing
electromagnetic reflection of signals. This can affect data transfer
rates.
To overcome some of these issues, manufacturers have released an 80
pin ribbon cable version that utilizes ground pins in between signal
pins to help with noise issues. They’ve also made some changes to the
layouts of where the various connectors lie on the cable and how the
end devices become connected. This has allowed higher data transfer
rates for newer style devices.
SATA
A more recent development, SATA or Serial ATA, was introduced in
2003. It utilizes a different style of connector than PATA opting instead
of a 7 pin connector. SATA devices transit data serially using differential
signalling at fast clock speeds.